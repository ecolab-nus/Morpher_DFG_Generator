; ModuleID = '../mibench_security/security/rijndael/aes.c'
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.aes = type { i64, i64, [64 x i64], [64 x i64], i8 }

@s_box = constant [256 x i8] c"c|w{\F2ko\C50\01g+\FE\D7\ABv\CA\82\C9}\FAYG\F0\AD\D4\A2\AF\9C\A4r\C0\B7\FD\93&6?\F7\CC4\A5\E5\F1q\D81\15\04\C7#\C3\18\96\05\9A\07\12\80\E2\EB'\B2u\09\83,\1A\1BnZ\A0R;\D6\B3)\E3/\84S\D1\00\ED \FC\B1[j\CB\BE9JLX\CF\D0\EF\AA\FBCM3\85E\F9\02\7FP<\9F\A8Q\A3@\8F\92\9D8\F5\BC\B6\DA!\10\FF\F3\D2\CD\0C\13\EC_\97D\17\C4\A7~=d]\19s`\81O\DC\22*\90\88F\EE\B8\14\DE^\0B\DB\E02:\0AI\06$\5C\C2\D3\ACb\91\95\E4y\E7\C87m\8D\D5N\A9lV\F4\EAez\AE\08\BAx%.\1C\A6\B4\C6\E8\DDt\1FK\BD\8B\8Ap>\B5fH\03\F6\0Ea5W\B9\86\C1\1D\9E\E1\F8\98\11i\D9\8E\94\9B\1E\87\E9\CEU(\DF\8C\A1\89\0D\BF\E6BhA\99-\0F\B0T\BB\16", align 16
@inv_s_box = constant [256 x i8] c"R\09j\D506\A58\BF@\A3\9E\81\F3\D7\FB|\E39\82\9B/\FF\874\8ECD\C4\DE\E9\CBT{\942\A6\C2#=\EEL\95\0BB\FA\C3N\08.\A1f(\D9$\B2v[\A2Im\8B\D1%r\F8\F6d\86h\98\16\D4\A4\5C\CC]e\B6\92lpHP\FD\ED\B9\DA^\15FW\A7\8D\9D\84\90\D8\AB\00\8C\BC\D3\0A\F7\E4X\05\B8\B3E\06\D0,\1E\8F\CA?\0F\02\C1\AF\BD\03\01\13\8Ak:\91\11AOg\DC\EA\97\F2\CF\CE\F0\B4\E6s\96\ACt\22\E7\AD5\85\E2\F97\E8\1Cu\DFnG\F1\1Aq\1D)\C5\89o\B7b\0E\AA\18\BE\1B\FCV>K\C6\D2y \9A\DB\C0\FEx\CDZ\F4\1F\DD\A83\88\07\C71\B1\12\10Y'\80\EC_`Q\7F\A9\19\B5J\0D-\E5z\9F\93\C9\9C\EF\A0\E0;M\AE*\F5\B0\C8\EB\BB<\83S\99a\17+\04~\BAw\D6&\E1i\14cU!\0C}", align 16
@rcon_tab = constant [29 x i64] [i64 1, i64 2, i64 4, i64 8, i64 16, i64 32, i64 64, i64 128, i64 27, i64 54, i64 108, i64 216, i64 171, i64 77, i64 154, i64 47, i64 94, i64 188, i64 99, i64 198, i64 151, i64 53, i64 106, i64 212, i64 179, i64 125, i64 250, i64 239, i64 197], align 16
@ft_tab = constant [4 x [256 x i64]] [[256 x i64] [i64 2774754246, i64 2222750968, i64 2574743534, i64 2373680118, i64 234025727, i64 3177933782, i64 2976870366, i64 1422247313, i64 1345335392, i64 50397442, i64 2842126286, i64 2099981142, i64 436141799, i64 1658312629, i64 3870010189, i64 2591454956, i64 1170918031, i64 2642575903, i64 1086966153, i64 2273148410, i64 368769775, i64 3948501426, i64 3376891790, i64 200339707, i64 3970805057, i64 1742001331, i64 4255294047, i64 3937382213, i64 3214711843, i64 4154762323, i64 2524082916, i64 1539358875, i64 3266819957, i64 486407649, i64 2928907069, i64 1780885068, i64 1513502316, i64 1094664062, i64 49805301, i64 1338821763, i64 1546925160, i64 4104496465, i64 887481809, i64 150073849, i64 2473685474, i64 1943591083, i64 1395732834, i64 1058346282, i64 201589768, i64 1388824469, i64 1696801606, i64 1589887901, i64 672667696, i64 2711000631, i64 251987210, i64 3046808111, i64 151455502, i64 907153956, i64 2608889883, i64 1038279391, i64 652995533, i64 1764173646, i64 3451040383, i64 2675275242, i64 453576978, i64 2659418909, i64 1949051992, i64 773462580, i64 756751158, i64 2993581788, i64 3998898868, i64 4221608027, i64 4132590244, i64 1295727478, i64 1641469623, i64 3467883389, i64 2066295122, i64 1055122397, i64 1898917726, i64 2542044179, i64 4115878822, i64 1758581177, i64 0, i64 753790401, i64 1612718144, i64 536673507, i64 3367088505, i64 3982187446, i64 3194645204, i64 1187761037, i64 3653156455, i64 1262041458, i64 3729410708, i64 3561770136, i64 3898103984, i64 1255133061, i64 1808847035, i64 720367557, i64 3853167183, i64 385612781, i64 3309519750, i64 3612167578, i64 1429418854, i64 2491778321, i64 3477423498, i64 284817897, i64 100794884, i64 2172616702, i64 4031795360, i64 1144798328, i64 3131023141, i64 3819481163, i64 4082192802, i64 4272137053, i64 3225436288, i64 2324664069, i64 2912064063, i64 3164445985, i64 1211644016, i64 83228145, i64 3753688163, i64 3249976951, i64 1977277103, i64 1663115586, i64 806359072, i64 452984805, i64 250868733, i64 1842533055, i64 1288555905, i64 336333848, i64 890442534, i64 804056259, i64 3781124030, i64 2727843637, i64 3427026056, i64 957814574, i64 1472513171, i64 4071073621, i64 2189328124, i64 1195195770, i64 2892260552, i64 3881655738, i64 723065138, i64 2507371494, i64 2690670784, i64 2558624025, i64 3511635870, i64 2145180835, i64 1713513028, i64 2116692564, i64 2878378043, i64 2206763019, i64 3393603212, i64 703524551, i64 3552098411, i64 1007948840, i64 2044649127, i64 3797835452, i64 487262998, i64 1994120109, i64 1004593371, i64 1446130276, i64 1312438900, i64 503974420, i64 3679013266, i64 168166924, i64 1814307912, i64 3831258296, i64 1573044895, i64 1859376061, i64 4021070915, i64 2791465668, i64 2828112185, i64 2761266481, i64 937747667, i64 2339994098, i64 854058965, i64 1137232011, i64 1496790894, i64 3077402074, i64 2358086913, i64 1691735473, i64 3528347292, i64 3769215305, i64 3027004632, i64 4199962284, i64 133494003, i64 636152527, i64 2942657994, i64 2390391540, i64 3920539207, i64 403179536, i64 3585784431, i64 2289596656, i64 1864705354, i64 1915629148, i64 605822008, i64 4054230615, i64 3350508659, i64 1371981463, i64 602466507, i64 2094914977, i64 2624877800, i64 555687742, i64 3712699286, i64 3703422305, i64 2257292045, i64 2240449039, i64 2423288032, i64 1111375484, i64 3300242801, i64 2858837708, i64 3628615824, i64 84083462, i64 32962295, i64 302911004, i64 2741068226, i64 1597322602, i64 4183250862, i64 3501832553, i64 2441512471, i64 1489093017, i64 656219450, i64 3114180135, i64 954327513, i64 335083755, i64 3013122091, i64 856756514, i64 3144247762, i64 1893325225, i64 2307821063, i64 2811532339, i64 3063651117, i64 572399164, i64 2458355477, i64 552200649, i64 1238290055, i64 4283782570, i64 2015897680, i64 2061492133, i64 2408352771, i64 4171342169, i64 2156497161, i64 386731290, i64 3669999461, i64 837215959, i64 3326231172, i64 3093850320, i64 3275833730, i64 2962856233, i64 1999449434, i64 286199582, i64 3417354363, i64 4233385128, i64 3602627437, i64 974525996], [256 x i64] [i64 1667483301, i64 2088564868, i64 2004348569, i64 2071721613, i64 4076011277, i64 1802229437, i64 1869602481, i64 3318059348, i64 808476752, i64 16843267, i64 1734856361, i64 724260477, i64 4278118169, i64 3621238114, i64 2880130534, i64 1987505306, i64 3402272581, i64 2189565853, i64 3385428288, i64 2105408135, i64 4210749205, i64 1499050731, i64 1195871945, i64 4042324747, i64 2913812972, i64 3570709351, i64 2728550397, i64 2947499498, i64 2627478463, i64 2762232823, i64 1920132246, i64 3233848155, i64 3082253762, i64 4261273884, i64 2475900334, i64 640044138, i64 909536346, i64 1061125697, i64 4160222466, i64 3435955023, i64 875849820, i64 2779075060, i64 3857043764, i64 4059166984, i64 1903288979, i64 3638078323, i64 825320019, i64 353708607, i64 67373068, i64 3351745874, i64 589514341, i64 3284376926, i64 404238376, i64 2526427041, i64 84216335, i64 2593796021, i64 117902857, i64 303178806, i64 2155879323, i64 3806519101, i64 3958099238, i64 656887401, i64 2998042573, i64 1970662047, i64 151589403, i64 2206408094, i64 741103732, i64 437924910, i64 454768173, i64 1852759218, i64 1515893998, i64 2694863867, i64 1381147894, i64 993752653, i64 3604395873, i64 3014884814, i64 690573947, i64 3823361342, i64 791633521, i64 2223248279, i64 1397991157, i64 3520182632, i64 0, i64 3991781676, i64 538984544, i64 4244431647, i64 2981198280, i64 1532737261, i64 1785386174, i64 3419114822, i64 3200149465, i64 960066123, i64 1246401758, i64 1280088276, i64 1482207464, i64 3486483786, i64 3503340395, i64 4025468202, i64 2863288293, i64 4227591446, i64 1128498885, i64 1296931543, i64 859006549, i64 2240090516, i64 1162185423, i64 4193904912, i64 33686534, i64 2139094657, i64 1347461360, i64 1010595908, i64 2678007226, i64 2829601763, i64 1364304627, i64 2745392638, i64 1077969088, i64 2408514954, i64 2459058093, i64 2644320700, i64 943222856, i64 4126535940, i64 3166462943, i64 3065411521, i64 3671764853, i64 555827811, i64 269492272, i64 4294960410, i64 4092853518, i64 3537026925, i64 3452797260, i64 202119188, i64 320022069, i64 3974939439, i64 1600110305, i64 2543269282, i64 1145342156, i64 387395129, i64 3301217111, i64 2812761586, i64 2122251394, i64 1027439175, i64 1684326572, i64 1566423783, i64 421081643, i64 1936975509, i64 1616953504, i64 2172721560, i64 1330618065, i64 3705447295, i64 572671078, i64 707417214, i64 2425371563, i64 2290617219, i64 1179028682, i64 4008625961, i64 3099093971, i64 336865340, i64 3739133817, i64 1583267042, i64 185275933, i64 3688607094, i64 3772832571, i64 842163286, i64 976909390, i64 168432670, i64 1229558491, i64 101059594, i64 606357612, i64 1549580516, i64 3267534685, i64 3553869166, i64 2896970735, i64 1650640038, i64 2442213800, i64 2509582756, i64 3840201527, i64 2038035083, i64 3890730290, i64 3368586051, i64 926379609, i64 1835915959, i64 2374828428, i64 3587551588, i64 1313774802, i64 2846444000, i64 1819072692, i64 1448520954, i64 4109693703, i64 3941256997, i64 1701169839, i64 2054878350, i64 2930657257, i64 134746136, i64 3132780501, i64 2021191816, i64 623200879, i64 774790258, i64 471611428, i64 2795919345, i64 3031724999, i64 3334903633, i64 3907570467, i64 3722289532, i64 1953818780, i64 522141217, i64 1263245021, i64 3183305180, i64 2341145990, i64 2324303749, i64 1886445712, i64 1044282434, i64 3048567236, i64 1718013098, i64 1212715224, i64 50529797, i64 4143380225, i64 235805714, i64 1633796771, i64 892693087, i64 1465364217, i64 3115936208, i64 2256934801, i64 3250690392, i64 488454695, i64 2661164985, i64 3789674808, i64 4177062675, i64 2560109491, i64 286335539, i64 1768542907, i64 3654920560, i64 2391672713, i64 2492740519, i64 2610638262, i64 505297954, i64 2273777042, i64 3924412704, i64 3469641545, i64 1431677695, i64 673730680, i64 3755976058, i64 2357986191, i64 2711706104, i64 2307459456, i64 218962455, i64 3216991706, i64 3873888049, i64 1111655622, i64 1751699640, i64 1094812355, i64 2576951728, i64 757946999, i64 252648977, i64 2964356043, i64 1414834428, i64 3149622742, i64 370551866], [256 x i64] [i64 1673962851, i64 2096661628, i64 2012125559, i64 2079755643, i64 4076801522, i64 1809235307, i64 1876865391, i64 3314635973, i64 811618352, i64 16909057, i64 1741597031, i64 727088427, i64 4276558334, i64 3618988759, i64 2874009259, i64 1995217526, i64 3398387146, i64 2183110018, i64 3381215433, i64 2113570685, i64 4209972730, i64 1504897881, i64 1200539975, i64 4042984432, i64 2906778797, i64 3568527316, i64 2724199842, i64 2940594863, i64 2619588508, i64 2756966308, i64 1927583346, i64 3231407040, i64 3077948087, i64 4259388669, i64 2470293139, i64 642542118, i64 913070646, i64 1065238847, i64 4160029431, i64 3431157708, i64 879254580, i64 2773611685, i64 3855693029, i64 4059629809, i64 1910674289, i64 3635114968, i64 828527409, i64 355090197, i64 67636228, i64 3348452039, i64 591815971, i64 3281870531, i64 405809176, i64 2520228246, i64 84545285, i64 2586817946, i64 118360327, i64 304363026, i64 2149292928, i64 3806281186, i64 3956090603, i64 659450151, i64 2994720178, i64 1978310517, i64 152181513, i64 2199756419, i64 743994412, i64 439627290, i64 456535323, i64 1859957358, i64 1521806938, i64 2690382752, i64 1386542674, i64 997608763, i64 3602342358, i64 3011366579, i64 693271337, i64 3822927587, i64 794718511, i64 2215876484, i64 1403450707, i64 3518589137, i64 0, i64 3988860141, i64 541089824, i64 4242743292, i64 2977548465, i64 1538714971, i64 1792327274, i64 3415033547, i64 3194476990, i64 963791673, i64 1251270218, i64 1285084236, i64 1487988824, i64 3481619151, i64 3501943760, i64 4022676207, i64 2857362858, i64 4226619131, i64 1132905795, i64 1301993293, i64 862344499, i64 2232521861, i64 1166724933, i64 4192801017, i64 33818114, i64 2147385727, i64 1352724560, i64 1014514748, i64 2670049951, i64 2823545768, i64 1369633617, i64 2740846243, i64 1082179648, i64 2399505039, i64 2453646738, i64 2636233885, i64 946882616, i64 4126213365, i64 3160661948, i64 3061301686, i64 3668932058, i64 557998881, i64 270544912, i64 4293204735, i64 4093447923, i64 3535760850, i64 3447803085, i64 202904588, i64 321271059, i64 3972214764, i64 1606345055, i64 2536874647, i64 1149815876, i64 388905239, i64 3297990596, i64 2807427751, i64 2130477694, i64 1031423805, i64 1690872932, i64 1572530013, i64 422718233, i64 1944491379, i64 1623236704, i64 2165938305, i64 1335808335, i64 3701702620, i64 574907938, i64 710180394, i64 2419829648, i64 2282455944, i64 1183631942, i64 4006029806, i64 3094074296, i64 338181140, i64 3735517662, i64 1589437022, i64 185998603, i64 3685578459, i64 3772464096, i64 845436466, i64 980700730, i64 169090570, i64 1234361161, i64 101452294, i64 608726052, i64 1555620956, i64 3265224130, i64 3552407251, i64 2890133420, i64 1657054818, i64 2436475025, i64 2503058581, i64 3839047652, i64 2045938553, i64 3889509095, i64 3364570056, i64 929978679, i64 1843050349, i64 2365688973, i64 3585172693, i64 1318900302, i64 2840191145, i64 1826141292, i64 1454176854, i64 4109567988, i64 3939444202, i64 1707781989, i64 2062847610, i64 2923948462, i64 135272456, i64 3127891386, i64 2029029496, i64 625635109, i64 777810478, i64 473441308, i64 2790781350, i64 3027486644, i64 3331805638, i64 3905627112, i64 3718347997, i64 1961401460, i64 524165407, i64 1268178251, i64 3177307325, i64 2332919435, i64 2316273034, i64 1893765232, i64 1048330814, i64 3044132021, i64 1724688998, i64 1217452104, i64 50726147, i64 4143383030, i64 236720654, i64 1640145761, i64 896163637, i64 1471084887, i64 3110719673, i64 2249691526, i64 3248052417, i64 490350365, i64 2653403550, i64 3789109473, i64 4176155640, i64 2553000856, i64 287453969, i64 1775418217, i64 3651760345, i64 2382858638, i64 2486413204, i64 2603464347, i64 507257374, i64 2266337927, i64 3922272489, i64 3464972750, i64 1437269845, i64 676362280, i64 3752164063, i64 2349043596, i64 2707028129, i64 2299101321, i64 219813645, i64 3211123391, i64 3872862694, i64 1115997762, i64 1758509160, i64 1099088705, i64 2569646233, i64 760903469, i64 253628687, i64 2960903088, i64 1420360788, i64 3144537787, i64 371997206], [256 x i64] [i64 3332727651, i64 4169432188, i64 4003034999, i64 4136467323, i64 4279104242, i64 3602738027, i64 3736170351, i64 2438251973, i64 1615867952, i64 33751297, i64 3467208551, i64 1451043627, i64 3877240574, i64 3043153879, i64 1306962859, i64 3969545846, i64 2403715786, i64 530416258, i64 2302724553, i64 4203183485, i64 4011195130, i64 3001768281, i64 2395555655, i64 4211863792, i64 1106029997, i64 3009926356, i64 1610457762, i64 1173008303, i64 599760028, i64 1408738468, i64 3835064946, i64 2606481600, i64 1975695287, i64 3776773629, i64 1034851219, i64 1282024998, i64 1817851446, i64 2118205247, i64 4110612471, i64 2203045068, i64 1750873140, i64 1374987685, i64 3509904869, i64 4178113009, i64 3801313649, i64 2876496088, i64 1649619249, i64 708777237, i64 135005188, i64 2505230279, i64 1181033251, i64 2640233411, i64 807933976, i64 933336726, i64 168756485, i64 800430746, i64 235472647, i64 607523346, i64 463175808, i64 3745374946, i64 3441880043, i64 1315514151, i64 2144187058, i64 3936318837, i64 303761673, i64 496927619, i64 1484008492, i64 875436570, i64 908925723, i64 3702681198, i64 3035519578, i64 1543217312, i64 2767606354, i64 1984772923, i64 3076642518, i64 2110698419, i64 1383803177, i64 3711886307, i64 1584475951, i64 328696964, i64 2801095507, i64 3110654417, i64 0, i64 3240947181, i64 1080041504, i64 3810524412, i64 2043195825, i64 3069008731, i64 3569248874, i64 2370227147, i64 1742323390, i64 1917532473, i64 2497595978, i64 2564049996, i64 2968016984, i64 2236272591, i64 3144405200, i64 3307925487, i64 1340451498, i64 3977706491, i64 2261074755, i64 2597801293, i64 1716859699, i64 294946181, i64 2328839493, i64 3910203897, i64 67502594, i64 4269899647, i64 2700103760, i64 2017737788, i64 632987551, i64 1273211048, i64 2733855057, i64 1576969123, i64 2160083008, i64 92966799, i64 1068339858, i64 566009245, i64 1883781176, i64 4043634165, i64 1675607228, i64 2009183926, i64 2943736538, i64 1113792801, i64 540020752, i64 3843751935, i64 4245615603, i64 3211645650, i64 2169294285, i64 403966988, i64 641012499, i64 3274697964, i64 3202441055, i64 899848087, i64 2295088196, i64 775493399, i64 2472002756, i64 1441965991, i64 4236410494, i64 2051489085, i64 3366741092, i64 3135724893, i64 841685273, i64 3868554099, i64 3231735904, i64 429425025, i64 2664517455, i64 2743065820, i64 1147544098, i64 1417554474, i64 1001099408, i64 193169544, i64 2362066502, i64 3341414126, i64 1809037496, i64 675025940, i64 2809781982, i64 3168951902, i64 371002123, i64 2910247899, i64 3678134496, i64 1683370546, i64 1951283770, i64 337512970, i64 2463844681, i64 201983494, i64 1215046692, i64 3101973596, i64 2673722050, i64 3178157011, i64 1139780780, i64 3299238498, i64 967348625, i64 832869781, i64 3543655652, i64 4069226873, i64 3576883175, i64 2336475336, i64 1851340599, i64 3669454189, i64 25988493, i64 2976175573, i64 2631028302, i64 1239460265, i64 3635702892, i64 2902087254, i64 4077384948, i64 3475368682, i64 3400492389, i64 4102978170, i64 1206496942, i64 270010376, i64 1876277946, i64 4035475576, i64 1248797989, i64 1550986798, i64 941890588, i64 1475454630, i64 1942467764, i64 2538718918, i64 3408128232, i64 2709315037, i64 3902567540, i64 1042358047, i64 2531085131, i64 1641856445, i64 226921355, i64 260409994, i64 3767562352, i64 2084716094, i64 1908716981, i64 3433719398, i64 2430093384, i64 100991747, i64 4144101110, i64 470945294, i64 3265487201, i64 1784624437, i64 2935576407, i64 1775286713, i64 395413126, i64 2572730817, i64 975641885, i64 666476190, i64 3644383713, i64 3943954680, i64 733190296, i64 573772049, i64 3535497577, i64 2842745305, i64 126455438, i64 866620564, i64 766942107, i64 1008868894, i64 361924487, i64 3374377449, i64 2269761230, i64 2868860245, i64 1350051880, i64 2776293343, i64 59739276, i64 1509466529, i64 159418761, i64 437718285, i64 1708834751, i64 3610371814, i64 2227585602, i64 3501746280, i64 2193834305, i64 699439513, i64 1517759789, i64 504434447, i64 2076946608, i64 2835108948, i64 1842789307, i64 742004246]], align 16
@it_tab = constant [4 x [256 x i64]] [[256 x i64] [i64 1353184337, i64 1399144830, i64 3282310938, i64 2522752826, i64 3412831035, i64 4047871263, i64 2874735276, i64 2466505547, i64 1442459680, i64 4134368941, i64 2440481928, i64 625738485, i64 4242007375, i64 3620416197, i64 2151953702, i64 2409849525, i64 1230680542, i64 1729870373, i64 2551114309, i64 3787521629, i64 41234371, i64 317738113, i64 2744600205, i64 3338261355, i64 3881799427, i64 2510066197, i64 3950669247, i64 3663286933, i64 763608788, i64 3542185048, i64 694804553, i64 1154009486, i64 1787413109, i64 2021232372, i64 1799248025, i64 3715217703, i64 3058688446, i64 397248752, i64 1722556617, i64 3023752829, i64 407560035, i64 2184256229, i64 1613975959, i64 1165972322, i64 3765920945, i64 2226023355, i64 480281086, i64 2485848313, i64 1483229296, i64 436028815, i64 2272059028, i64 3086515026, i64 601060267, i64 3791801202, i64 1468997603, i64 715871590, i64 120122290, i64 63092015, i64 2591802758, i64 2768779219, i64 4068943920, i64 2997206819, i64 3127509762, i64 1552029421, i64 723308426, i64 2461301159, i64 4042393587, i64 2715969870, i64 3455375973, i64 3586000134, i64 526529745, i64 2331944644, i64 2639474228, i64 2689987490, i64 853641733, i64 1978398372, i64 971801355, i64 2867814464, i64 111112542, i64 1360031421, i64 4186579262, i64 1023860118, i64 2919579357, i64 1186850381, i64 3045938321, i64 90031217, i64 1876166148, i64 4279586912, i64 620468249, i64 2548678102, i64 3426959497, i64 2006899047, i64 3175278768, i64 2290845959, i64 945494503, i64 3689859193, i64 1191869601, i64 3910091388, i64 3374220536, i64 0, i64 2206629897, i64 1223502642, i64 2893025566, i64 1316117100, i64 4227796733, i64 1446544655, i64 517320253, i64 658058550, i64 1691946762, i64 564550760, i64 3511966619, i64 976107044, i64 2976320012, i64 266819475, i64 3533106868, i64 2660342555, i64 1338359936, i64 2720062561, i64 1766553434, i64 370807324, i64 179999714, i64 3844776128, i64 1138762300, i64 488053522, i64 185403662, i64 2915535858, i64 3114841645, i64 3366526484, i64 2233069911, i64 1275557295, i64 3151862254, i64 4250959779, i64 2670068215, i64 3170202204, i64 3309004356, i64 880737115, i64 1982415755, i64 3703972811, i64 1761406390, i64 1676797112, i64 3403428311, i64 277177154, i64 1076008723, i64 538035844, i64 2099530373, i64 4164795346, i64 288553390, i64 1839278535, i64 1261411869, i64 4080055004, i64 3964831245, i64 3504587127, i64 1813426987, i64 2579067049, i64 4199060497, i64 577038663, i64 3297574056, i64 440397984, i64 3626794326, i64 4019204898, i64 3343796615, i64 3251714265, i64 4272081548, i64 906744984, i64 3481400742, i64 685669029, i64 646887386, i64 2764025151, i64 3835509292, i64 227702864, i64 2613862250, i64 1648787028, i64 3256061430, i64 3904428176, i64 1593260334, i64 4121936770, i64 3196083615, i64 2090061929, i64 2838353263, i64 3004310991, i64 999926984, i64 2809993232, i64 1852021992, i64 2075868123, i64 158869197, i64 4095236462, i64 28809964, i64 2828685187, i64 1701746150, i64 2129067946, i64 147831841, i64 3873969647, i64 3650873274, i64 3459673930, i64 3557400554, i64 3598495785, i64 2947720241, i64 824393514, i64 815048134, i64 3227951669, i64 935087732, i64 2798289660, i64 2966458592, i64 366520115, i64 1251476721, i64 4158319681, i64 240176511, i64 804688151, i64 2379631990, i64 1303441219, i64 1414376140, i64 3741619940, i64 3820343710, i64 461924940, i64 3089050817, i64 2136040774, i64 82468509, i64 1563790337, i64 1937016826, i64 776014843, i64 1511876531, i64 1389550482, i64 861278441, i64 323475053, i64 2355222426, i64 2047648055, i64 2383738969, i64 2302415851, i64 3995576782, i64 902390199, i64 3991215329, i64 1018251130, i64 1507840668, i64 1064563285, i64 2043548696, i64 3208103795, i64 3939366739, i64 1537932639, i64 342834655, i64 2262516856, i64 2180231114, i64 1053059257, i64 741614648, i64 1598071746, i64 1925389590, i64 203809468, i64 2336832552, i64 1100287487, i64 1895934009, i64 3736275976, i64 2632234200, i64 2428589668, i64 1636092795, i64 1890988757, i64 1952214088, i64 1113045200], [256 x i64] [i64 2817806672, i64 1698790995, i64 2752977603, i64 1579629206, i64 1806384075, i64 1167925233, i64 1492823211, i64 65227667, i64 4197458005, i64 1836494326, i64 1993115793, i64 1275262245, i64 3622129660, i64 3408578007, i64 1144333952, i64 2741155215, i64 1521606217, i64 465184103, i64 250234264, i64 3237895649, i64 1966064386, i64 4031545618, i64 2537983395, i64 4191382470, i64 1603208167, i64 2626819477, i64 2054012907, i64 1498584538, i64 2210321453, i64 561273043, i64 1776306473, i64 3368652356, i64 2311222634, i64 2039411832, i64 1045993835, i64 1907959773, i64 1340194486, i64 2911432727, i64 2887829862, i64 986611124, i64 1256153880, i64 823846274, i64 860985184, i64 2136171077, i64 2003087840, i64 2926295940, i64 2692873756, i64 722008468, i64 1749577816, i64 4249194265, i64 1826526343, i64 4168831671, i64 3547573027, i64 38499042, i64 2401231703, i64 2874500650, i64 686535175, i64 3266653955, i64 2076542618, i64 137876389, i64 2267558130, i64 2780767154, i64 1778582202, i64 2182540636, i64 483363371, i64 3027871634, i64 4060607472, i64 3798552225, i64 4107953613, i64 3188000469, i64 1647628575, i64 4272342154, i64 1395537053, i64 1442030240, i64 3783918898, i64 3958809717, i64 3968011065, i64 4016062634, i64 2675006982, i64 275692881, i64 2317434617, i64 115185213, i64 88006062, i64 3185986886, i64 2371129781, i64 1573155077, i64 3557164143, i64 357589247, i64 4221049124, i64 3921532567, i64 1128303052, i64 2665047927, i64 1122545853, i64 2341013384, i64 1528424248, i64 4006115803, i64 175939911, i64 256015593, i64 512030921, i64 0, i64 2256537987, i64 3979031112, i64 1880170156, i64 1918528590, i64 4279172603, i64 948244310, i64 3584965918, i64 959264295, i64 3641641572, i64 2791073825, i64 1415289809, i64 775300154, i64 1728711857, i64 3881276175, i64 2532226258, i64 2442861470, i64 3317727311, i64 551313826, i64 1266113129, i64 437394454, i64 3130253834, i64 715178213, i64 3760340035, i64 387650077, i64 218697227, i64 3347837613, i64 2830511545, i64 2837320904, i64 435246981, i64 125153100, i64 3717852859, i64 1618977789, i64 637663135, i64 4117912764, i64 996558021, i64 2130402100, i64 692292470, i64 3324234716, i64 4243437160, i64 4058298467, i64 3694254026, i64 2237874704, i64 580326208, i64 298222624, i64 608863613, i64 1035719416, i64 855223825, i64 2703869805, i64 798891339, i64 817028339, i64 1384517100, i64 3821107152, i64 380840812, i64 3111168409, i64 1217663482, i64 1693009698, i64 2365368516, i64 1072734234, i64 746411736, i64 2419270383, i64 1313441735, i64 3510163905, i64 2731183358, i64 198481974, i64 2180359887, i64 3732579624, i64 2394413606, i64 3215802276, i64 2637835492, i64 2457358349, i64 3428805275, i64 1182684258, i64 328070850, i64 3101200616, i64 4147719774, i64 2948825845, i64 2153619390, i64 2479909244, i64 768962473, i64 304467891, i64 2578237499, i64 2098729127, i64 1671227502, i64 3141262203, i64 2015808777, i64 408514292, i64 3080383489, i64 2588902312, i64 1855317605, i64 3875515006, i64 3485212936, i64 3893751782, i64 2615655129, i64 913263310, i64 161475284, i64 2091919830, i64 2997105071, i64 591342129, i64 2493892144, i64 1721906624, i64 3159258167, i64 3397581990, i64 3499155632, i64 3634836245, i64 2550460746, i64 3672916471, i64 1355644686, i64 4136703791, i64 3595400845, i64 2968470349, i64 1303039060, i64 76997855, i64 3050413795, i64 2288667675, i64 523026872, i64 1365591679, i64 3932069124, i64 898367837, i64 1955068531, i64 1091304238, i64 493335386, i64 3537605202, i64 1443948851, i64 1205234963, i64 1641519756, i64 211892090, i64 351820174, i64 1007938441, i64 665439982, i64 3378624309, i64 3843875309, i64 2974251580, i64 3755121753, i64 1945261375, i64 3457423481, i64 935818175, i64 3455538154, i64 2868731739, i64 1866325780, i64 3678697606, i64 4088384129, i64 3295197502, i64 874788908, i64 1084473951, i64 3273463410, i64 635616268, i64 1228679307, i64 2500722497, i64 27801969, i64 3003910366, i64 3837057180, i64 3243664528, i64 2227927905, i64 3056784752, i64 1550600308, i64 1471729730], [256 x i64] [i64 4098969767, i64 1098797925, i64 387629988, i64 658151006, i64 2872822635, i64 2636116293, i64 4205620056, i64 3813380867, i64 807425530, i64 1991112301, i64 3431502198, i64 49620300, i64 3847224535, i64 717608907, i64 891715652, i64 1656065955, i64 2984135002, i64 3123013403, i64 3930429454, i64 4267565504, i64 801309301, i64 1283527408, i64 1183687575, i64 3547055865, i64 2399397727, i64 2450888092, i64 1841294202, i64 1385552473, i64 3201576323, i64 1951978273, i64 3762891113, i64 3381544136, i64 3262474889, i64 2398386297, i64 1486449470, i64 3106397553, i64 3787372111, i64 2297436077, i64 550069932, i64 3464344634, i64 3747813450, i64 451248689, i64 1368875059, i64 1398949247, i64 1689378935, i64 1807451310, i64 2180914336, i64 150574123, i64 1215322216, i64 1167006205, i64 3734275948, i64 2069018616, i64 1940595667, i64 1265820162, i64 534992783, i64 1432758955, i64 3954313000, i64 3039757250, i64 3313932923, i64 936617224, i64 674296455, i64 3206787749, i64 50510442, i64 384654466, i64 3481938716, i64 2041025204, i64 133427442, i64 1766760930, i64 3664104948, i64 84334014, i64 886120290, i64 2797898494, i64 775200083, i64 4087521365, i64 2315596513, i64 4137973227, i64 2198551020, i64 1614850799, i64 1901987487, i64 1857900816, i64 557775242, i64 3717610758, i64 1054715397, i64 3863824061, i64 1418835341, i64 3295741277, i64 100954068, i64 1348534037, i64 2551784699, i64 3184957417, i64 1082772547, i64 3647436702, i64 3903896898, i64 2298972299, i64 434583643, i64 3363429358, i64 2090944266, i64 1115482383, i64 2230896926, i64 0, i64 2148107142, i64 724715757, i64 287222896, i64 1517047410, i64 251526143, i64 2232374840, i64 2923241173, i64 758523705, i64 252339417, i64 1550328230, i64 1536938324, i64 908343854, i64 168604007, i64 1469255655, i64 4004827798, i64 2602278545, i64 3229634501, i64 3697386016, i64 2002413899, i64 303830554, i64 2481064634, i64 2696996138, i64 574374880, i64 454171927, i64 151915277, i64 2347937223, i64 3056449960, i64 504678569, i64 4049044761, i64 1974422535, i64 2582559709, i64 2141453664, i64 33005350, i64 1918680309, i64 1715782971, i64 4217058430, i64 1133213225, i64 600562886, i64 3988154620, i64 3837289457, i64 836225756, i64 1665273989, i64 2534621218, i64 3330547729, i64 1250262308, i64 3151165501, i64 4188934450, i64 700935585, i64 2652719919, i64 3000824624, i64 2249059410, i64 3245854947, i64 3005967382, i64 1890163129, i64 2484206152, i64 3913753188, i64 4238918796, i64 4037024319, i64 2102843436, i64 857927568, i64 1233635150, i64 953795025, i64 3398237858, i64 3566745099, i64 4121350017, i64 2057644254, i64 3084527246, i64 2906629311, i64 976020637, i64 2018512274, i64 1600822220, i64 2119459398, i64 2381758995, i64 3633375416, i64 959340279, i64 3280139695, i64 1570750080, i64 3496574099, i64 3580864813, i64 634368786, i64 2898803609, i64 403744637, i64 2632478307, i64 1004239803, i64 650971512, i64 1500443672, i64 2599158199, i64 1334028442, i64 2514904430, i64 4289363686, i64 3156281551, i64 368043752, i64 3887782299, i64 1867173430, i64 2682967049, i64 2955531900, i64 2754719666, i64 1059729699, i64 2781229204, i64 2721431654, i64 1316239292, i64 2197595850, i64 2430644432, i64 2805143000, i64 82922136, i64 3963746266, i64 3447656016, i64 2434215926, i64 1299615190, i64 4014165424, i64 2865517645, i64 2531581700, i64 3516851125, i64 1783372680, i64 750893087, i64 1699118929, i64 1587348714, i64 2348899637, i64 2281337716, i64 201010753, i64 1739807261, i64 3683799762, i64 283718486, i64 3597472583, i64 3617229921, i64 2704767500, i64 4166618644, i64 334203196, i64 2848910887, i64 1639396809, i64 484568549, i64 1199193265, i64 3533461983, i64 4065673075, i64 337148366, i64 3346251575, i64 4149471949, i64 4250885034, i64 1038029935, i64 1148749531, i64 2949284339, i64 1756970692, i64 607661108, i64 2747424576, i64 488010435, i64 3803974693, i64 1009290057, i64 234832277, i64 2822336769, i64 201907891, i64 3034094820, i64 1449431233, i64 3413860740, i64 852848822, i64 1816687708, i64 3100656215], [256 x i64] [i64 1364240372, i64 2119394625, i64 449029143, i64 982933031, i64 1003187115, i64 535905693, i64 2896910586, i64 1267925987, i64 542505520, i64 2918608246, i64 2291234508, i64 4112862210, i64 1341970405, i64 3319253802, i64 645940277, i64 3046089570, i64 3729349297, i64 627514298, i64 1167593194, i64 1575076094, i64 3271718191, i64 2165502028, i64 2376308550, i64 1808202195, i64 65494927, i64 362126482, i64 3219880557, i64 2514114898, i64 3559752638, i64 1490231668, i64 1227450848, i64 2386872521, i64 1969916354, i64 4101536142, i64 2573942360, i64 668823993, i64 3199619041, i64 4028083592, i64 3378949152, i64 2108963534, i64 1662536415, i64 3850514714, i64 2539664209, i64 1648721747, i64 2984277860, i64 3146034795, i64 4263288961, i64 4187237128, i64 1884842056, i64 2400845125, i64 2491903198, i64 1387788411, i64 2871251827, i64 1927414347, i64 3814166303, i64 1714072405, i64 2986813675, i64 788775605, i64 2258271173, i64 3550808119, i64 821200680, i64 598910399, i64 45771267, i64 3982262806, i64 2318081231, i64 2811409529, i64 4092654087, i64 1319232105, i64 1707996378, i64 114671109, i64 3508494900, i64 3297443494, i64 882725678, i64 2728416755, i64 87220618, i64 2759191542, i64 188345475, i64 1084944224, i64 1577492337, i64 3176206446, i64 1056541217, i64 2520581853, i64 3719169342, i64 1296481766, i64 2444594516, i64 1896177092, i64 74437638, i64 1627329872, i64 421854104, i64 3600279997, i64 2311865152, i64 1735892697, i64 2965193448, i64 126389129, i64 3879230233, i64 2044456648, i64 2705787516, i64 2095648578, i64 4173930116, i64 0, i64 159614592, i64 843640107, i64 514617361, i64 1817080410, i64 4261150478, i64 257308805, i64 1025430958, i64 908540205, i64 174381327, i64 1747035740, i64 2614187099, i64 607792694, i64 212952842, i64 2467293015, i64 3033700078, i64 463376795, i64 2152711616, i64 1638015196, i64 1516850039, i64 471210514, i64 3792353939, i64 3236244128, i64 1011081250, i64 303896347, i64 235605257, i64 4071475083, i64 767142070, i64 348694814, i64 1468340721, i64 2940995445, i64 4005289369, i64 2751291519, i64 4154402305, i64 1555887474, i64 1153776486, i64 1530167035, i64 2339776835, i64 3420243491, i64 3060333805, i64 3093557732, i64 3620396081, i64 1108378979, i64 322970263, i64 2216694214, i64 2239571018, i64 3539484091, i64 2920362745, i64 3345850665, i64 491466654, i64 3706925234, i64 233591430, i64 2010178497, i64 728503987, i64 2845423984, i64 301615252, i64 1193436393, i64 2831453436, i64 2686074864, i64 1457007741, i64 586125363, i64 2277985865, i64 3653357880, i64 2365498058, i64 2553678804, i64 2798617077, i64 2770919034, i64 3659959991, i64 1067761581, i64 753179962, i64 1343066744, i64 1788595295, i64 1415726718, i64 4139914125, i64 2431170776, i64 777975609, i64 2197139395, i64 2680062045, i64 1769771984, i64 1873358293, i64 3484619301, i64 3359349164, i64 279411992, i64 3899548572, i64 3682319163, i64 3439949862, i64 1861490777, i64 3959535514, i64 2208864847, i64 3865407125, i64 2860443391, i64 554225596, i64 4024887317, i64 3134823399, i64 1255028335, i64 3939764639, i64 701922480, i64 833598116, i64 707863359, i64 3325072549, i64 901801634, i64 1949809742, i64 4238789250, i64 3769684112, i64 857069735, i64 4048197636, i64 1106762476, i64 2131644621, i64 389019281, i64 1989006925, i64 1129165039, i64 3428076970, i64 3839820950, i64 2665723345, i64 1276872810, i64 3250069292, i64 1182749029, i64 2634345054, i64 22885772, i64 4201870471, i64 4214112523, i64 3009027431, i64 2454901467, i64 3912455696, i64 1829980118, i64 2592891351, i64 930745505, i64 1502483704, i64 3951639571, i64 3471714217, i64 3073755489, i64 3790464284, i64 2050797895, i64 2623135698, i64 1430221810, i64 410635796, i64 1941911495, i64 1407897079, i64 1599843069, i64 3742658365, i64 2022103876, i64 3397514159, i64 3107898472, i64 942421028, i64 3261022371, i64 376619805, i64 3154912738, i64 680216892, i64 4282488077, i64 963707304, i64 148812556, i64 3634160820, i64 1687208278, i64 2069988555, i64 3580933682, i64 1215585388, i64 3494008760]], align 16
@fl_tab = constant [4 x [256 x i64]] [[256 x i64] [i64 99, i64 124, i64 119, i64 123, i64 242, i64 107, i64 111, i64 197, i64 48, i64 1, i64 103, i64 43, i64 254, i64 215, i64 171, i64 118, i64 202, i64 130, i64 201, i64 125, i64 250, i64 89, i64 71, i64 240, i64 173, i64 212, i64 162, i64 175, i64 156, i64 164, i64 114, i64 192, i64 183, i64 253, i64 147, i64 38, i64 54, i64 63, i64 247, i64 204, i64 52, i64 165, i64 229, i64 241, i64 113, i64 216, i64 49, i64 21, i64 4, i64 199, i64 35, i64 195, i64 24, i64 150, i64 5, i64 154, i64 7, i64 18, i64 128, i64 226, i64 235, i64 39, i64 178, i64 117, i64 9, i64 131, i64 44, i64 26, i64 27, i64 110, i64 90, i64 160, i64 82, i64 59, i64 214, i64 179, i64 41, i64 227, i64 47, i64 132, i64 83, i64 209, i64 0, i64 237, i64 32, i64 252, i64 177, i64 91, i64 106, i64 203, i64 190, i64 57, i64 74, i64 76, i64 88, i64 207, i64 208, i64 239, i64 170, i64 251, i64 67, i64 77, i64 51, i64 133, i64 69, i64 249, i64 2, i64 127, i64 80, i64 60, i64 159, i64 168, i64 81, i64 163, i64 64, i64 143, i64 146, i64 157, i64 56, i64 245, i64 188, i64 182, i64 218, i64 33, i64 16, i64 255, i64 243, i64 210, i64 205, i64 12, i64 19, i64 236, i64 95, i64 151, i64 68, i64 23, i64 196, i64 167, i64 126, i64 61, i64 100, i64 93, i64 25, i64 115, i64 96, i64 129, i64 79, i64 220, i64 34, i64 42, i64 144, i64 136, i64 70, i64 238, i64 184, i64 20, i64 222, i64 94, i64 11, i64 219, i64 224, i64 50, i64 58, i64 10, i64 73, i64 6, i64 36, i64 92, i64 194, i64 211, i64 172, i64 98, i64 145, i64 149, i64 228, i64 121, i64 231, i64 200, i64 55, i64 109, i64 141, i64 213, i64 78, i64 169, i64 108, i64 86, i64 244, i64 234, i64 101, i64 122, i64 174, i64 8, i64 186, i64 120, i64 37, i64 46, i64 28, i64 166, i64 180, i64 198, i64 232, i64 221, i64 116, i64 31, i64 75, i64 189, i64 139, i64 138, i64 112, i64 62, i64 181, i64 102, i64 72, i64 3, i64 246, i64 14, i64 97, i64 53, i64 87, i64 185, i64 134, i64 193, i64 29, i64 158, i64 225, i64 248, i64 152, i64 17, i64 105, i64 217, i64 142, i64 148, i64 155, i64 30, i64 135, i64 233, i64 206, i64 85, i64 40, i64 223, i64 140, i64 161, i64 137, i64 13, i64 191, i64 230, i64 66, i64 104, i64 65, i64 153, i64 45, i64 15, i64 176, i64 84, i64 187, i64 22], [256 x i64] [i64 25344, i64 31744, i64 30464, i64 31488, i64 61952, i64 27392, i64 28416, i64 50432, i64 12288, i64 256, i64 26368, i64 11008, i64 65024, i64 55040, i64 43776, i64 30208, i64 51712, i64 33280, i64 51456, i64 32000, i64 64000, i64 22784, i64 18176, i64 61440, i64 44288, i64 54272, i64 41472, i64 44800, i64 39936, i64 41984, i64 29184, i64 49152, i64 46848, i64 64768, i64 37632, i64 9728, i64 13824, i64 16128, i64 63232, i64 52224, i64 13312, i64 42240, i64 58624, i64 61696, i64 28928, i64 55296, i64 12544, i64 5376, i64 1024, i64 50944, i64 8960, i64 49920, i64 6144, i64 38400, i64 1280, i64 39424, i64 1792, i64 4608, i64 32768, i64 57856, i64 60160, i64 9984, i64 45568, i64 29952, i64 2304, i64 33536, i64 11264, i64 6656, i64 6912, i64 28160, i64 23040, i64 40960, i64 20992, i64 15104, i64 54784, i64 45824, i64 10496, i64 58112, i64 12032, i64 33792, i64 21248, i64 53504, i64 0, i64 60672, i64 8192, i64 64512, i64 45312, i64 23296, i64 27136, i64 51968, i64 48640, i64 14592, i64 18944, i64 19456, i64 22528, i64 52992, i64 53248, i64 61184, i64 43520, i64 64256, i64 17152, i64 19712, i64 13056, i64 34048, i64 17664, i64 63744, i64 512, i64 32512, i64 20480, i64 15360, i64 40704, i64 43008, i64 20736, i64 41728, i64 16384, i64 36608, i64 37376, i64 40192, i64 14336, i64 62720, i64 48128, i64 46592, i64 55808, i64 8448, i64 4096, i64 65280, i64 62208, i64 53760, i64 52480, i64 3072, i64 4864, i64 60416, i64 24320, i64 38656, i64 17408, i64 5888, i64 50176, i64 42752, i64 32256, i64 15616, i64 25600, i64 23808, i64 6400, i64 29440, i64 24576, i64 33024, i64 20224, i64 56320, i64 8704, i64 10752, i64 36864, i64 34816, i64 17920, i64 60928, i64 47104, i64 5120, i64 56832, i64 24064, i64 2816, i64 56064, i64 57344, i64 12800, i64 14848, i64 2560, i64 18688, i64 1536, i64 9216, i64 23552, i64 49664, i64 54016, i64 44032, i64 25088, i64 37120, i64 38144, i64 58368, i64 30976, i64 59136, i64 51200, i64 14080, i64 27904, i64 36096, i64 54528, i64 19968, i64 43264, i64 27648, i64 22016, i64 62464, i64 59904, i64 25856, i64 31232, i64 44544, i64 2048, i64 47616, i64 30720, i64 9472, i64 11776, i64 7168, i64 42496, i64 46080, i64 50688, i64 59392, i64 56576, i64 29696, i64 7936, i64 19200, i64 48384, i64 35584, i64 35328, i64 28672, i64 15872, i64 46336, i64 26112, i64 18432, i64 768, i64 62976, i64 3584, i64 24832, i64 13568, i64 22272, i64 47360, i64 34304, i64 49408, i64 7424, i64 40448, i64 57600, i64 63488, i64 38912, i64 4352, i64 26880, i64 55552, i64 36352, i64 37888, i64 39680, i64 7680, i64 34560, i64 59648, i64 52736, i64 21760, i64 10240, i64 57088, i64 35840, i64 41216, i64 35072, i64 3328, i64 48896, i64 58880, i64 16896, i64 26624, i64 16640, i64 39168, i64 11520, i64 3840, i64 45056, i64 21504, i64 47872, i64 5632], [256 x i64] [i64 6488064, i64 8126464, i64 7798784, i64 8060928, i64 15859712, i64 7012352, i64 7274496, i64 12910592, i64 3145728, i64 65536, i64 6750208, i64 2818048, i64 16646144, i64 14090240, i64 11206656, i64 7733248, i64 13238272, i64 8519680, i64 13172736, i64 8192000, i64 16384000, i64 5832704, i64 4653056, i64 15728640, i64 11337728, i64 13893632, i64 10616832, i64 11468800, i64 10223616, i64 10747904, i64 7471104, i64 12582912, i64 11993088, i64 16580608, i64 9633792, i64 2490368, i64 3538944, i64 4128768, i64 16187392, i64 13369344, i64 3407872, i64 10813440, i64 15007744, i64 15794176, i64 7405568, i64 14155776, i64 3211264, i64 1376256, i64 262144, i64 13041664, i64 2293760, i64 12779520, i64 1572864, i64 9830400, i64 327680, i64 10092544, i64 458752, i64 1179648, i64 8388608, i64 14811136, i64 15400960, i64 2555904, i64 11665408, i64 7667712, i64 589824, i64 8585216, i64 2883584, i64 1703936, i64 1769472, i64 7208960, i64 5898240, i64 10485760, i64 5373952, i64 3866624, i64 14024704, i64 11730944, i64 2686976, i64 14876672, i64 3080192, i64 8650752, i64 5439488, i64 13697024, i64 0, i64 15532032, i64 2097152, i64 16515072, i64 11599872, i64 5963776, i64 6946816, i64 13303808, i64 12451840, i64 3735552, i64 4849664, i64 4980736, i64 5767168, i64 13565952, i64 13631488, i64 15663104, i64 11141120, i64 16449536, i64 4390912, i64 5046272, i64 3342336, i64 8716288, i64 4521984, i64 16318464, i64 131072, i64 8323072, i64 5242880, i64 3932160, i64 10420224, i64 11010048, i64 5308416, i64 10682368, i64 4194304, i64 9371648, i64 9568256, i64 10289152, i64 3670016, i64 16056320, i64 12320768, i64 11927552, i64 14286848, i64 2162688, i64 1048576, i64 16711680, i64 15925248, i64 13762560, i64 13434880, i64 786432, i64 1245184, i64 15466496, i64 6225920, i64 9895936, i64 4456448, i64 1507328, i64 12845056, i64 10944512, i64 8257536, i64 3997696, i64 6553600, i64 6094848, i64 1638400, i64 7536640, i64 6291456, i64 8454144, i64 5177344, i64 14417920, i64 2228224, i64 2752512, i64 9437184, i64 8912896, i64 4587520, i64 15597568, i64 12058624, i64 1310720, i64 14548992, i64 6160384, i64 720896, i64 14352384, i64 14680064, i64 3276800, i64 3801088, i64 655360, i64 4784128, i64 393216, i64 2359296, i64 6029312, i64 12713984, i64 13828096, i64 11272192, i64 6422528, i64 9502720, i64 9764864, i64 14942208, i64 7929856, i64 15138816, i64 13107200, i64 3604480, i64 7143424, i64 9240576, i64 13959168, i64 5111808, i64 11075584, i64 7077888, i64 5636096, i64 15990784, i64 15335424, i64 6619136, i64 7995392, i64 11403264, i64 524288, i64 12189696, i64 7864320, i64 2424832, i64 3014656, i64 1835008, i64 10878976, i64 11796480, i64 12976128, i64 15204352, i64 14483456, i64 7602176, i64 2031616, i64 4915200, i64 12386304, i64 9109504, i64 9043968, i64 7340032, i64 4063232, i64 11862016, i64 6684672, i64 4718592, i64 196608, i64 16121856, i64 917504, i64 6356992, i64 3473408, i64 5701632, i64 12124160, i64 8781824, i64 12648448, i64 1900544, i64 10354688, i64 14745600, i64 16252928, i64 9961472, i64 1114112, i64 6881280, i64 14221312, i64 9306112, i64 9699328, i64 10158080, i64 1966080, i64 8847360, i64 15269888, i64 13500416, i64 5570560, i64 2621440, i64 14614528, i64 9175040, i64 10551296, i64 8978432, i64 851968, i64 12517376, i64 15073280, i64 4325376, i64 6815744, i64 4259840, i64 10027008, i64 2949120, i64 983040, i64 11534336, i64 5505024, i64 12255232, i64 1441792], [256 x i64] [i64 1660944384, i64 2080374784, i64 1996488704, i64 2063597568, i64 4060086272, i64 1795162112, i64 1862270976, i64 3305111552, i64 805306368, i64 16777216, i64 1728053248, i64 721420288, i64 4261412864, i64 3607101440, i64 2868903936, i64 1979711488, i64 3388997632, i64 2181038080, i64 3372220416, i64 2097152000, i64 4194304000, i64 1493172224, i64 1191182336, i64 4026531840, i64 2902458368, i64 3556769792, i64 2717908992, i64 2936012800, i64 2617245696, i64 2751463424, i64 1912602624, i64 3221225472, i64 3070230528, i64 4244635648, i64 2466250752, i64 637534208, i64 905969664, i64 1056964608, i64 4143972352, i64 3422552064, i64 872415232, i64 2768240640, i64 3841982464, i64 4043309056, i64 1895825408, i64 3623878656, i64 822083584, i64 352321536, i64 67108864, i64 3338665984, i64 587202560, i64 3271557120, i64 402653184, i64 2516582400, i64 83886080, i64 2583691264, i64 117440512, i64 301989888, i64 2147483648, i64 3791650816, i64 3942645760, i64 654311424, i64 2986344448, i64 1962934272, i64 150994944, i64 2197815296, i64 738197504, i64 436207616, i64 452984832, i64 1845493760, i64 1509949440, i64 2684354560, i64 1375731712, i64 989855744, i64 3590324224, i64 3003121664, i64 687865856, i64 3808428032, i64 788529152, i64 2214592512, i64 1392508928, i64 3506438144, i64 0, i64 3976200192, i64 536870912, i64 4227858432, i64 2969567232, i64 1526726656, i64 1778384896, i64 3405774848, i64 3187671040, i64 956301312, i64 1241513984, i64 1275068416, i64 1476395008, i64 3472883712, i64 3489660928, i64 4009754624, i64 2852126720, i64 4211081216, i64 1124073472, i64 1291845632, i64 855638016, i64 2231369728, i64 1157627904, i64 4177526784, i64 33554432, i64 2130706432, i64 1342177280, i64 1006632960, i64 2667577344, i64 2818572288, i64 1358954496, i64 2734686208, i64 1073741824, i64 2399141888, i64 2449473536, i64 2634022912, i64 939524096, i64 4110417920, i64 3154116608, i64 3053453312, i64 3657433088, i64 553648128, i64 268435456, i64 4278190080, i64 4076863488, i64 3523215360, i64 3439329280, i64 201326592, i64 318767104, i64 3959422976, i64 1593835520, i64 2533359616, i64 1140850688, i64 385875968, i64 3288334336, i64 2801795072, i64 2113929216, i64 1023410176, i64 1677721600, i64 1560281088, i64 419430400, i64 1929379840, i64 1610612736, i64 2164260864, i64 1325400064, i64 3690987520, i64 570425344, i64 704643072, i64 2415919104, i64 2281701376, i64 1174405120, i64 3992977408, i64 3087007744, i64 335544320, i64 3724541952, i64 1577058304, i64 184549376, i64 3674210304, i64 3758096384, i64 838860800, i64 973078528, i64 167772160, i64 1224736768, i64 100663296, i64 603979776, i64 1543503872, i64 3254779904, i64 3539992576, i64 2885681152, i64 1644167168, i64 2432696320, i64 2499805184, i64 3825205248, i64 2030043136, i64 3875536896, i64 3355443200, i64 922746880, i64 1828716544, i64 2365587456, i64 3573547008, i64 1308622848, i64 2835349504, i64 1811939328, i64 1442840576, i64 4093640704, i64 3925868544, i64 1694498816, i64 2046820352, i64 2919235584, i64 134217728, i64 3120562176, i64 2013265920, i64 620756992, i64 771751936, i64 469762048, i64 2785017856, i64 3019898880, i64 3321888768, i64 3892314112, i64 3707764736, i64 1946157056, i64 520093696, i64 1258291200, i64 3170893824, i64 2332033024, i64 2315255808, i64 1879048192, i64 1040187392, i64 3036676096, i64 1711276032, i64 1207959552, i64 50331648, i64 4127195136, i64 234881024, i64 1627389952, i64 889192448, i64 1459617792, i64 3103784960, i64 2248146944, i64 3238002688, i64 486539264, i64 2650800128, i64 3774873600, i64 4160749568, i64 2550136832, i64 285212672, i64 1761607680, i64 3640655872, i64 2382364672, i64 2483027968, i64 2600468480, i64 503316480, i64 2264924160, i64 3909091328, i64 3456106496, i64 1426063360, i64 671088640, i64 3741319168, i64 2348810240, i64 2701131776, i64 2298478592, i64 218103808, i64 3204448256, i64 3858759680, i64 1107296256, i64 1744830464, i64 1090519040, i64 2566914048, i64 754974720, i64 251658240, i64 2952790016, i64 1409286144, i64 3137339392, i64 369098752]], align 16
@il_tab = constant [4 x [256 x i64]] [[256 x i64] [i64 82, i64 9, i64 106, i64 213, i64 48, i64 54, i64 165, i64 56, i64 191, i64 64, i64 163, i64 158, i64 129, i64 243, i64 215, i64 251, i64 124, i64 227, i64 57, i64 130, i64 155, i64 47, i64 255, i64 135, i64 52, i64 142, i64 67, i64 68, i64 196, i64 222, i64 233, i64 203, i64 84, i64 123, i64 148, i64 50, i64 166, i64 194, i64 35, i64 61, i64 238, i64 76, i64 149, i64 11, i64 66, i64 250, i64 195, i64 78, i64 8, i64 46, i64 161, i64 102, i64 40, i64 217, i64 36, i64 178, i64 118, i64 91, i64 162, i64 73, i64 109, i64 139, i64 209, i64 37, i64 114, i64 248, i64 246, i64 100, i64 134, i64 104, i64 152, i64 22, i64 212, i64 164, i64 92, i64 204, i64 93, i64 101, i64 182, i64 146, i64 108, i64 112, i64 72, i64 80, i64 253, i64 237, i64 185, i64 218, i64 94, i64 21, i64 70, i64 87, i64 167, i64 141, i64 157, i64 132, i64 144, i64 216, i64 171, i64 0, i64 140, i64 188, i64 211, i64 10, i64 247, i64 228, i64 88, i64 5, i64 184, i64 179, i64 69, i64 6, i64 208, i64 44, i64 30, i64 143, i64 202, i64 63, i64 15, i64 2, i64 193, i64 175, i64 189, i64 3, i64 1, i64 19, i64 138, i64 107, i64 58, i64 145, i64 17, i64 65, i64 79, i64 103, i64 220, i64 234, i64 151, i64 242, i64 207, i64 206, i64 240, i64 180, i64 230, i64 115, i64 150, i64 172, i64 116, i64 34, i64 231, i64 173, i64 53, i64 133, i64 226, i64 249, i64 55, i64 232, i64 28, i64 117, i64 223, i64 110, i64 71, i64 241, i64 26, i64 113, i64 29, i64 41, i64 197, i64 137, i64 111, i64 183, i64 98, i64 14, i64 170, i64 24, i64 190, i64 27, i64 252, i64 86, i64 62, i64 75, i64 198, i64 210, i64 121, i64 32, i64 154, i64 219, i64 192, i64 254, i64 120, i64 205, i64 90, i64 244, i64 31, i64 221, i64 168, i64 51, i64 136, i64 7, i64 199, i64 49, i64 177, i64 18, i64 16, i64 89, i64 39, i64 128, i64 236, i64 95, i64 96, i64 81, i64 127, i64 169, i64 25, i64 181, i64 74, i64 13, i64 45, i64 229, i64 122, i64 159, i64 147, i64 201, i64 156, i64 239, i64 160, i64 224, i64 59, i64 77, i64 174, i64 42, i64 245, i64 176, i64 200, i64 235, i64 187, i64 60, i64 131, i64 83, i64 153, i64 97, i64 23, i64 43, i64 4, i64 126, i64 186, i64 119, i64 214, i64 38, i64 225, i64 105, i64 20, i64 99, i64 85, i64 33, i64 12, i64 125], [256 x i64] [i64 20992, i64 2304, i64 27136, i64 54528, i64 12288, i64 13824, i64 42240, i64 14336, i64 48896, i64 16384, i64 41728, i64 40448, i64 33024, i64 62208, i64 55040, i64 64256, i64 31744, i64 58112, i64 14592, i64 33280, i64 39680, i64 12032, i64 65280, i64 34560, i64 13312, i64 36352, i64 17152, i64 17408, i64 50176, i64 56832, i64 59648, i64 51968, i64 21504, i64 31488, i64 37888, i64 12800, i64 42496, i64 49664, i64 8960, i64 15616, i64 60928, i64 19456, i64 38144, i64 2816, i64 16896, i64 64000, i64 49920, i64 19968, i64 2048, i64 11776, i64 41216, i64 26112, i64 10240, i64 55552, i64 9216, i64 45568, i64 30208, i64 23296, i64 41472, i64 18688, i64 27904, i64 35584, i64 53504, i64 9472, i64 29184, i64 63488, i64 62976, i64 25600, i64 34304, i64 26624, i64 38912, i64 5632, i64 54272, i64 41984, i64 23552, i64 52224, i64 23808, i64 25856, i64 46592, i64 37376, i64 27648, i64 28672, i64 18432, i64 20480, i64 64768, i64 60672, i64 47360, i64 55808, i64 24064, i64 5376, i64 17920, i64 22272, i64 42752, i64 36096, i64 40192, i64 33792, i64 36864, i64 55296, i64 43776, i64 0, i64 35840, i64 48128, i64 54016, i64 2560, i64 63232, i64 58368, i64 22528, i64 1280, i64 47104, i64 45824, i64 17664, i64 1536, i64 53248, i64 11264, i64 7680, i64 36608, i64 51712, i64 16128, i64 3840, i64 512, i64 49408, i64 44800, i64 48384, i64 768, i64 256, i64 4864, i64 35328, i64 27392, i64 14848, i64 37120, i64 4352, i64 16640, i64 20224, i64 26368, i64 56320, i64 59904, i64 38656, i64 61952, i64 52992, i64 52736, i64 61440, i64 46080, i64 58880, i64 29440, i64 38400, i64 44032, i64 29696, i64 8704, i64 59136, i64 44288, i64 13568, i64 34048, i64 57856, i64 63744, i64 14080, i64 59392, i64 7168, i64 29952, i64 57088, i64 28160, i64 18176, i64 61696, i64 6656, i64 28928, i64 7424, i64 10496, i64 50432, i64 35072, i64 28416, i64 46848, i64 25088, i64 3584, i64 43520, i64 6144, i64 48640, i64 6912, i64 64512, i64 22016, i64 15872, i64 19200, i64 50688, i64 53760, i64 30976, i64 8192, i64 39424, i64 56064, i64 49152, i64 65024, i64 30720, i64 52480, i64 23040, i64 62464, i64 7936, i64 56576, i64 43008, i64 13056, i64 34816, i64 1792, i64 50944, i64 12544, i64 45312, i64 4608, i64 4096, i64 22784, i64 9984, i64 32768, i64 60416, i64 24320, i64 24576, i64 20736, i64 32512, i64 43264, i64 6400, i64 46336, i64 18944, i64 3328, i64 11520, i64 58624, i64 31232, i64 40704, i64 37632, i64 51456, i64 39936, i64 61184, i64 40960, i64 57344, i64 15104, i64 19712, i64 44544, i64 10752, i64 62720, i64 45056, i64 51200, i64 60160, i64 47872, i64 15360, i64 33536, i64 21248, i64 39168, i64 24832, i64 5888, i64 11008, i64 1024, i64 32256, i64 47616, i64 30464, i64 54784, i64 9728, i64 57600, i64 26880, i64 5120, i64 25344, i64 21760, i64 8448, i64 3072, i64 32000], [256 x i64] [i64 5373952, i64 589824, i64 6946816, i64 13959168, i64 3145728, i64 3538944, i64 10813440, i64 3670016, i64 12517376, i64 4194304, i64 10682368, i64 10354688, i64 8454144, i64 15925248, i64 14090240, i64 16449536, i64 8126464, i64 14876672, i64 3735552, i64 8519680, i64 10158080, i64 3080192, i64 16711680, i64 8847360, i64 3407872, i64 9306112, i64 4390912, i64 4456448, i64 12845056, i64 14548992, i64 15269888, i64 13303808, i64 5505024, i64 8060928, i64 9699328, i64 3276800, i64 10878976, i64 12713984, i64 2293760, i64 3997696, i64 15597568, i64 4980736, i64 9764864, i64 720896, i64 4325376, i64 16384000, i64 12779520, i64 5111808, i64 524288, i64 3014656, i64 10551296, i64 6684672, i64 2621440, i64 14221312, i64 2359296, i64 11665408, i64 7733248, i64 5963776, i64 10616832, i64 4784128, i64 7143424, i64 9109504, i64 13697024, i64 2424832, i64 7471104, i64 16252928, i64 16121856, i64 6553600, i64 8781824, i64 6815744, i64 9961472, i64 1441792, i64 13893632, i64 10747904, i64 6029312, i64 13369344, i64 6094848, i64 6619136, i64 11927552, i64 9568256, i64 7077888, i64 7340032, i64 4718592, i64 5242880, i64 16580608, i64 15532032, i64 12124160, i64 14286848, i64 6160384, i64 1376256, i64 4587520, i64 5701632, i64 10944512, i64 9240576, i64 10289152, i64 8650752, i64 9437184, i64 14155776, i64 11206656, i64 0, i64 9175040, i64 12320768, i64 13828096, i64 655360, i64 16187392, i64 14942208, i64 5767168, i64 327680, i64 12058624, i64 11730944, i64 4521984, i64 393216, i64 13631488, i64 2883584, i64 1966080, i64 9371648, i64 13238272, i64 4128768, i64 983040, i64 131072, i64 12648448, i64 11468800, i64 12386304, i64 196608, i64 65536, i64 1245184, i64 9043968, i64 7012352, i64 3801088, i64 9502720, i64 1114112, i64 4259840, i64 5177344, i64 6750208, i64 14417920, i64 15335424, i64 9895936, i64 15859712, i64 13565952, i64 13500416, i64 15728640, i64 11796480, i64 15073280, i64 7536640, i64 9830400, i64 11272192, i64 7602176, i64 2228224, i64 15138816, i64 11337728, i64 3473408, i64 8716288, i64 14811136, i64 16318464, i64 3604480, i64 15204352, i64 1835008, i64 7667712, i64 14614528, i64 7208960, i64 4653056, i64 15794176, i64 1703936, i64 7405568, i64 1900544, i64 2686976, i64 12910592, i64 8978432, i64 7274496, i64 11993088, i64 6422528, i64 917504, i64 11141120, i64 1572864, i64 12451840, i64 1769472, i64 16515072, i64 5636096, i64 4063232, i64 4915200, i64 12976128, i64 13762560, i64 7929856, i64 2097152, i64 10092544, i64 14352384, i64 12582912, i64 16646144, i64 7864320, i64 13434880, i64 5898240, i64 15990784, i64 2031616, i64 14483456, i64 11010048, i64 3342336, i64 8912896, i64 458752, i64 13041664, i64 3211264, i64 11599872, i64 1179648, i64 1048576, i64 5832704, i64 2555904, i64 8388608, i64 15466496, i64 6225920, i64 6291456, i64 5308416, i64 8323072, i64 11075584, i64 1638400, i64 11862016, i64 4849664, i64 851968, i64 2949120, i64 15007744, i64 7995392, i64 10420224, i64 9633792, i64 13172736, i64 10223616, i64 15663104, i64 10485760, i64 14680064, i64 3866624, i64 5046272, i64 11403264, i64 2752512, i64 16056320, i64 11534336, i64 13107200, i64 15400960, i64 12255232, i64 3932160, i64 8585216, i64 5439488, i64 10027008, i64 6356992, i64 1507328, i64 2818048, i64 262144, i64 8257536, i64 12189696, i64 7798784, i64 14024704, i64 2490368, i64 14745600, i64 6881280, i64 1310720, i64 6488064, i64 5570560, i64 2162688, i64 786432, i64 8192000], [256 x i64] [i64 1375731712, i64 150994944, i64 1778384896, i64 3573547008, i64 805306368, i64 905969664, i64 2768240640, i64 939524096, i64 3204448256, i64 1073741824, i64 2734686208, i64 2650800128, i64 2164260864, i64 4076863488, i64 3607101440, i64 4211081216, i64 2080374784, i64 3808428032, i64 956301312, i64 2181038080, i64 2600468480, i64 788529152, i64 4278190080, i64 2264924160, i64 872415232, i64 2382364672, i64 1124073472, i64 1140850688, i64 3288334336, i64 3724541952, i64 3909091328, i64 3405774848, i64 1409286144, i64 2063597568, i64 2483027968, i64 838860800, i64 2785017856, i64 3254779904, i64 587202560, i64 1023410176, i64 3992977408, i64 1275068416, i64 2499805184, i64 184549376, i64 1107296256, i64 4194304000, i64 3271557120, i64 1308622848, i64 134217728, i64 771751936, i64 2701131776, i64 1711276032, i64 671088640, i64 3640655872, i64 603979776, i64 2986344448, i64 1979711488, i64 1526726656, i64 2717908992, i64 1224736768, i64 1828716544, i64 2332033024, i64 3506438144, i64 620756992, i64 1912602624, i64 4160749568, i64 4127195136, i64 1677721600, i64 2248146944, i64 1744830464, i64 2550136832, i64 369098752, i64 3556769792, i64 2751463424, i64 1543503872, i64 3422552064, i64 1560281088, i64 1694498816, i64 3053453312, i64 2449473536, i64 1811939328, i64 1879048192, i64 1207959552, i64 1342177280, i64 4244635648, i64 3976200192, i64 3103784960, i64 3657433088, i64 1577058304, i64 352321536, i64 1174405120, i64 1459617792, i64 2801795072, i64 2365587456, i64 2634022912, i64 2214592512, i64 2415919104, i64 3623878656, i64 2868903936, i64 0, i64 2348810240, i64 3154116608, i64 3539992576, i64 167772160, i64 4143972352, i64 3825205248, i64 1476395008, i64 83886080, i64 3087007744, i64 3003121664, i64 1157627904, i64 100663296, i64 3489660928, i64 738197504, i64 503316480, i64 2399141888, i64 3388997632, i64 1056964608, i64 251658240, i64 33554432, i64 3238002688, i64 2936012800, i64 3170893824, i64 50331648, i64 16777216, i64 318767104, i64 2315255808, i64 1795162112, i64 973078528, i64 2432696320, i64 285212672, i64 1090519040, i64 1325400064, i64 1728053248, i64 3690987520, i64 3925868544, i64 2533359616, i64 4060086272, i64 3472883712, i64 3456106496, i64 4026531840, i64 3019898880, i64 3858759680, i64 1929379840, i64 2516582400, i64 2885681152, i64 1946157056, i64 570425344, i64 3875536896, i64 2902458368, i64 889192448, i64 2231369728, i64 3791650816, i64 4177526784, i64 922746880, i64 3892314112, i64 469762048, i64 1962934272, i64 3741319168, i64 1845493760, i64 1191182336, i64 4043309056, i64 436207616, i64 1895825408, i64 486539264, i64 687865856, i64 3305111552, i64 2298478592, i64 1862270976, i64 3070230528, i64 1644167168, i64 234881024, i64 2852126720, i64 402653184, i64 3187671040, i64 452984832, i64 4227858432, i64 1442840576, i64 1040187392, i64 1258291200, i64 3321888768, i64 3523215360, i64 2030043136, i64 536870912, i64 2583691264, i64 3674210304, i64 3221225472, i64 4261412864, i64 2013265920, i64 3439329280, i64 1509949440, i64 4093640704, i64 520093696, i64 3707764736, i64 2818572288, i64 855638016, i64 2281701376, i64 117440512, i64 3338665984, i64 822083584, i64 2969567232, i64 301989888, i64 268435456, i64 1493172224, i64 654311424, i64 2147483648, i64 3959422976, i64 1593835520, i64 1610612736, i64 1358954496, i64 2130706432, i64 2835349504, i64 419430400, i64 3036676096, i64 1241513984, i64 218103808, i64 754974720, i64 3841982464, i64 2046820352, i64 2667577344, i64 2466250752, i64 3372220416, i64 2617245696, i64 4009754624, i64 2684354560, i64 3758096384, i64 989855744, i64 1291845632, i64 2919235584, i64 704643072, i64 4110417920, i64 2952790016, i64 3355443200, i64 3942645760, i64 3137339392, i64 1006632960, i64 2197815296, i64 1392508928, i64 2566914048, i64 1627389952, i64 385875968, i64 721420288, i64 67108864, i64 2113929216, i64 3120562176, i64 1996488704, i64 3590324224, i64 637534208, i64 3774873600, i64 1761607680, i64 335544320, i64 1660944384, i64 1426063360, i64 553648128, i64 201326592, i64 2097152000]], align 16
@im_tab = constant [4 x [256 x i64]] [[256 x i64] [i64 0, i64 185403662, i64 370807324, i64 488053522, i64 741614648, i64 658058550, i64 976107044, i64 824393514, i64 1483229296, i64 1399144830, i64 1316117100, i64 1165972322, i64 1952214088, i64 2136040774, i64 1648787028, i64 1766553434, i64 2966458592, i64 3151862254, i64 2798289660, i64 2915535858, i64 2632234200, i64 2548678102, i64 2331944644, i64 2180231114, i64 3904428176, i64 3820343710, i64 4272081548, i64 4121936770, i64 3297574056, i64 3481400742, i64 3533106868, i64 3650873274, i64 2075868123, i64 1890988757, i64 1839278535, i64 1722556617, i64 1468997603, i64 1552029421, i64 1100287487, i64 1251476721, i64 601060267, i64 685669029, i64 902390199, i64 1053059257, i64 266819475, i64 82468509, i64 436028815, i64 317738113, i64 3412831035, i64 3227951669, i64 3715217703, i64 3598495785, i64 3881799427, i64 3964831245, i64 4047871263, i64 4199060497, i64 2466505547, i64 2551114309, i64 2233069911, i64 2383738969, i64 3208103795, i64 3023752829, i64 2838353263, i64 2720062561, i64 4134368941, i64 4250959779, i64 3765920945, i64 3950669247, i64 3663286933, i64 3511966619, i64 3426959497, i64 3343796615, i64 2919579357, i64 2768779219, i64 3089050817, i64 3004310991, i64 2184256229, i64 2302415851, i64 2485848313, i64 2670068215, i64 1186850381, i64 1303441219, i64 1353184337, i64 1537932639, i64 1787413109, i64 1636092795, i64 2090061929, i64 2006899047, i64 517320253, i64 366520115, i64 147831841, i64 63092015, i64 853641733, i64 971801355, i64 620468249, i64 804688151, i64 2379631990, i64 2262516856, i64 2613862250, i64 2428589668, i64 2715969870, i64 2867814464, i64 3086515026, i64 3170202204, i64 3586000134, i64 3736275976, i64 3282310938, i64 3366526484, i64 4186579262, i64 4068943920, i64 4019204898, i64 3835509292, i64 1023860118, i64 906744984, i64 723308426, i64 538035844, i64 288553390, i64 440397984, i64 120122290, i64 203809468, i64 1701746150, i64 1852021992, i64 1937016826, i64 2021232372, i64 1230680542, i64 1113045200, i64 1598071746, i64 1414376140, i64 4158319681, i64 4242007375, i64 3787521629, i64 3939366739, i64 3689859193, i64 3504587127, i64 3455375973, i64 3338261355, i64 2947720241, i64 2764025151, i64 3114841645, i64 2997206819, i64 2206629897, i64 2290845959, i64 2510066197, i64 2660342555, i64 1191869601, i64 1275557295, i64 1360031421, i64 1511876531, i64 1799248025, i64 1613975959, i64 2099530373, i64 1982415755, i64 526529745, i64 342834655, i64 158869197, i64 41234371, i64 861278441, i64 945494503, i64 625738485, i64 776014843, i64 2355222426, i64 2272059028, i64 2591802758, i64 2440481928, i64 2689987490, i64 2874735276, i64 3058688446, i64 3175278768, i64 3557400554, i64 3741619940, i64 3256061430, i64 3374220536, i64 4164795346, i64 4080055004, i64 3995576782, i64 3844776128, i64 1018251130, i64 935087732, i64 715871590, i64 564550760, i64 277177154, i64 461924940, i64 111112542, i64 227702864, i64 1691946762, i64 1876166148, i64 1925389590, i64 2043548696, i64 1223502642, i64 1138762300, i64 1593260334, i64 1442459680, i64 28809964, i64 179999714, i64 397248752, i64 480281086, i64 763608788, i64 646887386, i64 999926984, i64 815048134, i64 1507840668, i64 1389550482, i64 1338359936, i64 1154009486, i64 1978398372, i64 2129067946, i64 1676797112, i64 1761406390, i64 2976320012, i64 3127509762, i64 2809993232, i64 2893025566, i64 2639474228, i64 2522752826, i64 2336832552, i64 2151953702, i64 3910091388, i64 3791801202, i64 4279586912, i64 4095236462, i64 3309004356, i64 3459673930, i64 3542185048, i64 3626794326, i64 2047648055, i64 1895934009, i64 1813426987, i64 1729870373, i64 1446544655, i64 1563790337, i64 1076008723, i64 1261411869, i64 577038663, i64 694804553, i64 880737115, i64 1064563285, i64 240176511, i64 90031217, i64 407560035, i64 323475053, i64 3403428311, i64 3251714265, i64 3703972811, i64 3620416197, i64 3873969647, i64 3991215329, i64 4042393587, i64 4227796733, i64 2461301159, i64 2579067049, i64 2226023355, i64 2409849525, i64 3196083615, i64 3045938321, i64 2828685187, i64 2744600205], [256 x i64] [i64 0, i64 218697227, i64 437394454, i64 387650077, i64 874788908, i64 959264295, i64 775300154, i64 591342129, i64 1749577816, i64 1698790995, i64 1918528590, i64 2136171077, i64 1550600308, i64 1365591679, i64 1182684258, i64 1266113129, i64 3499155632, i64 3717852859, i64 3397581990, i64 3347837613, i64 3837057180, i64 3921532567, i64 4272342154, i64 4088384129, i64 3101200616, i64 3050413795, i64 2731183358, i64 2948825845, i64 2365368516, i64 2180359887, i64 2532226258, i64 2615655129, i64 3141262203, i64 3056784752, i64 2703869805, i64 2887829862, i64 2401231703, i64 2182540636, i64 2500722497, i64 2550460746, i64 3547573027, i64 3732579624, i64 3378624309, i64 3295197502, i64 3881276175, i64 3932069124, i64 4249194265, i64 4031545618, i64 1806384075, i64 1721906624, i64 1907959773, i64 2091919830, i64 1603208167, i64 1384517100, i64 1167925233, i64 1217663482, i64 65227667, i64 250234264, i64 435246981, i64 351820174, i64 935818175, i64 986611124, i64 768962473, i64 551313826, i64 1836494326, i64 1618977789, i64 2003087840, i64 2054012907, i64 1498584538, i64 1415289809, i64 1128303052, i64 1313441735, i64 88006062, i64 137876389, i64 523026872, i64 304467891, i64 823846274, i64 1007938441, i64 722008468, i64 637663135, i64 3185986886, i64 2968470349, i64 2817806672, i64 2868731739, i64 2311222634, i64 2227927905, i64 2479909244, i64 2665047927, i64 3584965918, i64 3634836245, i64 3485212936, i64 3266653955, i64 3783918898, i64 3968011065, i64 4221049124, i64 4136703791, i64 3595400845, i64 3678697606, i64 3428805275, i64 3243664528, i64 3798552225, i64 4016062634, i64 4168831671, i64 4117912764, i64 3188000469, i64 3003910366, i64 2752977603, i64 2837320904, i64 2317434617, i64 2267558130, i64 2419270383, i64 2637835492, i64 115185213, i64 198481974, i64 483363371, i64 298222624, i64 855223825, i64 1072734234, i64 686535175, i64 635616268, i64 1855317605, i64 1671227502, i64 1955068531, i64 2039411832, i64 1521606217, i64 1471729730, i64 1084473951, i64 1303039060, i64 3672916471, i64 3622129660, i64 3237895649, i64 3455538154, i64 4006115803, i64 3821107152, i64 4107953613, i64 4191382470, i64 2997105071, i64 3215802276, i64 2830511545, i64 2780767154, i64 2256537987, i64 2341013384, i64 2626819477, i64 2442861470, i64 175939911, i64 125153100, i64 275692881, i64 493335386, i64 1045993835, i64 860985184, i64 608863613, i64 692292470, i64 1647628575, i64 1866325780, i64 2015808777, i64 1966064386, i64 1443948851, i64 1528424248, i64 1275262245, i64 1091304238, i64 1641519756, i64 1826526343, i64 2076542618, i64 1993115793, i64 1442030240, i64 1492823211, i64 1340194486, i64 1122545853, i64 161475284, i64 76997855, i64 328070850, i64 512030921, i64 1035719416, i64 817028339, i64 665439982, i64 715178213, i64 2974251580, i64 3159258167, i64 2874500650, i64 2791073825, i64 2237874704, i64 2288667675, i64 2675006982, i64 2457358349, i64 3641641572, i64 3557164143, i64 3273463410, i64 3457423481, i64 3979031112, i64 3760340035, i64 4147719774, i64 4197458005, i64 3080383489, i64 3130253834, i64 2911432727, i64 2692873756, i64 2210321453, i64 2394413606, i64 2578237499, i64 2493892144, i64 3755121753, i64 3537605202, i64 3317727311, i64 3368652356, i64 3958809717, i64 3875515006, i64 4058298467, i64 4243437160, i64 1728711857, i64 1778582202, i64 2098729127, i64 1880170156, i64 1395537053, i64 1579629206, i64 1228679307, i64 1144333952, i64 256015593, i64 38499042, i64 357589247, i64 408514292, i64 996558021, i64 913263310, i64 561273043, i64 746411736, i64 211892090, i64 27801969, i64 380840812, i64 465184103, i64 948244310, i64 898367837, i64 580326208, i64 798891339, i64 1693009698, i64 1776306473, i64 2130402100, i64 1945261375, i64 1355644686, i64 1573155077, i64 1256153880, i64 1205234963, i64 3694254026, i64 3510163905, i64 3324234716, i64 3408578007, i64 3893751782, i64 3843875309, i64 4060607472, i64 4279172603, i64 3027871634, i64 3111168409, i64 2926295940, i64 2741155215, i64 2153619390, i64 2371129781, i64 2588902312, i64 2537983395], [256 x i64] [i64 0, i64 151915277, i64 303830554, i64 454171927, i64 607661108, i64 758523705, i64 908343854, i64 1059729699, i64 1215322216, i64 1098797925, i64 1517047410, i64 1398949247, i64 1816687708, i64 1699118929, i64 2119459398, i64 2002413899, i64 2430644432, i64 2582559709, i64 2197595850, i64 2347937223, i64 3034094820, i64 3184957417, i64 2797898494, i64 2949284339, i64 3633375416, i64 3516851125, i64 3398237858, i64 3280139695, i64 4238918796, i64 4121350017, i64 4004827798, i64 3887782299, i64 1004239803, i64 852848822, i64 700935585, i64 550069932, i64 534992783, i64 384654466, i64 234832277, i64 82922136, i64 1940595667, i64 2057644254, i64 1639396809, i64 1756970692, i64 1469255655, i64 1587348714, i64 1167006205, i64 1283527408, i64 2872822635, i64 2721431654, i64 3106397553, i64 2955531900, i64 2399397727, i64 2249059410, i64 2636116293, i64 2484206152, i64 3813380867, i64 3930429454, i64 4049044761, i64 4166618644, i64 3346251575, i64 3464344634, i64 3580864813, i64 3697386016, i64 1991112301, i64 2141453664, i64 1689378935, i64 1841294202, i64 1385552473, i64 1536938324, i64 1082772547, i64 1233635150, i64 1054715397, i64 936617224, i64 750893087, i64 634368786, i64 451248689, i64 334203196, i64 150574123, i64 33005350, i64 3863824061, i64 4014165424, i64 4098969767, i64 4250885034, i64 3262474889, i64 3413860740, i64 3496574099, i64 3647436702, i64 2923241173, i64 2805143000, i64 3156281551, i64 3039757250, i64 2315596513, i64 2198551020, i64 2551784699, i64 2434215926, i64 1299615190, i64 1148749531, i64 1600822220, i64 1449431233, i64 1766760930, i64 1614850799, i64 2069018616, i64 1918680309, i64 84334014, i64 201907891, i64 387629988, i64 504678569, i64 557775242, i64 674296455, i64 857927568, i64 976020637, i64 3717610758, i64 3566745099, i64 3481938716, i64 3330547729, i64 4188934450, i64 4037024319, i64 3954313000, i64 3803974693, i64 2514904430, i64 2632478307, i64 2281337716, i64 2398386297, i64 2984135002, i64 3100656215, i64 2747424576, i64 2865517645, i64 3963746266, i64 3847224535, i64 4267565504, i64 4149471949, i64 3363429358, i64 3245854947, i64 3664104948, i64 3547055865, i64 2754719666, i64 2906629311, i64 3056449960, i64 3206787749, i64 2148107142, i64 2298972299, i64 2450888092, i64 2602278545, i64 2090944266, i64 1974422535, i64 1857900816, i64 1739807261, i64 1486449470, i64 1368875059, i64 1250262308, i64 1133213225, i64 886120290, i64 1038029935, i64 650971512, i64 801309301, i64 283718486, i64 434583643, i64 49620300, i64 201010753, i64 3617229921, i64 3734275948, i64 3313932923, i64 3431502198, i64 4087521365, i64 4205620056, i64 3787372111, i64 3903896898, i64 2682967049, i64 2531581700, i64 2381758995, i64 2230896926, i64 3151165501, i64 3000824624, i64 2848910887, i64 2696996138, i64 1199193265, i64 1316239292, i64 1432758955, i64 1550328230, i64 1665273989, i64 1783372680, i64 1901987487, i64 2018512274, i64 252339417, i64 100954068, i64 488010435, i64 337148366, i64 724715757, i64 574374880, i64 959340279, i64 807425530, i64 2599158199, i64 2481064634, i64 2297436077, i64 2180914336, i64 3201576323, i64 3084527246, i64 2898803609, i64 2781229204, i64 3533461983, i64 3683799762, i64 3229634501, i64 3381544136, i64 4137973227, i64 4289363686, i64 3837289457, i64 3988154620, i64 168604007, i64 50510442, i64 403744637, i64 287222896, i64 775200083, i64 658151006, i64 1009290057, i64 891715652, i64 1115482383, i64 1265820162, i64 1348534037, i64 1500443672, i64 1715782971, i64 1867173430, i64 1951978273, i64 2102843436, i64 2704767500, i64 2822336769, i64 3005967382, i64 3123013403, i64 2232374840, i64 2348899637, i64 2534621218, i64 2652719919, i64 3913753188, i64 3762891113, i64 4217058430, i64 4065673075, i64 3447656016, i64 3295741277, i64 3747813450, i64 3597472583, i64 836225756, i64 953795025, i64 600562886, i64 717608907, i64 368043752, i64 484568549, i64 133427442, i64 251526143, i64 2041025204, i64 1890163129, i64 1807451310, i64 1656065955, i64 1570750080, i64 1418835341, i64 1334028442, i64 1183687575], [256 x i64] [i64 0, i64 235605257, i64 471210514, i64 303896347, i64 942421028, i64 908540205, i64 607792694, i64 707863359, i64 1884842056, i64 2119394625, i64 1817080410, i64 1648721747, i64 1215585388, i64 1182749029, i64 1415726718, i64 1516850039, i64 3769684112, i64 4005289369, i64 4238789250, i64 4071475083, i64 3634160820, i64 3600279997, i64 3297443494, i64 3397514159, i64 2431170776, i64 2665723345, i64 2365498058, i64 2197139395, i64 2831453436, i64 2798617077, i64 3033700078, i64 3134823399, i64 3682319163, i64 3580933682, i64 3345850665, i64 3378949152, i64 3814166303, i64 3982262806, i64 4282488077, i64 4048197636, i64 2871251827, i64 2770919034, i64 3073755489, i64 3107898472, i64 2467293015, i64 2634345054, i64 2400845125, i64 2165502028, i64 1003187115, i64 901801634, i64 668823993, i64 701922480, i64 65494927, i64 233591430, i64 535905693, i64 301615252, i64 1267925987, i64 1167593194, i64 1468340721, i64 1502483704, i64 1941911495, i64 2108963534, i64 1873358293, i64 1638015196, i64 2918608246, i64 2751291519, i64 2984277860, i64 3219880557, i64 2514114898, i64 2614187099, i64 2311865152, i64 2277985865, i64 3719169342, i64 3550808119, i64 3250069292, i64 3484619301, i64 3850514714, i64 3951639571, i64 4187237128, i64 4154402305, i64 1296481766, i64 1129165039, i64 1364240372, i64 1599843069, i64 1969916354, i64 2069988555, i64 1769771984, i64 1735892697, i64 1025430958, i64 857069735, i64 554225596, i64 788775605, i64 87220618, i64 188345475, i64 421854104, i64 389019281, i64 1989006925, i64 2022103876, i64 1788595295, i64 1687208278, i64 1319232105, i64 1084944224, i64 1387788411, i64 1555887474, i64 114671109, i64 148812556, i64 449029143, i64 348694814, i64 1056541217, i64 821200680, i64 586125363, i64 753179962, i64 2520581853, i64 2553678804, i64 2318081231, i64 2216694214, i64 2920362745, i64 2686074864, i64 2986813675, i64 3154912738, i64 3865407125, i64 3899548572, i64 4201870471, i64 4101536142, i64 3729349297, i64 3494008760, i64 3261022371, i64 3428076970, i64 1106762476, i64 1341970405, i64 1575076094, i64 1407897079, i64 2044456648, i64 2010178497, i64 1707996378, i64 1808202195, i64 833598116, i64 1067761581, i64 767142070, i64 598910399, i64 159614592, i64 126389129, i64 362126482, i64 463376795, i64 2705787516, i64 2940995445, i64 3176206446, i64 3009027431, i64 2573942360, i64 2539664209, i64 2239571018, i64 2339776835, i64 3508494900, i64 3742658365, i64 3439949862, i64 3271718191, i64 3912455696, i64 3879230233, i64 4112862210, i64 4214112523, i64 2592891351, i64 2491903198, i64 2258271173, i64 2291234508, i64 2728416755, i64 2896910586, i64 3199619041, i64 2965193448, i64 3939764639, i64 3839820950, i64 4139914125, i64 4173930116, i64 3539484091, i64 3706925234, i64 3471714217, i64 3236244128, i64 2050797895, i64 1949809742, i64 1714072405, i64 1747035740, i64 1108378979, i64 1276872810, i64 1577492337, i64 1343066744, i64 174381327, i64 74437638, i64 376619805, i64 410635796, i64 843640107, i64 1011081250, i64 777975609, i64 542505520, i64 3959535514, i64 3792353939, i64 4028083592, i64 4263288961, i64 3559752638, i64 3659959991, i64 3359349164, i64 3325072549, i64 2623135698, i64 2454901467, i64 2152711616, i64 2386872521, i64 2759191542, i64 2860443391, i64 3093557732, i64 3060333805, i64 212952842, i64 45771267, i64 279411992, i64 514617361, i64 882725678, i64 982933031, i64 680216892, i64 645940277, i64 2095648578, i64 1927414347, i64 1627329872, i64 1861490777, i64 1153776486, i64 1255028335, i64 1490231668, i64 1457007741, i64 930745505, i64 963707304, i64 728503987, i64 627514298, i64 257308805, i64 22885772, i64 322970263, i64 491466654, i64 1193436393, i64 1227450848, i64 1530167035, i64 1430221810, i64 2131644621, i64 1896177092, i64 1662536415, i64 1829980118, i64 3620396081, i64 3653357880, i64 3420243491, i64 3319253802, i64 4024887317, i64 3790464284, i64 4092654087, i64 4261150478, i64 2811409529, i64 2845423984, i64 3146034795, i64 3046089570, i64 2680062045, i64 2444594516, i64 2208864847, i64 2376308550]], align 16

; Function Attrs: nounwind uwtable
define signext i16 @set_key(i8* %in_key, i64 %n_bytes, i32 %f, %struct.aes* %cx) #0 {
entry:
  %retval = alloca i16, align 2
  %in_key.addr = alloca i8*, align 8
  %n_bytes.addr = alloca i64, align 8
  %f.addr = alloca i32, align 4
  %cx.addr = alloca %struct.aes*, align 8
  %kf = alloca i64*, align 8
  %kt = alloca i64*, align 8
  %rci = alloca i64, align 8
  %i = alloca i64, align 8
  store i8* %in_key, i8** %in_key.addr, align 8
  store i64 %n_bytes, i64* %n_bytes.addr, align 8
  store i32 %f, i32* %f.addr, align 4
  store %struct.aes* %cx, %struct.aes** %cx.addr, align 8
  %0 = load i64, i64* %n_bytes.addr, align 8
  %and = and i64 %0, 7
  %tobool = icmp ne i64 %and, 0
  br i1 %tobool, label %if.then, label %lor.lhs.false

lor.lhs.false:                                    ; preds = %entry
  %1 = load i64, i64* %n_bytes.addr, align 8
  %cmp = icmp ult i64 %1, 16
  br i1 %cmp, label %if.then, label %lor.lhs.false1

lor.lhs.false1:                                   ; preds = %lor.lhs.false
  %2 = load i64, i64* %n_bytes.addr, align 8
  %cmp2 = icmp ugt i64 %2, 32
  br i1 %cmp2, label %if.then, label %lor.lhs.false3

lor.lhs.false3:                                   ; preds = %lor.lhs.false1
  %3 = load i32, i32* %f.addr, align 4
  %and4 = and i32 %3, 1
  %tobool5 = icmp ne i32 %and4, 0
  br i1 %tobool5, label %if.end, label %land.lhs.true

land.lhs.true:                                    ; preds = %lor.lhs.false3
  %4 = load i32, i32* %f.addr, align 4
  %and6 = and i32 %4, 2
  %tobool7 = icmp ne i32 %and6, 0
  br i1 %tobool7, label %if.end, label %if.then

if.then:                                          ; preds = %land.lhs.true, %lor.lhs.false1, %lor.lhs.false, %entry
  %5 = load i64, i64* %n_bytes.addr, align 8
  %tobool8 = icmp ne i64 %5, 0
  br i1 %tobool8, label %cond.true, label %cond.false

cond.true:                                        ; preds = %if.then
  %6 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %mode = getelementptr inbounds %struct.aes, %struct.aes* %6, i32 0, i32 4
  %7 = load i8, i8* %mode, align 8
  %conv = zext i8 %7 to i32
  %and9 = and i32 %conv, -4
  %conv10 = trunc i32 %and9 to i8
  store i8 %conv10, i8* %mode, align 8
  br label %cond.end

cond.false:                                       ; preds = %if.then
  %8 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %Nkey = getelementptr inbounds %struct.aes, %struct.aes* %8, i32 0, i32 0
  %9 = load i64, i64* %Nkey, align 8
  %shl = shl i64 %9, 2
  %conv11 = trunc i64 %shl to i16
  %conv12 = sext i16 %conv11 to i32
  br label %cond.end

cond.end:                                         ; preds = %cond.false, %cond.true
  %cond = phi i32 [ 0, %cond.true ], [ %conv12, %cond.false ]
  %conv13 = trunc i32 %cond to i16
  store i16 %conv13, i16* %retval, align 2
  br label %return

if.end:                                           ; preds = %land.lhs.true, %lor.lhs.false3
  %10 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %mode14 = getelementptr inbounds %struct.aes, %struct.aes* %10, i32 0, i32 4
  %11 = load i8, i8* %mode14, align 8
  %conv15 = zext i8 %11 to i32
  %and16 = and i32 %conv15, -4
  %12 = load i32, i32* %f.addr, align 4
  %conv17 = trunc i32 %12 to i8
  %conv18 = zext i8 %conv17 to i32
  %and19 = and i32 %conv18, 3
  %or = or i32 %and16, %and19
  %conv20 = trunc i32 %or to i8
  %13 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %mode21 = getelementptr inbounds %struct.aes, %struct.aes* %13, i32 0, i32 4
  store i8 %conv20, i8* %mode21, align 8
  %14 = load i64, i64* %n_bytes.addr, align 8
  %shr = lshr i64 %14, 2
  %15 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %Nkey22 = getelementptr inbounds %struct.aes, %struct.aes* %15, i32 0, i32 0
  store i64 %shr, i64* %Nkey22, align 8
  %16 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %Nkey23 = getelementptr inbounds %struct.aes, %struct.aes* %16, i32 0, i32 0
  %17 = load i64, i64* %Nkey23, align 8
  %cmp24 = icmp ugt i64 %17, 4
  br i1 %cmp24, label %cond.true26, label %cond.false28

cond.true26:                                      ; preds = %if.end
  %18 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %Nkey27 = getelementptr inbounds %struct.aes, %struct.aes* %18, i32 0, i32 0
  %19 = load i64, i64* %Nkey27, align 8
  br label %cond.end29

cond.false28:                                     ; preds = %if.end
  br label %cond.end29

cond.end29:                                       ; preds = %cond.false28, %cond.true26
  %cond30 = phi i64 [ %19, %cond.true26 ], [ 4, %cond.false28 ]
  %add = add i64 %cond30, 6
  %20 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %Nrnd = getelementptr inbounds %struct.aes, %struct.aes* %20, i32 0, i32 1
  store i64 %add, i64* %Nrnd, align 8
  %21 = load i8*, i8** %in_key.addr, align 8
  %22 = bitcast i8* %21 to i64*
  %23 = load i64, i64* %22, align 8
  %24 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %e_key = getelementptr inbounds %struct.aes, %struct.aes* %24, i32 0, i32 2
  %arrayidx = getelementptr inbounds [64 x i64], [64 x i64]* %e_key, i64 0, i64 0
  store i64 %23, i64* %arrayidx, align 8
  %25 = load i8*, i8** %in_key.addr, align 8
  %add.ptr = getelementptr inbounds i8, i8* %25, i64 4
  %26 = bitcast i8* %add.ptr to i64*
  %27 = load i64, i64* %26, align 8
  %28 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %e_key31 = getelementptr inbounds %struct.aes, %struct.aes* %28, i32 0, i32 2
  %arrayidx32 = getelementptr inbounds [64 x i64], [64 x i64]* %e_key31, i64 0, i64 1
  store i64 %27, i64* %arrayidx32, align 8
  %29 = load i8*, i8** %in_key.addr, align 8
  %add.ptr33 = getelementptr inbounds i8, i8* %29, i64 8
  %30 = bitcast i8* %add.ptr33 to i64*
  %31 = load i64, i64* %30, align 8
  %32 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %e_key34 = getelementptr inbounds %struct.aes, %struct.aes* %32, i32 0, i32 2
  %arrayidx35 = getelementptr inbounds [64 x i64], [64 x i64]* %e_key34, i64 0, i64 2
  store i64 %31, i64* %arrayidx35, align 8
  %33 = load i8*, i8** %in_key.addr, align 8
  %add.ptr36 = getelementptr inbounds i8, i8* %33, i64 12
  %34 = bitcast i8* %add.ptr36 to i64*
  %35 = load i64, i64* %34, align 8
  %36 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %e_key37 = getelementptr inbounds %struct.aes, %struct.aes* %36, i32 0, i32 2
  %arrayidx38 = getelementptr inbounds [64 x i64], [64 x i64]* %e_key37, i64 0, i64 3
  store i64 %35, i64* %arrayidx38, align 8
  %37 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %e_key39 = getelementptr inbounds %struct.aes, %struct.aes* %37, i32 0, i32 2
  %arraydecay = getelementptr inbounds [64 x i64], [64 x i64]* %e_key39, i32 0, i32 0
  store i64* %arraydecay, i64** %kf, align 8
  %38 = load i64*, i64** %kf, align 8
  %39 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %Nrnd40 = getelementptr inbounds %struct.aes, %struct.aes* %39, i32 0, i32 1
  %40 = load i64, i64* %Nrnd40, align 8
  %add41 = add i64 %40, 1
  %mul = mul i64 4, %add41
  %add.ptr42 = getelementptr inbounds i64, i64* %38, i64 %mul
  %41 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %Nkey43 = getelementptr inbounds %struct.aes, %struct.aes* %41, i32 0, i32 0
  %42 = load i64, i64* %Nkey43, align 8
  %idx.neg = sub i64 0, %42
  %add.ptr44 = getelementptr inbounds i64, i64* %add.ptr42, i64 %idx.neg
  store i64* %add.ptr44, i64** %kt, align 8
  store i64 0, i64* %rci, align 8
  %43 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %Nkey45 = getelementptr inbounds %struct.aes, %struct.aes* %43, i32 0, i32 0
  %44 = load i64, i64* %Nkey45, align 8
  switch i64 %44, label %sw.epilog [
    i64 4, label %sw.bb
    i64 6, label %sw.bb87
    i64 8, label %sw.bb149
  ]

sw.bb:                                            ; preds = %cond.end29
  br label %do.body

do.body:                                          ; preds = %do.cond, %sw.bb
  %45 = load i64*, i64** %kf, align 8
  %arrayidx46 = getelementptr inbounds i64, i64* %45, i64 0
  %46 = load i64, i64* %arrayidx46, align 8
  %47 = load i64*, i64** %kf, align 8
  %arrayidx47 = getelementptr inbounds i64, i64* %47, i64 3
  %48 = load i64, i64* %arrayidx47, align 8
  %shr48 = lshr i64 %48, 8
  %conv49 = trunc i64 %shr48 to i8
  %idxprom = zext i8 %conv49 to i64
  %arrayidx50 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 0), i64 0, i64 %idxprom
  %49 = load i64, i64* %arrayidx50, align 8
  %50 = load i64*, i64** %kf, align 8
  %arrayidx51 = getelementptr inbounds i64, i64* %50, i64 3
  %51 = load i64, i64* %arrayidx51, align 8
  %shr52 = lshr i64 %51, 16
  %conv53 = trunc i64 %shr52 to i8
  %idxprom54 = zext i8 %conv53 to i64
  %arrayidx55 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 1), i64 0, i64 %idxprom54
  %52 = load i64, i64* %arrayidx55, align 8
  %xor = xor i64 %49, %52
  %53 = load i64*, i64** %kf, align 8
  %arrayidx56 = getelementptr inbounds i64, i64* %53, i64 3
  %54 = load i64, i64* %arrayidx56, align 8
  %shr57 = lshr i64 %54, 24
  %conv58 = trunc i64 %shr57 to i8
  %idxprom59 = zext i8 %conv58 to i64
  %arrayidx60 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 2), i64 0, i64 %idxprom59
  %55 = load i64, i64* %arrayidx60, align 8
  %xor61 = xor i64 %xor, %55
  %56 = load i64*, i64** %kf, align 8
  %arrayidx62 = getelementptr inbounds i64, i64* %56, i64 3
  %57 = load i64, i64* %arrayidx62, align 8
  %shr63 = lshr i64 %57, 0
  %conv64 = trunc i64 %shr63 to i8
  %idxprom65 = zext i8 %conv64 to i64
  %arrayidx66 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 3), i64 0, i64 %idxprom65
  %58 = load i64, i64* %arrayidx66, align 8
  %xor67 = xor i64 %xor61, %58
  %xor68 = xor i64 %46, %xor67
  %59 = load i64, i64* %rci, align 8
  %inc = add i64 %59, 1
  store i64 %inc, i64* %rci, align 8
  %arrayidx69 = getelementptr inbounds [29 x i64], [29 x i64]* @rcon_tab, i64 0, i64 %59
  %60 = load i64, i64* %arrayidx69, align 8
  %xor70 = xor i64 %xor68, %60
  %61 = load i64*, i64** %kf, align 8
  %arrayidx71 = getelementptr inbounds i64, i64* %61, i64 4
  store i64 %xor70, i64* %arrayidx71, align 8
  %62 = load i64*, i64** %kf, align 8
  %arrayidx72 = getelementptr inbounds i64, i64* %62, i64 1
  %63 = load i64, i64* %arrayidx72, align 8
  %64 = load i64*, i64** %kf, align 8
  %arrayidx73 = getelementptr inbounds i64, i64* %64, i64 4
  %65 = load i64, i64* %arrayidx73, align 8
  %xor74 = xor i64 %63, %65
  %66 = load i64*, i64** %kf, align 8
  %arrayidx75 = getelementptr inbounds i64, i64* %66, i64 5
  store i64 %xor74, i64* %arrayidx75, align 8
  %67 = load i64*, i64** %kf, align 8
  %arrayidx76 = getelementptr inbounds i64, i64* %67, i64 2
  %68 = load i64, i64* %arrayidx76, align 8
  %69 = load i64*, i64** %kf, align 8
  %arrayidx77 = getelementptr inbounds i64, i64* %69, i64 5
  %70 = load i64, i64* %arrayidx77, align 8
  %xor78 = xor i64 %68, %70
  %71 = load i64*, i64** %kf, align 8
  %arrayidx79 = getelementptr inbounds i64, i64* %71, i64 6
  store i64 %xor78, i64* %arrayidx79, align 8
  %72 = load i64*, i64** %kf, align 8
  %arrayidx80 = getelementptr inbounds i64, i64* %72, i64 3
  %73 = load i64, i64* %arrayidx80, align 8
  %74 = load i64*, i64** %kf, align 8
  %arrayidx81 = getelementptr inbounds i64, i64* %74, i64 6
  %75 = load i64, i64* %arrayidx81, align 8
  %xor82 = xor i64 %73, %75
  %76 = load i64*, i64** %kf, align 8
  %arrayidx83 = getelementptr inbounds i64, i64* %76, i64 7
  store i64 %xor82, i64* %arrayidx83, align 8
  %77 = load i64*, i64** %kf, align 8
  %add.ptr84 = getelementptr inbounds i64, i64* %77, i64 4
  store i64* %add.ptr84, i64** %kf, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %78 = load i64*, i64** %kf, align 8
  %79 = load i64*, i64** %kt, align 8
  %cmp85 = icmp ult i64* %78, %79
  br i1 %cmp85, label %do.body, label %do.end

do.end:                                           ; preds = %do.cond
  br label %sw.epilog

sw.bb87:                                          ; preds = %cond.end29
  %80 = load i8*, i8** %in_key.addr, align 8
  %add.ptr88 = getelementptr inbounds i8, i8* %80, i64 16
  %81 = bitcast i8* %add.ptr88 to i64*
  %82 = load i64, i64* %81, align 8
  %83 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %e_key89 = getelementptr inbounds %struct.aes, %struct.aes* %83, i32 0, i32 2
  %arrayidx90 = getelementptr inbounds [64 x i64], [64 x i64]* %e_key89, i64 0, i64 4
  store i64 %82, i64* %arrayidx90, align 8
  %84 = load i8*, i8** %in_key.addr, align 8
  %add.ptr91 = getelementptr inbounds i8, i8* %84, i64 20
  %85 = bitcast i8* %add.ptr91 to i64*
  %86 = load i64, i64* %85, align 8
  %87 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %e_key92 = getelementptr inbounds %struct.aes, %struct.aes* %87, i32 0, i32 2
  %arrayidx93 = getelementptr inbounds [64 x i64], [64 x i64]* %e_key92, i64 0, i64 5
  store i64 %86, i64* %arrayidx93, align 8
  br label %do.body94

do.body94:                                        ; preds = %do.cond145, %sw.bb87
  %88 = load i64*, i64** %kf, align 8
  %arrayidx95 = getelementptr inbounds i64, i64* %88, i64 0
  %89 = load i64, i64* %arrayidx95, align 8
  %90 = load i64*, i64** %kf, align 8
  %arrayidx96 = getelementptr inbounds i64, i64* %90, i64 5
  %91 = load i64, i64* %arrayidx96, align 8
  %shr97 = lshr i64 %91, 8
  %conv98 = trunc i64 %shr97 to i8
  %idxprom99 = zext i8 %conv98 to i64
  %arrayidx100 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 0), i64 0, i64 %idxprom99
  %92 = load i64, i64* %arrayidx100, align 8
  %93 = load i64*, i64** %kf, align 8
  %arrayidx101 = getelementptr inbounds i64, i64* %93, i64 5
  %94 = load i64, i64* %arrayidx101, align 8
  %shr102 = lshr i64 %94, 16
  %conv103 = trunc i64 %shr102 to i8
  %idxprom104 = zext i8 %conv103 to i64
  %arrayidx105 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 1), i64 0, i64 %idxprom104
  %95 = load i64, i64* %arrayidx105, align 8
  %xor106 = xor i64 %92, %95
  %96 = load i64*, i64** %kf, align 8
  %arrayidx107 = getelementptr inbounds i64, i64* %96, i64 5
  %97 = load i64, i64* %arrayidx107, align 8
  %shr108 = lshr i64 %97, 24
  %conv109 = trunc i64 %shr108 to i8
  %idxprom110 = zext i8 %conv109 to i64
  %arrayidx111 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 2), i64 0, i64 %idxprom110
  %98 = load i64, i64* %arrayidx111, align 8
  %xor112 = xor i64 %xor106, %98
  %99 = load i64*, i64** %kf, align 8
  %arrayidx113 = getelementptr inbounds i64, i64* %99, i64 5
  %100 = load i64, i64* %arrayidx113, align 8
  %shr114 = lshr i64 %100, 0
  %conv115 = trunc i64 %shr114 to i8
  %idxprom116 = zext i8 %conv115 to i64
  %arrayidx117 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 3), i64 0, i64 %idxprom116
  %101 = load i64, i64* %arrayidx117, align 8
  %xor118 = xor i64 %xor112, %101
  %xor119 = xor i64 %89, %xor118
  %102 = load i64, i64* %rci, align 8
  %inc120 = add i64 %102, 1
  store i64 %inc120, i64* %rci, align 8
  %arrayidx121 = getelementptr inbounds [29 x i64], [29 x i64]* @rcon_tab, i64 0, i64 %102
  %103 = load i64, i64* %arrayidx121, align 8
  %xor122 = xor i64 %xor119, %103
  %104 = load i64*, i64** %kf, align 8
  %arrayidx123 = getelementptr inbounds i64, i64* %104, i64 6
  store i64 %xor122, i64* %arrayidx123, align 8
  %105 = load i64*, i64** %kf, align 8
  %arrayidx124 = getelementptr inbounds i64, i64* %105, i64 1
  %106 = load i64, i64* %arrayidx124, align 8
  %107 = load i64*, i64** %kf, align 8
  %arrayidx125 = getelementptr inbounds i64, i64* %107, i64 6
  %108 = load i64, i64* %arrayidx125, align 8
  %xor126 = xor i64 %106, %108
  %109 = load i64*, i64** %kf, align 8
  %arrayidx127 = getelementptr inbounds i64, i64* %109, i64 7
  store i64 %xor126, i64* %arrayidx127, align 8
  %110 = load i64*, i64** %kf, align 8
  %arrayidx128 = getelementptr inbounds i64, i64* %110, i64 2
  %111 = load i64, i64* %arrayidx128, align 8
  %112 = load i64*, i64** %kf, align 8
  %arrayidx129 = getelementptr inbounds i64, i64* %112, i64 7
  %113 = load i64, i64* %arrayidx129, align 8
  %xor130 = xor i64 %111, %113
  %114 = load i64*, i64** %kf, align 8
  %arrayidx131 = getelementptr inbounds i64, i64* %114, i64 8
  store i64 %xor130, i64* %arrayidx131, align 8
  %115 = load i64*, i64** %kf, align 8
  %arrayidx132 = getelementptr inbounds i64, i64* %115, i64 3
  %116 = load i64, i64* %arrayidx132, align 8
  %117 = load i64*, i64** %kf, align 8
  %arrayidx133 = getelementptr inbounds i64, i64* %117, i64 8
  %118 = load i64, i64* %arrayidx133, align 8
  %xor134 = xor i64 %116, %118
  %119 = load i64*, i64** %kf, align 8
  %arrayidx135 = getelementptr inbounds i64, i64* %119, i64 9
  store i64 %xor134, i64* %arrayidx135, align 8
  %120 = load i64*, i64** %kf, align 8
  %arrayidx136 = getelementptr inbounds i64, i64* %120, i64 4
  %121 = load i64, i64* %arrayidx136, align 8
  %122 = load i64*, i64** %kf, align 8
  %arrayidx137 = getelementptr inbounds i64, i64* %122, i64 9
  %123 = load i64, i64* %arrayidx137, align 8
  %xor138 = xor i64 %121, %123
  %124 = load i64*, i64** %kf, align 8
  %arrayidx139 = getelementptr inbounds i64, i64* %124, i64 10
  store i64 %xor138, i64* %arrayidx139, align 8
  %125 = load i64*, i64** %kf, align 8
  %arrayidx140 = getelementptr inbounds i64, i64* %125, i64 5
  %126 = load i64, i64* %arrayidx140, align 8
  %127 = load i64*, i64** %kf, align 8
  %arrayidx141 = getelementptr inbounds i64, i64* %127, i64 10
  %128 = load i64, i64* %arrayidx141, align 8
  %xor142 = xor i64 %126, %128
  %129 = load i64*, i64** %kf, align 8
  %arrayidx143 = getelementptr inbounds i64, i64* %129, i64 11
  store i64 %xor142, i64* %arrayidx143, align 8
  %130 = load i64*, i64** %kf, align 8
  %add.ptr144 = getelementptr inbounds i64, i64* %130, i64 6
  store i64* %add.ptr144, i64** %kf, align 8
  br label %do.cond145

do.cond145:                                       ; preds = %do.body94
  %131 = load i64*, i64** %kf, align 8
  %132 = load i64*, i64** %kt, align 8
  %cmp146 = icmp ult i64* %131, %132
  br i1 %cmp146, label %do.body94, label %do.end148

do.end148:                                        ; preds = %do.cond145
  br label %sw.epilog

sw.bb149:                                         ; preds = %cond.end29
  %133 = load i8*, i8** %in_key.addr, align 8
  %add.ptr150 = getelementptr inbounds i8, i8* %133, i64 16
  %134 = bitcast i8* %add.ptr150 to i64*
  %135 = load i64, i64* %134, align 8
  %136 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %e_key151 = getelementptr inbounds %struct.aes, %struct.aes* %136, i32 0, i32 2
  %arrayidx152 = getelementptr inbounds [64 x i64], [64 x i64]* %e_key151, i64 0, i64 4
  store i64 %135, i64* %arrayidx152, align 8
  %137 = load i8*, i8** %in_key.addr, align 8
  %add.ptr153 = getelementptr inbounds i8, i8* %137, i64 20
  %138 = bitcast i8* %add.ptr153 to i64*
  %139 = load i64, i64* %138, align 8
  %140 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %e_key154 = getelementptr inbounds %struct.aes, %struct.aes* %140, i32 0, i32 2
  %arrayidx155 = getelementptr inbounds [64 x i64], [64 x i64]* %e_key154, i64 0, i64 5
  store i64 %139, i64* %arrayidx155, align 8
  %141 = load i8*, i8** %in_key.addr, align 8
  %add.ptr156 = getelementptr inbounds i8, i8* %141, i64 24
  %142 = bitcast i8* %add.ptr156 to i64*
  %143 = load i64, i64* %142, align 8
  %144 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %e_key157 = getelementptr inbounds %struct.aes, %struct.aes* %144, i32 0, i32 2
  %arrayidx158 = getelementptr inbounds [64 x i64], [64 x i64]* %e_key157, i64 0, i64 6
  store i64 %143, i64* %arrayidx158, align 8
  %145 = load i8*, i8** %in_key.addr, align 8
  %add.ptr159 = getelementptr inbounds i8, i8* %145, i64 28
  %146 = bitcast i8* %add.ptr159 to i64*
  %147 = load i64, i64* %146, align 8
  %148 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %e_key160 = getelementptr inbounds %struct.aes, %struct.aes* %148, i32 0, i32 2
  %arrayidx161 = getelementptr inbounds [64 x i64], [64 x i64]* %e_key160, i64 0, i64 7
  store i64 %147, i64* %arrayidx161, align 8
  br label %do.body162

do.body162:                                       ; preds = %do.cond243, %sw.bb149
  %149 = load i64*, i64** %kf, align 8
  %arrayidx163 = getelementptr inbounds i64, i64* %149, i64 0
  %150 = load i64, i64* %arrayidx163, align 8
  %151 = load i64*, i64** %kf, align 8
  %arrayidx164 = getelementptr inbounds i64, i64* %151, i64 7
  %152 = load i64, i64* %arrayidx164, align 8
  %shr165 = lshr i64 %152, 8
  %conv166 = trunc i64 %shr165 to i8
  %idxprom167 = zext i8 %conv166 to i64
  %arrayidx168 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 0), i64 0, i64 %idxprom167
  %153 = load i64, i64* %arrayidx168, align 8
  %154 = load i64*, i64** %kf, align 8
  %arrayidx169 = getelementptr inbounds i64, i64* %154, i64 7
  %155 = load i64, i64* %arrayidx169, align 8
  %shr170 = lshr i64 %155, 16
  %conv171 = trunc i64 %shr170 to i8
  %idxprom172 = zext i8 %conv171 to i64
  %arrayidx173 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 1), i64 0, i64 %idxprom172
  %156 = load i64, i64* %arrayidx173, align 8
  %xor174 = xor i64 %153, %156
  %157 = load i64*, i64** %kf, align 8
  %arrayidx175 = getelementptr inbounds i64, i64* %157, i64 7
  %158 = load i64, i64* %arrayidx175, align 8
  %shr176 = lshr i64 %158, 24
  %conv177 = trunc i64 %shr176 to i8
  %idxprom178 = zext i8 %conv177 to i64
  %arrayidx179 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 2), i64 0, i64 %idxprom178
  %159 = load i64, i64* %arrayidx179, align 8
  %xor180 = xor i64 %xor174, %159
  %160 = load i64*, i64** %kf, align 8
  %arrayidx181 = getelementptr inbounds i64, i64* %160, i64 7
  %161 = load i64, i64* %arrayidx181, align 8
  %shr182 = lshr i64 %161, 0
  %conv183 = trunc i64 %shr182 to i8
  %idxprom184 = zext i8 %conv183 to i64
  %arrayidx185 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 3), i64 0, i64 %idxprom184
  %162 = load i64, i64* %arrayidx185, align 8
  %xor186 = xor i64 %xor180, %162
  %xor187 = xor i64 %150, %xor186
  %163 = load i64, i64* %rci, align 8
  %inc188 = add i64 %163, 1
  store i64 %inc188, i64* %rci, align 8
  %arrayidx189 = getelementptr inbounds [29 x i64], [29 x i64]* @rcon_tab, i64 0, i64 %163
  %164 = load i64, i64* %arrayidx189, align 8
  %xor190 = xor i64 %xor187, %164
  %165 = load i64*, i64** %kf, align 8
  %arrayidx191 = getelementptr inbounds i64, i64* %165, i64 8
  store i64 %xor190, i64* %arrayidx191, align 8
  %166 = load i64*, i64** %kf, align 8
  %arrayidx192 = getelementptr inbounds i64, i64* %166, i64 1
  %167 = load i64, i64* %arrayidx192, align 8
  %168 = load i64*, i64** %kf, align 8
  %arrayidx193 = getelementptr inbounds i64, i64* %168, i64 8
  %169 = load i64, i64* %arrayidx193, align 8
  %xor194 = xor i64 %167, %169
  %170 = load i64*, i64** %kf, align 8
  %arrayidx195 = getelementptr inbounds i64, i64* %170, i64 9
  store i64 %xor194, i64* %arrayidx195, align 8
  %171 = load i64*, i64** %kf, align 8
  %arrayidx196 = getelementptr inbounds i64, i64* %171, i64 2
  %172 = load i64, i64* %arrayidx196, align 8
  %173 = load i64*, i64** %kf, align 8
  %arrayidx197 = getelementptr inbounds i64, i64* %173, i64 9
  %174 = load i64, i64* %arrayidx197, align 8
  %xor198 = xor i64 %172, %174
  %175 = load i64*, i64** %kf, align 8
  %arrayidx199 = getelementptr inbounds i64, i64* %175, i64 10
  store i64 %xor198, i64* %arrayidx199, align 8
  %176 = load i64*, i64** %kf, align 8
  %arrayidx200 = getelementptr inbounds i64, i64* %176, i64 3
  %177 = load i64, i64* %arrayidx200, align 8
  %178 = load i64*, i64** %kf, align 8
  %arrayidx201 = getelementptr inbounds i64, i64* %178, i64 10
  %179 = load i64, i64* %arrayidx201, align 8
  %xor202 = xor i64 %177, %179
  %180 = load i64*, i64** %kf, align 8
  %arrayidx203 = getelementptr inbounds i64, i64* %180, i64 11
  store i64 %xor202, i64* %arrayidx203, align 8
  %181 = load i64*, i64** %kf, align 8
  %arrayidx204 = getelementptr inbounds i64, i64* %181, i64 4
  %182 = load i64, i64* %arrayidx204, align 8
  %183 = load i64*, i64** %kf, align 8
  %arrayidx205 = getelementptr inbounds i64, i64* %183, i64 11
  %184 = load i64, i64* %arrayidx205, align 8
  %shr206 = lshr i64 %184, 0
  %conv207 = trunc i64 %shr206 to i8
  %idxprom208 = zext i8 %conv207 to i64
  %arrayidx209 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 0), i64 0, i64 %idxprom208
  %185 = load i64, i64* %arrayidx209, align 8
  %186 = load i64*, i64** %kf, align 8
  %arrayidx210 = getelementptr inbounds i64, i64* %186, i64 11
  %187 = load i64, i64* %arrayidx210, align 8
  %shr211 = lshr i64 %187, 8
  %conv212 = trunc i64 %shr211 to i8
  %idxprom213 = zext i8 %conv212 to i64
  %arrayidx214 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 1), i64 0, i64 %idxprom213
  %188 = load i64, i64* %arrayidx214, align 8
  %xor215 = xor i64 %185, %188
  %189 = load i64*, i64** %kf, align 8
  %arrayidx216 = getelementptr inbounds i64, i64* %189, i64 11
  %190 = load i64, i64* %arrayidx216, align 8
  %shr217 = lshr i64 %190, 16
  %conv218 = trunc i64 %shr217 to i8
  %idxprom219 = zext i8 %conv218 to i64
  %arrayidx220 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 2), i64 0, i64 %idxprom219
  %191 = load i64, i64* %arrayidx220, align 8
  %xor221 = xor i64 %xor215, %191
  %192 = load i64*, i64** %kf, align 8
  %arrayidx222 = getelementptr inbounds i64, i64* %192, i64 11
  %193 = load i64, i64* %arrayidx222, align 8
  %shr223 = lshr i64 %193, 24
  %conv224 = trunc i64 %shr223 to i8
  %idxprom225 = zext i8 %conv224 to i64
  %arrayidx226 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 3), i64 0, i64 %idxprom225
  %194 = load i64, i64* %arrayidx226, align 8
  %xor227 = xor i64 %xor221, %194
  %xor228 = xor i64 %182, %xor227
  %195 = load i64*, i64** %kf, align 8
  %arrayidx229 = getelementptr inbounds i64, i64* %195, i64 12
  store i64 %xor228, i64* %arrayidx229, align 8
  %196 = load i64*, i64** %kf, align 8
  %arrayidx230 = getelementptr inbounds i64, i64* %196, i64 5
  %197 = load i64, i64* %arrayidx230, align 8
  %198 = load i64*, i64** %kf, align 8
  %arrayidx231 = getelementptr inbounds i64, i64* %198, i64 12
  %199 = load i64, i64* %arrayidx231, align 8
  %xor232 = xor i64 %197, %199
  %200 = load i64*, i64** %kf, align 8
  %arrayidx233 = getelementptr inbounds i64, i64* %200, i64 13
  store i64 %xor232, i64* %arrayidx233, align 8
  %201 = load i64*, i64** %kf, align 8
  %arrayidx234 = getelementptr inbounds i64, i64* %201, i64 6
  %202 = load i64, i64* %arrayidx234, align 8
  %203 = load i64*, i64** %kf, align 8
  %arrayidx235 = getelementptr inbounds i64, i64* %203, i64 13
  %204 = load i64, i64* %arrayidx235, align 8
  %xor236 = xor i64 %202, %204
  %205 = load i64*, i64** %kf, align 8
  %arrayidx237 = getelementptr inbounds i64, i64* %205, i64 14
  store i64 %xor236, i64* %arrayidx237, align 8
  %206 = load i64*, i64** %kf, align 8
  %arrayidx238 = getelementptr inbounds i64, i64* %206, i64 7
  %207 = load i64, i64* %arrayidx238, align 8
  %208 = load i64*, i64** %kf, align 8
  %arrayidx239 = getelementptr inbounds i64, i64* %208, i64 14
  %209 = load i64, i64* %arrayidx239, align 8
  %xor240 = xor i64 %207, %209
  %210 = load i64*, i64** %kf, align 8
  %arrayidx241 = getelementptr inbounds i64, i64* %210, i64 15
  store i64 %xor240, i64* %arrayidx241, align 8
  %211 = load i64*, i64** %kf, align 8
  %add.ptr242 = getelementptr inbounds i64, i64* %211, i64 8
  store i64* %add.ptr242, i64** %kf, align 8
  br label %do.cond243

do.cond243:                                       ; preds = %do.body162
  %212 = load i64*, i64** %kf, align 8
  %213 = load i64*, i64** %kt, align 8
  %cmp244 = icmp ult i64* %212, %213
  br i1 %cmp244, label %do.body162, label %do.end246

do.end246:                                        ; preds = %do.cond243
  br label %sw.epilog

sw.epilog:                                        ; preds = %cond.end29, %do.end246, %do.end148, %do.end
  %214 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %mode247 = getelementptr inbounds %struct.aes, %struct.aes* %214, i32 0, i32 4
  %215 = load i8, i8* %mode247, align 8
  %conv248 = zext i8 %215 to i32
  %and249 = and i32 %conv248, 3
  %cmp250 = icmp ne i32 %and249, 1
  br i1 %cmp250, label %if.then252, label %if.end364

if.then252:                                       ; preds = %sw.epilog
  %216 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %d_key = getelementptr inbounds %struct.aes, %struct.aes* %216, i32 0, i32 3
  %arraydecay253 = getelementptr inbounds [64 x i64], [64 x i64]* %d_key, i32 0, i32 0
  %217 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %Nrnd254 = getelementptr inbounds %struct.aes, %struct.aes* %217, i32 0, i32 1
  %218 = load i64, i64* %Nrnd254, align 8
  %mul255 = mul i64 4, %218
  %add.ptr256 = getelementptr inbounds i64, i64* %arraydecay253, i64 %mul255
  store i64* %add.ptr256, i64** %kt, align 8
  %219 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %e_key257 = getelementptr inbounds %struct.aes, %struct.aes* %219, i32 0, i32 2
  %arraydecay258 = getelementptr inbounds [64 x i64], [64 x i64]* %e_key257, i32 0, i32 0
  store i64* %arraydecay258, i64** %kf, align 8
  %220 = load i64*, i64** %kf, align 8
  %incdec.ptr = getelementptr inbounds i64, i64* %220, i32 1
  store i64* %incdec.ptr, i64** %kf, align 8
  %221 = load i64, i64* %220, align 8
  %222 = load i64*, i64** %kt, align 8
  %incdec.ptr259 = getelementptr inbounds i64, i64* %222, i32 1
  store i64* %incdec.ptr259, i64** %kt, align 8
  store i64 %221, i64* %222, align 8
  %223 = load i64*, i64** %kf, align 8
  %incdec.ptr260 = getelementptr inbounds i64, i64* %223, i32 1
  store i64* %incdec.ptr260, i64** %kf, align 8
  %224 = load i64, i64* %223, align 8
  %225 = load i64*, i64** %kt, align 8
  %incdec.ptr261 = getelementptr inbounds i64, i64* %225, i32 1
  store i64* %incdec.ptr261, i64** %kt, align 8
  store i64 %224, i64* %225, align 8
  %226 = load i64*, i64** %kf, align 8
  %incdec.ptr262 = getelementptr inbounds i64, i64* %226, i32 1
  store i64* %incdec.ptr262, i64** %kf, align 8
  %227 = load i64, i64* %226, align 8
  %228 = load i64*, i64** %kt, align 8
  %incdec.ptr263 = getelementptr inbounds i64, i64* %228, i32 1
  store i64* %incdec.ptr263, i64** %kt, align 8
  store i64 %227, i64* %228, align 8
  %229 = load i64*, i64** %kf, align 8
  %incdec.ptr264 = getelementptr inbounds i64, i64* %229, i32 1
  store i64* %incdec.ptr264, i64** %kf, align 8
  %230 = load i64, i64* %229, align 8
  %231 = load i64*, i64** %kt, align 8
  %incdec.ptr265 = getelementptr inbounds i64, i64* %231, i32 1
  store i64* %incdec.ptr265, i64** %kt, align 8
  store i64 %230, i64* %231, align 8
  %232 = load i64*, i64** %kt, align 8
  %add.ptr266 = getelementptr inbounds i64, i64* %232, i64 -8
  store i64* %add.ptr266, i64** %kt, align 8
  store i64 1, i64* %i, align 8
  br label %for.cond

for.cond:                                         ; preds = %for.inc, %if.then252
  %233 = load i64, i64* %i, align 8
  %234 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %Nrnd267 = getelementptr inbounds %struct.aes, %struct.aes* %234, i32 0, i32 1
  %235 = load i64, i64* %Nrnd267, align 8
  %cmp268 = icmp ult i64 %233, %235
  br i1 %cmp268, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %236 = load i64*, i64** %kf, align 8
  %237 = load i64, i64* %236, align 8
  %shr270 = lshr i64 %237, 0
  %conv271 = trunc i64 %shr270 to i8
  %idxprom272 = zext i8 %conv271 to i64
  %arrayidx273 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 0), i64 0, i64 %idxprom272
  %238 = load i64, i64* %arrayidx273, align 8
  %239 = load i64*, i64** %kf, align 8
  %240 = load i64, i64* %239, align 8
  %shr274 = lshr i64 %240, 8
  %conv275 = trunc i64 %shr274 to i8
  %idxprom276 = zext i8 %conv275 to i64
  %arrayidx277 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 1), i64 0, i64 %idxprom276
  %241 = load i64, i64* %arrayidx277, align 8
  %xor278 = xor i64 %238, %241
  %242 = load i64*, i64** %kf, align 8
  %243 = load i64, i64* %242, align 8
  %shr279 = lshr i64 %243, 16
  %conv280 = trunc i64 %shr279 to i8
  %idxprom281 = zext i8 %conv280 to i64
  %arrayidx282 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 2), i64 0, i64 %idxprom281
  %244 = load i64, i64* %arrayidx282, align 8
  %xor283 = xor i64 %xor278, %244
  %245 = load i64*, i64** %kf, align 8
  %246 = load i64, i64* %245, align 8
  %shr284 = lshr i64 %246, 24
  %conv285 = trunc i64 %shr284 to i8
  %idxprom286 = zext i8 %conv285 to i64
  %arrayidx287 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 3), i64 0, i64 %idxprom286
  %247 = load i64, i64* %arrayidx287, align 8
  %xor288 = xor i64 %xor283, %247
  %248 = load i64*, i64** %kt, align 8
  %incdec.ptr289 = getelementptr inbounds i64, i64* %248, i32 1
  store i64* %incdec.ptr289, i64** %kt, align 8
  store i64 %xor288, i64* %248, align 8
  %249 = load i64*, i64** %kf, align 8
  %incdec.ptr290 = getelementptr inbounds i64, i64* %249, i32 1
  store i64* %incdec.ptr290, i64** %kf, align 8
  %250 = load i64*, i64** %kf, align 8
  %251 = load i64, i64* %250, align 8
  %shr291 = lshr i64 %251, 0
  %conv292 = trunc i64 %shr291 to i8
  %idxprom293 = zext i8 %conv292 to i64
  %arrayidx294 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 0), i64 0, i64 %idxprom293
  %252 = load i64, i64* %arrayidx294, align 8
  %253 = load i64*, i64** %kf, align 8
  %254 = load i64, i64* %253, align 8
  %shr295 = lshr i64 %254, 8
  %conv296 = trunc i64 %shr295 to i8
  %idxprom297 = zext i8 %conv296 to i64
  %arrayidx298 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 1), i64 0, i64 %idxprom297
  %255 = load i64, i64* %arrayidx298, align 8
  %xor299 = xor i64 %252, %255
  %256 = load i64*, i64** %kf, align 8
  %257 = load i64, i64* %256, align 8
  %shr300 = lshr i64 %257, 16
  %conv301 = trunc i64 %shr300 to i8
  %idxprom302 = zext i8 %conv301 to i64
  %arrayidx303 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 2), i64 0, i64 %idxprom302
  %258 = load i64, i64* %arrayidx303, align 8
  %xor304 = xor i64 %xor299, %258
  %259 = load i64*, i64** %kf, align 8
  %260 = load i64, i64* %259, align 8
  %shr305 = lshr i64 %260, 24
  %conv306 = trunc i64 %shr305 to i8
  %idxprom307 = zext i8 %conv306 to i64
  %arrayidx308 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 3), i64 0, i64 %idxprom307
  %261 = load i64, i64* %arrayidx308, align 8
  %xor309 = xor i64 %xor304, %261
  %262 = load i64*, i64** %kt, align 8
  %incdec.ptr310 = getelementptr inbounds i64, i64* %262, i32 1
  store i64* %incdec.ptr310, i64** %kt, align 8
  store i64 %xor309, i64* %262, align 8
  %263 = load i64*, i64** %kf, align 8
  %incdec.ptr311 = getelementptr inbounds i64, i64* %263, i32 1
  store i64* %incdec.ptr311, i64** %kf, align 8
  %264 = load i64*, i64** %kf, align 8
  %265 = load i64, i64* %264, align 8
  %shr312 = lshr i64 %265, 0
  %conv313 = trunc i64 %shr312 to i8
  %idxprom314 = zext i8 %conv313 to i64
  %arrayidx315 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 0), i64 0, i64 %idxprom314
  %266 = load i64, i64* %arrayidx315, align 8
  %267 = load i64*, i64** %kf, align 8
  %268 = load i64, i64* %267, align 8
  %shr316 = lshr i64 %268, 8
  %conv317 = trunc i64 %shr316 to i8
  %idxprom318 = zext i8 %conv317 to i64
  %arrayidx319 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 1), i64 0, i64 %idxprom318
  %269 = load i64, i64* %arrayidx319, align 8
  %xor320 = xor i64 %266, %269
  %270 = load i64*, i64** %kf, align 8
  %271 = load i64, i64* %270, align 8
  %shr321 = lshr i64 %271, 16
  %conv322 = trunc i64 %shr321 to i8
  %idxprom323 = zext i8 %conv322 to i64
  %arrayidx324 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 2), i64 0, i64 %idxprom323
  %272 = load i64, i64* %arrayidx324, align 8
  %xor325 = xor i64 %xor320, %272
  %273 = load i64*, i64** %kf, align 8
  %274 = load i64, i64* %273, align 8
  %shr326 = lshr i64 %274, 24
  %conv327 = trunc i64 %shr326 to i8
  %idxprom328 = zext i8 %conv327 to i64
  %arrayidx329 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 3), i64 0, i64 %idxprom328
  %275 = load i64, i64* %arrayidx329, align 8
  %xor330 = xor i64 %xor325, %275
  %276 = load i64*, i64** %kt, align 8
  %incdec.ptr331 = getelementptr inbounds i64, i64* %276, i32 1
  store i64* %incdec.ptr331, i64** %kt, align 8
  store i64 %xor330, i64* %276, align 8
  %277 = load i64*, i64** %kf, align 8
  %incdec.ptr332 = getelementptr inbounds i64, i64* %277, i32 1
  store i64* %incdec.ptr332, i64** %kf, align 8
  %278 = load i64*, i64** %kf, align 8
  %279 = load i64, i64* %278, align 8
  %shr333 = lshr i64 %279, 0
  %conv334 = trunc i64 %shr333 to i8
  %idxprom335 = zext i8 %conv334 to i64
  %arrayidx336 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 0), i64 0, i64 %idxprom335
  %280 = load i64, i64* %arrayidx336, align 8
  %281 = load i64*, i64** %kf, align 8
  %282 = load i64, i64* %281, align 8
  %shr337 = lshr i64 %282, 8
  %conv338 = trunc i64 %shr337 to i8
  %idxprom339 = zext i8 %conv338 to i64
  %arrayidx340 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 1), i64 0, i64 %idxprom339
  %283 = load i64, i64* %arrayidx340, align 8
  %xor341 = xor i64 %280, %283
  %284 = load i64*, i64** %kf, align 8
  %285 = load i64, i64* %284, align 8
  %shr342 = lshr i64 %285, 16
  %conv343 = trunc i64 %shr342 to i8
  %idxprom344 = zext i8 %conv343 to i64
  %arrayidx345 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 2), i64 0, i64 %idxprom344
  %286 = load i64, i64* %arrayidx345, align 8
  %xor346 = xor i64 %xor341, %286
  %287 = load i64*, i64** %kf, align 8
  %288 = load i64, i64* %287, align 8
  %shr347 = lshr i64 %288, 24
  %conv348 = trunc i64 %shr347 to i8
  %idxprom349 = zext i8 %conv348 to i64
  %arrayidx350 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @im_tab, i64 0, i64 3), i64 0, i64 %idxprom349
  %289 = load i64, i64* %arrayidx350, align 8
  %xor351 = xor i64 %xor346, %289
  %290 = load i64*, i64** %kt, align 8
  %incdec.ptr352 = getelementptr inbounds i64, i64* %290, i32 1
  store i64* %incdec.ptr352, i64** %kt, align 8
  store i64 %xor351, i64* %290, align 8
  %291 = load i64*, i64** %kf, align 8
  %incdec.ptr353 = getelementptr inbounds i64, i64* %291, i32 1
  store i64* %incdec.ptr353, i64** %kf, align 8
  %292 = load i64*, i64** %kt, align 8
  %add.ptr354 = getelementptr inbounds i64, i64* %292, i64 -8
  store i64* %add.ptr354, i64** %kt, align 8
  br label %for.inc

for.inc:                                          ; preds = %for.body
  %293 = load i64, i64* %i, align 8
  %inc355 = add i64 %293, 1
  store i64 %inc355, i64* %i, align 8
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %294 = load i64*, i64** %kf, align 8
  %incdec.ptr356 = getelementptr inbounds i64, i64* %294, i32 1
  store i64* %incdec.ptr356, i64** %kf, align 8
  %295 = load i64, i64* %294, align 8
  %296 = load i64*, i64** %kt, align 8
  %incdec.ptr357 = getelementptr inbounds i64, i64* %296, i32 1
  store i64* %incdec.ptr357, i64** %kt, align 8
  store i64 %295, i64* %296, align 8
  %297 = load i64*, i64** %kf, align 8
  %incdec.ptr358 = getelementptr inbounds i64, i64* %297, i32 1
  store i64* %incdec.ptr358, i64** %kf, align 8
  %298 = load i64, i64* %297, align 8
  %299 = load i64*, i64** %kt, align 8
  %incdec.ptr359 = getelementptr inbounds i64, i64* %299, i32 1
  store i64* %incdec.ptr359, i64** %kt, align 8
  store i64 %298, i64* %299, align 8
  %300 = load i64*, i64** %kf, align 8
  %incdec.ptr360 = getelementptr inbounds i64, i64* %300, i32 1
  store i64* %incdec.ptr360, i64** %kf, align 8
  %301 = load i64, i64* %300, align 8
  %302 = load i64*, i64** %kt, align 8
  %incdec.ptr361 = getelementptr inbounds i64, i64* %302, i32 1
  store i64* %incdec.ptr361, i64** %kt, align 8
  store i64 %301, i64* %302, align 8
  %303 = load i64*, i64** %kf, align 8
  %incdec.ptr362 = getelementptr inbounds i64, i64* %303, i32 1
  store i64* %incdec.ptr362, i64** %kf, align 8
  %304 = load i64, i64* %303, align 8
  %305 = load i64*, i64** %kt, align 8
  %incdec.ptr363 = getelementptr inbounds i64, i64* %305, i32 1
  store i64* %incdec.ptr363, i64** %kt, align 8
  store i64 %304, i64* %305, align 8
  br label %if.end364

if.end364:                                        ; preds = %for.end, %sw.epilog
  store i16 1, i16* %retval, align 2
  br label %return

return:                                           ; preds = %if.end364, %cond.end
  %306 = load i16, i16* %retval, align 2
  ret i16 %306
}

; Function Attrs: nounwind uwtable
define signext i16 @encrypt(i8* %in_blk, i8* %out_blk, %struct.aes* %cx) #0 {
entry:
  %retval = alloca i16, align 2
  %in_blk.addr = alloca i8*, align 8
  %out_blk.addr = alloca i8*, align 8
  %cx.addr = alloca %struct.aes*, align 8
  %b1 = alloca [4 x i64], align 16
  %b0 = alloca [4 x i64], align 16
  %kp = alloca i64*, align 8
  store i8* %in_blk, i8** %in_blk.addr, align 8
  store i8* %out_blk, i8** %out_blk.addr, align 8
  store %struct.aes* %cx, %struct.aes** %cx.addr, align 8
  %0 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %e_key = getelementptr inbounds %struct.aes, %struct.aes* %0, i32 0, i32 2
  %arraydecay = getelementptr inbounds [64 x i64], [64 x i64]* %e_key, i32 0, i32 0
  store i64* %arraydecay, i64** %kp, align 8
  %1 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %mode = getelementptr inbounds %struct.aes, %struct.aes* %1, i32 0, i32 4
  %2 = load i8, i8* %mode, align 8
  %conv = zext i8 %2 to i32
  %and = and i32 %conv, 1
  %tobool = icmp ne i32 %and, 0
  br i1 %tobool, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  store i16 0, i16* %retval, align 2
  br label %return

if.end:                                           ; preds = %entry
  %3 = load i8*, i8** %in_blk.addr, align 8
  %add.ptr = getelementptr inbounds i8, i8* %3, i64 0
  %4 = bitcast i8* %add.ptr to i64*
  %5 = load i64, i64* %4, align 8
  %6 = load i64*, i64** %kp, align 8
  %arrayidx = getelementptr inbounds i64, i64* %6, i64 0
  %7 = load i64, i64* %arrayidx, align 8
  %xor = xor i64 %5, %7
  %arrayidx1 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor, i64* %arrayidx1, align 16
  %8 = load i8*, i8** %in_blk.addr, align 8
  %add.ptr2 = getelementptr inbounds i8, i8* %8, i64 4
  %9 = bitcast i8* %add.ptr2 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = load i64*, i64** %kp, align 8
  %arrayidx3 = getelementptr inbounds i64, i64* %11, i64 1
  %12 = load i64, i64* %arrayidx3, align 8
  %xor4 = xor i64 %10, %12
  %arrayidx5 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor4, i64* %arrayidx5, align 8
  %13 = load i8*, i8** %in_blk.addr, align 8
  %add.ptr6 = getelementptr inbounds i8, i8* %13, i64 8
  %14 = bitcast i8* %add.ptr6 to i64*
  %15 = load i64, i64* %14, align 8
  %16 = load i64*, i64** %kp, align 8
  %arrayidx7 = getelementptr inbounds i64, i64* %16, i64 2
  %17 = load i64, i64* %arrayidx7, align 8
  %xor8 = xor i64 %15, %17
  %arrayidx9 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor8, i64* %arrayidx9, align 16
  %18 = load i8*, i8** %in_blk.addr, align 8
  %add.ptr10 = getelementptr inbounds i8, i8* %18, i64 12
  %19 = bitcast i8* %add.ptr10 to i64*
  %20 = load i64, i64* %19, align 8
  %21 = load i64*, i64** %kp, align 8
  %arrayidx11 = getelementptr inbounds i64, i64* %21, i64 3
  %22 = load i64, i64* %arrayidx11, align 8
  %xor12 = xor i64 %20, %22
  %arrayidx13 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor12, i64* %arrayidx13, align 8
  %23 = load i64*, i64** %kp, align 8
  %add.ptr14 = getelementptr inbounds i64, i64* %23, i64 4
  store i64* %add.ptr14, i64** %kp, align 8
  %24 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %Nrnd = getelementptr inbounds %struct.aes, %struct.aes* %24, i32 0, i32 1
  %25 = load i64, i64* %Nrnd, align 8
  switch i64 %25, label %sw.epilog [
    i64 14, label %sw.bb
    i64 12, label %sw.bb226
    i64 10, label %sw.bb440
  ]

sw.bb:                                            ; preds = %if.end
  %26 = load i64*, i64** %kp, align 8
  %arrayidx15 = getelementptr inbounds i64, i64* %26, i64 0
  %27 = load i64, i64* %arrayidx15, align 8
  %arrayidx16 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %28 = load i64, i64* %arrayidx16, align 16
  %shr = lshr i64 %28, 0
  %conv17 = trunc i64 %shr to i8
  %idxprom = zext i8 %conv17 to i64
  %arrayidx18 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom
  %29 = load i64, i64* %arrayidx18, align 8
  %arrayidx19 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %30 = load i64, i64* %arrayidx19, align 8
  %shr20 = lshr i64 %30, 8
  %conv21 = trunc i64 %shr20 to i8
  %idxprom22 = zext i8 %conv21 to i64
  %arrayidx23 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom22
  %31 = load i64, i64* %arrayidx23, align 8
  %xor24 = xor i64 %29, %31
  %arrayidx25 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %32 = load i64, i64* %arrayidx25, align 16
  %shr26 = lshr i64 %32, 16
  %conv27 = trunc i64 %shr26 to i8
  %idxprom28 = zext i8 %conv27 to i64
  %arrayidx29 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom28
  %33 = load i64, i64* %arrayidx29, align 8
  %xor30 = xor i64 %xor24, %33
  %arrayidx31 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %34 = load i64, i64* %arrayidx31, align 8
  %shr32 = lshr i64 %34, 24
  %conv33 = trunc i64 %shr32 to i8
  %idxprom34 = zext i8 %conv33 to i64
  %arrayidx35 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom34
  %35 = load i64, i64* %arrayidx35, align 8
  %xor36 = xor i64 %xor30, %35
  %xor37 = xor i64 %27, %xor36
  %arrayidx38 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor37, i64* %arrayidx38, align 16
  %36 = load i64*, i64** %kp, align 8
  %arrayidx39 = getelementptr inbounds i64, i64* %36, i64 1
  %37 = load i64, i64* %arrayidx39, align 8
  %arrayidx40 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %38 = load i64, i64* %arrayidx40, align 8
  %shr41 = lshr i64 %38, 0
  %conv42 = trunc i64 %shr41 to i8
  %idxprom43 = zext i8 %conv42 to i64
  %arrayidx44 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom43
  %39 = load i64, i64* %arrayidx44, align 8
  %arrayidx45 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %40 = load i64, i64* %arrayidx45, align 16
  %shr46 = lshr i64 %40, 8
  %conv47 = trunc i64 %shr46 to i8
  %idxprom48 = zext i8 %conv47 to i64
  %arrayidx49 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom48
  %41 = load i64, i64* %arrayidx49, align 8
  %xor50 = xor i64 %39, %41
  %arrayidx51 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %42 = load i64, i64* %arrayidx51, align 8
  %shr52 = lshr i64 %42, 16
  %conv53 = trunc i64 %shr52 to i8
  %idxprom54 = zext i8 %conv53 to i64
  %arrayidx55 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom54
  %43 = load i64, i64* %arrayidx55, align 8
  %xor56 = xor i64 %xor50, %43
  %arrayidx57 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %44 = load i64, i64* %arrayidx57, align 16
  %shr58 = lshr i64 %44, 24
  %conv59 = trunc i64 %shr58 to i8
  %idxprom60 = zext i8 %conv59 to i64
  %arrayidx61 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom60
  %45 = load i64, i64* %arrayidx61, align 8
  %xor62 = xor i64 %xor56, %45
  %xor63 = xor i64 %37, %xor62
  %arrayidx64 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor63, i64* %arrayidx64, align 8
  %46 = load i64*, i64** %kp, align 8
  %arrayidx65 = getelementptr inbounds i64, i64* %46, i64 2
  %47 = load i64, i64* %arrayidx65, align 8
  %arrayidx66 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %48 = load i64, i64* %arrayidx66, align 16
  %shr67 = lshr i64 %48, 0
  %conv68 = trunc i64 %shr67 to i8
  %idxprom69 = zext i8 %conv68 to i64
  %arrayidx70 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom69
  %49 = load i64, i64* %arrayidx70, align 8
  %arrayidx71 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %50 = load i64, i64* %arrayidx71, align 8
  %shr72 = lshr i64 %50, 8
  %conv73 = trunc i64 %shr72 to i8
  %idxprom74 = zext i8 %conv73 to i64
  %arrayidx75 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom74
  %51 = load i64, i64* %arrayidx75, align 8
  %xor76 = xor i64 %49, %51
  %arrayidx77 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %52 = load i64, i64* %arrayidx77, align 16
  %shr78 = lshr i64 %52, 16
  %conv79 = trunc i64 %shr78 to i8
  %idxprom80 = zext i8 %conv79 to i64
  %arrayidx81 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom80
  %53 = load i64, i64* %arrayidx81, align 8
  %xor82 = xor i64 %xor76, %53
  %arrayidx83 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %54 = load i64, i64* %arrayidx83, align 8
  %shr84 = lshr i64 %54, 24
  %conv85 = trunc i64 %shr84 to i8
  %idxprom86 = zext i8 %conv85 to i64
  %arrayidx87 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom86
  %55 = load i64, i64* %arrayidx87, align 8
  %xor88 = xor i64 %xor82, %55
  %xor89 = xor i64 %47, %xor88
  %arrayidx90 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor89, i64* %arrayidx90, align 16
  %56 = load i64*, i64** %kp, align 8
  %arrayidx91 = getelementptr inbounds i64, i64* %56, i64 3
  %57 = load i64, i64* %arrayidx91, align 8
  %arrayidx92 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %58 = load i64, i64* %arrayidx92, align 8
  %shr93 = lshr i64 %58, 0
  %conv94 = trunc i64 %shr93 to i8
  %idxprom95 = zext i8 %conv94 to i64
  %arrayidx96 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom95
  %59 = load i64, i64* %arrayidx96, align 8
  %arrayidx97 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %60 = load i64, i64* %arrayidx97, align 16
  %shr98 = lshr i64 %60, 8
  %conv99 = trunc i64 %shr98 to i8
  %idxprom100 = zext i8 %conv99 to i64
  %arrayidx101 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom100
  %61 = load i64, i64* %arrayidx101, align 8
  %xor102 = xor i64 %59, %61
  %arrayidx103 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %62 = load i64, i64* %arrayidx103, align 8
  %shr104 = lshr i64 %62, 16
  %conv105 = trunc i64 %shr104 to i8
  %idxprom106 = zext i8 %conv105 to i64
  %arrayidx107 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom106
  %63 = load i64, i64* %arrayidx107, align 8
  %xor108 = xor i64 %xor102, %63
  %arrayidx109 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %64 = load i64, i64* %arrayidx109, align 16
  %shr110 = lshr i64 %64, 24
  %conv111 = trunc i64 %shr110 to i8
  %idxprom112 = zext i8 %conv111 to i64
  %arrayidx113 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom112
  %65 = load i64, i64* %arrayidx113, align 8
  %xor114 = xor i64 %xor108, %65
  %xor115 = xor i64 %57, %xor114
  %arrayidx116 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor115, i64* %arrayidx116, align 8
  %66 = load i64*, i64** %kp, align 8
  %add.ptr117 = getelementptr inbounds i64, i64* %66, i64 4
  %arrayidx118 = getelementptr inbounds i64, i64* %add.ptr117, i64 0
  %67 = load i64, i64* %arrayidx118, align 8
  %arrayidx119 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %68 = load i64, i64* %arrayidx119, align 16
  %shr120 = lshr i64 %68, 0
  %conv121 = trunc i64 %shr120 to i8
  %idxprom122 = zext i8 %conv121 to i64
  %arrayidx123 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom122
  %69 = load i64, i64* %arrayidx123, align 8
  %arrayidx124 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %70 = load i64, i64* %arrayidx124, align 8
  %shr125 = lshr i64 %70, 8
  %conv126 = trunc i64 %shr125 to i8
  %idxprom127 = zext i8 %conv126 to i64
  %arrayidx128 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom127
  %71 = load i64, i64* %arrayidx128, align 8
  %xor129 = xor i64 %69, %71
  %arrayidx130 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %72 = load i64, i64* %arrayidx130, align 16
  %shr131 = lshr i64 %72, 16
  %conv132 = trunc i64 %shr131 to i8
  %idxprom133 = zext i8 %conv132 to i64
  %arrayidx134 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom133
  %73 = load i64, i64* %arrayidx134, align 8
  %xor135 = xor i64 %xor129, %73
  %arrayidx136 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %74 = load i64, i64* %arrayidx136, align 8
  %shr137 = lshr i64 %74, 24
  %conv138 = trunc i64 %shr137 to i8
  %idxprom139 = zext i8 %conv138 to i64
  %arrayidx140 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom139
  %75 = load i64, i64* %arrayidx140, align 8
  %xor141 = xor i64 %xor135, %75
  %xor142 = xor i64 %67, %xor141
  %arrayidx143 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor142, i64* %arrayidx143, align 16
  %76 = load i64*, i64** %kp, align 8
  %add.ptr144 = getelementptr inbounds i64, i64* %76, i64 4
  %arrayidx145 = getelementptr inbounds i64, i64* %add.ptr144, i64 1
  %77 = load i64, i64* %arrayidx145, align 8
  %arrayidx146 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %78 = load i64, i64* %arrayidx146, align 8
  %shr147 = lshr i64 %78, 0
  %conv148 = trunc i64 %shr147 to i8
  %idxprom149 = zext i8 %conv148 to i64
  %arrayidx150 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom149
  %79 = load i64, i64* %arrayidx150, align 8
  %arrayidx151 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %80 = load i64, i64* %arrayidx151, align 16
  %shr152 = lshr i64 %80, 8
  %conv153 = trunc i64 %shr152 to i8
  %idxprom154 = zext i8 %conv153 to i64
  %arrayidx155 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom154
  %81 = load i64, i64* %arrayidx155, align 8
  %xor156 = xor i64 %79, %81
  %arrayidx157 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %82 = load i64, i64* %arrayidx157, align 8
  %shr158 = lshr i64 %82, 16
  %conv159 = trunc i64 %shr158 to i8
  %idxprom160 = zext i8 %conv159 to i64
  %arrayidx161 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom160
  %83 = load i64, i64* %arrayidx161, align 8
  %xor162 = xor i64 %xor156, %83
  %arrayidx163 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %84 = load i64, i64* %arrayidx163, align 16
  %shr164 = lshr i64 %84, 24
  %conv165 = trunc i64 %shr164 to i8
  %idxprom166 = zext i8 %conv165 to i64
  %arrayidx167 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom166
  %85 = load i64, i64* %arrayidx167, align 8
  %xor168 = xor i64 %xor162, %85
  %xor169 = xor i64 %77, %xor168
  %arrayidx170 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor169, i64* %arrayidx170, align 8
  %86 = load i64*, i64** %kp, align 8
  %add.ptr171 = getelementptr inbounds i64, i64* %86, i64 4
  %arrayidx172 = getelementptr inbounds i64, i64* %add.ptr171, i64 2
  %87 = load i64, i64* %arrayidx172, align 8
  %arrayidx173 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %88 = load i64, i64* %arrayidx173, align 16
  %shr174 = lshr i64 %88, 0
  %conv175 = trunc i64 %shr174 to i8
  %idxprom176 = zext i8 %conv175 to i64
  %arrayidx177 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom176
  %89 = load i64, i64* %arrayidx177, align 8
  %arrayidx178 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %90 = load i64, i64* %arrayidx178, align 8
  %shr179 = lshr i64 %90, 8
  %conv180 = trunc i64 %shr179 to i8
  %idxprom181 = zext i8 %conv180 to i64
  %arrayidx182 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom181
  %91 = load i64, i64* %arrayidx182, align 8
  %xor183 = xor i64 %89, %91
  %arrayidx184 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %92 = load i64, i64* %arrayidx184, align 16
  %shr185 = lshr i64 %92, 16
  %conv186 = trunc i64 %shr185 to i8
  %idxprom187 = zext i8 %conv186 to i64
  %arrayidx188 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom187
  %93 = load i64, i64* %arrayidx188, align 8
  %xor189 = xor i64 %xor183, %93
  %arrayidx190 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %94 = load i64, i64* %arrayidx190, align 8
  %shr191 = lshr i64 %94, 24
  %conv192 = trunc i64 %shr191 to i8
  %idxprom193 = zext i8 %conv192 to i64
  %arrayidx194 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom193
  %95 = load i64, i64* %arrayidx194, align 8
  %xor195 = xor i64 %xor189, %95
  %xor196 = xor i64 %87, %xor195
  %arrayidx197 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor196, i64* %arrayidx197, align 16
  %96 = load i64*, i64** %kp, align 8
  %add.ptr198 = getelementptr inbounds i64, i64* %96, i64 4
  %arrayidx199 = getelementptr inbounds i64, i64* %add.ptr198, i64 3
  %97 = load i64, i64* %arrayidx199, align 8
  %arrayidx200 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %98 = load i64, i64* %arrayidx200, align 8
  %shr201 = lshr i64 %98, 0
  %conv202 = trunc i64 %shr201 to i8
  %idxprom203 = zext i8 %conv202 to i64
  %arrayidx204 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom203
  %99 = load i64, i64* %arrayidx204, align 8
  %arrayidx205 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %100 = load i64, i64* %arrayidx205, align 16
  %shr206 = lshr i64 %100, 8
  %conv207 = trunc i64 %shr206 to i8
  %idxprom208 = zext i8 %conv207 to i64
  %arrayidx209 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom208
  %101 = load i64, i64* %arrayidx209, align 8
  %xor210 = xor i64 %99, %101
  %arrayidx211 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %102 = load i64, i64* %arrayidx211, align 8
  %shr212 = lshr i64 %102, 16
  %conv213 = trunc i64 %shr212 to i8
  %idxprom214 = zext i8 %conv213 to i64
  %arrayidx215 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom214
  %103 = load i64, i64* %arrayidx215, align 8
  %xor216 = xor i64 %xor210, %103
  %arrayidx217 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %104 = load i64, i64* %arrayidx217, align 16
  %shr218 = lshr i64 %104, 24
  %conv219 = trunc i64 %shr218 to i8
  %idxprom220 = zext i8 %conv219 to i64
  %arrayidx221 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom220
  %105 = load i64, i64* %arrayidx221, align 8
  %xor222 = xor i64 %xor216, %105
  %xor223 = xor i64 %97, %xor222
  %arrayidx224 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor223, i64* %arrayidx224, align 8
  %106 = load i64*, i64** %kp, align 8
  %add.ptr225 = getelementptr inbounds i64, i64* %106, i64 8
  store i64* %add.ptr225, i64** %kp, align 8
  br label %sw.bb226

sw.bb226:                                         ; preds = %if.end, %sw.bb
  %107 = load i64*, i64** %kp, align 8
  %arrayidx227 = getelementptr inbounds i64, i64* %107, i64 0
  %108 = load i64, i64* %arrayidx227, align 8
  %arrayidx228 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %109 = load i64, i64* %arrayidx228, align 16
  %shr229 = lshr i64 %109, 0
  %conv230 = trunc i64 %shr229 to i8
  %idxprom231 = zext i8 %conv230 to i64
  %arrayidx232 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom231
  %110 = load i64, i64* %arrayidx232, align 8
  %arrayidx233 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %111 = load i64, i64* %arrayidx233, align 8
  %shr234 = lshr i64 %111, 8
  %conv235 = trunc i64 %shr234 to i8
  %idxprom236 = zext i8 %conv235 to i64
  %arrayidx237 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom236
  %112 = load i64, i64* %arrayidx237, align 8
  %xor238 = xor i64 %110, %112
  %arrayidx239 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %113 = load i64, i64* %arrayidx239, align 16
  %shr240 = lshr i64 %113, 16
  %conv241 = trunc i64 %shr240 to i8
  %idxprom242 = zext i8 %conv241 to i64
  %arrayidx243 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom242
  %114 = load i64, i64* %arrayidx243, align 8
  %xor244 = xor i64 %xor238, %114
  %arrayidx245 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %115 = load i64, i64* %arrayidx245, align 8
  %shr246 = lshr i64 %115, 24
  %conv247 = trunc i64 %shr246 to i8
  %idxprom248 = zext i8 %conv247 to i64
  %arrayidx249 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom248
  %116 = load i64, i64* %arrayidx249, align 8
  %xor250 = xor i64 %xor244, %116
  %xor251 = xor i64 %108, %xor250
  %arrayidx252 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor251, i64* %arrayidx252, align 16
  %117 = load i64*, i64** %kp, align 8
  %arrayidx253 = getelementptr inbounds i64, i64* %117, i64 1
  %118 = load i64, i64* %arrayidx253, align 8
  %arrayidx254 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %119 = load i64, i64* %arrayidx254, align 8
  %shr255 = lshr i64 %119, 0
  %conv256 = trunc i64 %shr255 to i8
  %idxprom257 = zext i8 %conv256 to i64
  %arrayidx258 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom257
  %120 = load i64, i64* %arrayidx258, align 8
  %arrayidx259 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %121 = load i64, i64* %arrayidx259, align 16
  %shr260 = lshr i64 %121, 8
  %conv261 = trunc i64 %shr260 to i8
  %idxprom262 = zext i8 %conv261 to i64
  %arrayidx263 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom262
  %122 = load i64, i64* %arrayidx263, align 8
  %xor264 = xor i64 %120, %122
  %arrayidx265 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %123 = load i64, i64* %arrayidx265, align 8
  %shr266 = lshr i64 %123, 16
  %conv267 = trunc i64 %shr266 to i8
  %idxprom268 = zext i8 %conv267 to i64
  %arrayidx269 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom268
  %124 = load i64, i64* %arrayidx269, align 8
  %xor270 = xor i64 %xor264, %124
  %arrayidx271 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %125 = load i64, i64* %arrayidx271, align 16
  %shr272 = lshr i64 %125, 24
  %conv273 = trunc i64 %shr272 to i8
  %idxprom274 = zext i8 %conv273 to i64
  %arrayidx275 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom274
  %126 = load i64, i64* %arrayidx275, align 8
  %xor276 = xor i64 %xor270, %126
  %xor277 = xor i64 %118, %xor276
  %arrayidx278 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor277, i64* %arrayidx278, align 8
  %127 = load i64*, i64** %kp, align 8
  %arrayidx279 = getelementptr inbounds i64, i64* %127, i64 2
  %128 = load i64, i64* %arrayidx279, align 8
  %arrayidx280 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %129 = load i64, i64* %arrayidx280, align 16
  %shr281 = lshr i64 %129, 0
  %conv282 = trunc i64 %shr281 to i8
  %idxprom283 = zext i8 %conv282 to i64
  %arrayidx284 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom283
  %130 = load i64, i64* %arrayidx284, align 8
  %arrayidx285 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %131 = load i64, i64* %arrayidx285, align 8
  %shr286 = lshr i64 %131, 8
  %conv287 = trunc i64 %shr286 to i8
  %idxprom288 = zext i8 %conv287 to i64
  %arrayidx289 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom288
  %132 = load i64, i64* %arrayidx289, align 8
  %xor290 = xor i64 %130, %132
  %arrayidx291 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %133 = load i64, i64* %arrayidx291, align 16
  %shr292 = lshr i64 %133, 16
  %conv293 = trunc i64 %shr292 to i8
  %idxprom294 = zext i8 %conv293 to i64
  %arrayidx295 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom294
  %134 = load i64, i64* %arrayidx295, align 8
  %xor296 = xor i64 %xor290, %134
  %arrayidx297 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %135 = load i64, i64* %arrayidx297, align 8
  %shr298 = lshr i64 %135, 24
  %conv299 = trunc i64 %shr298 to i8
  %idxprom300 = zext i8 %conv299 to i64
  %arrayidx301 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom300
  %136 = load i64, i64* %arrayidx301, align 8
  %xor302 = xor i64 %xor296, %136
  %xor303 = xor i64 %128, %xor302
  %arrayidx304 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor303, i64* %arrayidx304, align 16
  %137 = load i64*, i64** %kp, align 8
  %arrayidx305 = getelementptr inbounds i64, i64* %137, i64 3
  %138 = load i64, i64* %arrayidx305, align 8
  %arrayidx306 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %139 = load i64, i64* %arrayidx306, align 8
  %shr307 = lshr i64 %139, 0
  %conv308 = trunc i64 %shr307 to i8
  %idxprom309 = zext i8 %conv308 to i64
  %arrayidx310 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom309
  %140 = load i64, i64* %arrayidx310, align 8
  %arrayidx311 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %141 = load i64, i64* %arrayidx311, align 16
  %shr312 = lshr i64 %141, 8
  %conv313 = trunc i64 %shr312 to i8
  %idxprom314 = zext i8 %conv313 to i64
  %arrayidx315 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom314
  %142 = load i64, i64* %arrayidx315, align 8
  %xor316 = xor i64 %140, %142
  %arrayidx317 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %143 = load i64, i64* %arrayidx317, align 8
  %shr318 = lshr i64 %143, 16
  %conv319 = trunc i64 %shr318 to i8
  %idxprom320 = zext i8 %conv319 to i64
  %arrayidx321 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom320
  %144 = load i64, i64* %arrayidx321, align 8
  %xor322 = xor i64 %xor316, %144
  %arrayidx323 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %145 = load i64, i64* %arrayidx323, align 16
  %shr324 = lshr i64 %145, 24
  %conv325 = trunc i64 %shr324 to i8
  %idxprom326 = zext i8 %conv325 to i64
  %arrayidx327 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom326
  %146 = load i64, i64* %arrayidx327, align 8
  %xor328 = xor i64 %xor322, %146
  %xor329 = xor i64 %138, %xor328
  %arrayidx330 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor329, i64* %arrayidx330, align 8
  %147 = load i64*, i64** %kp, align 8
  %add.ptr331 = getelementptr inbounds i64, i64* %147, i64 4
  %arrayidx332 = getelementptr inbounds i64, i64* %add.ptr331, i64 0
  %148 = load i64, i64* %arrayidx332, align 8
  %arrayidx333 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %149 = load i64, i64* %arrayidx333, align 16
  %shr334 = lshr i64 %149, 0
  %conv335 = trunc i64 %shr334 to i8
  %idxprom336 = zext i8 %conv335 to i64
  %arrayidx337 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom336
  %150 = load i64, i64* %arrayidx337, align 8
  %arrayidx338 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %151 = load i64, i64* %arrayidx338, align 8
  %shr339 = lshr i64 %151, 8
  %conv340 = trunc i64 %shr339 to i8
  %idxprom341 = zext i8 %conv340 to i64
  %arrayidx342 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom341
  %152 = load i64, i64* %arrayidx342, align 8
  %xor343 = xor i64 %150, %152
  %arrayidx344 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %153 = load i64, i64* %arrayidx344, align 16
  %shr345 = lshr i64 %153, 16
  %conv346 = trunc i64 %shr345 to i8
  %idxprom347 = zext i8 %conv346 to i64
  %arrayidx348 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom347
  %154 = load i64, i64* %arrayidx348, align 8
  %xor349 = xor i64 %xor343, %154
  %arrayidx350 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %155 = load i64, i64* %arrayidx350, align 8
  %shr351 = lshr i64 %155, 24
  %conv352 = trunc i64 %shr351 to i8
  %idxprom353 = zext i8 %conv352 to i64
  %arrayidx354 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom353
  %156 = load i64, i64* %arrayidx354, align 8
  %xor355 = xor i64 %xor349, %156
  %xor356 = xor i64 %148, %xor355
  %arrayidx357 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor356, i64* %arrayidx357, align 16
  %157 = load i64*, i64** %kp, align 8
  %add.ptr358 = getelementptr inbounds i64, i64* %157, i64 4
  %arrayidx359 = getelementptr inbounds i64, i64* %add.ptr358, i64 1
  %158 = load i64, i64* %arrayidx359, align 8
  %arrayidx360 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %159 = load i64, i64* %arrayidx360, align 8
  %shr361 = lshr i64 %159, 0
  %conv362 = trunc i64 %shr361 to i8
  %idxprom363 = zext i8 %conv362 to i64
  %arrayidx364 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom363
  %160 = load i64, i64* %arrayidx364, align 8
  %arrayidx365 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %161 = load i64, i64* %arrayidx365, align 16
  %shr366 = lshr i64 %161, 8
  %conv367 = trunc i64 %shr366 to i8
  %idxprom368 = zext i8 %conv367 to i64
  %arrayidx369 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom368
  %162 = load i64, i64* %arrayidx369, align 8
  %xor370 = xor i64 %160, %162
  %arrayidx371 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %163 = load i64, i64* %arrayidx371, align 8
  %shr372 = lshr i64 %163, 16
  %conv373 = trunc i64 %shr372 to i8
  %idxprom374 = zext i8 %conv373 to i64
  %arrayidx375 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom374
  %164 = load i64, i64* %arrayidx375, align 8
  %xor376 = xor i64 %xor370, %164
  %arrayidx377 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %165 = load i64, i64* %arrayidx377, align 16
  %shr378 = lshr i64 %165, 24
  %conv379 = trunc i64 %shr378 to i8
  %idxprom380 = zext i8 %conv379 to i64
  %arrayidx381 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom380
  %166 = load i64, i64* %arrayidx381, align 8
  %xor382 = xor i64 %xor376, %166
  %xor383 = xor i64 %158, %xor382
  %arrayidx384 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor383, i64* %arrayidx384, align 8
  %167 = load i64*, i64** %kp, align 8
  %add.ptr385 = getelementptr inbounds i64, i64* %167, i64 4
  %arrayidx386 = getelementptr inbounds i64, i64* %add.ptr385, i64 2
  %168 = load i64, i64* %arrayidx386, align 8
  %arrayidx387 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %169 = load i64, i64* %arrayidx387, align 16
  %shr388 = lshr i64 %169, 0
  %conv389 = trunc i64 %shr388 to i8
  %idxprom390 = zext i8 %conv389 to i64
  %arrayidx391 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom390
  %170 = load i64, i64* %arrayidx391, align 8
  %arrayidx392 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %171 = load i64, i64* %arrayidx392, align 8
  %shr393 = lshr i64 %171, 8
  %conv394 = trunc i64 %shr393 to i8
  %idxprom395 = zext i8 %conv394 to i64
  %arrayidx396 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom395
  %172 = load i64, i64* %arrayidx396, align 8
  %xor397 = xor i64 %170, %172
  %arrayidx398 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %173 = load i64, i64* %arrayidx398, align 16
  %shr399 = lshr i64 %173, 16
  %conv400 = trunc i64 %shr399 to i8
  %idxprom401 = zext i8 %conv400 to i64
  %arrayidx402 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom401
  %174 = load i64, i64* %arrayidx402, align 8
  %xor403 = xor i64 %xor397, %174
  %arrayidx404 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %175 = load i64, i64* %arrayidx404, align 8
  %shr405 = lshr i64 %175, 24
  %conv406 = trunc i64 %shr405 to i8
  %idxprom407 = zext i8 %conv406 to i64
  %arrayidx408 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom407
  %176 = load i64, i64* %arrayidx408, align 8
  %xor409 = xor i64 %xor403, %176
  %xor410 = xor i64 %168, %xor409
  %arrayidx411 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor410, i64* %arrayidx411, align 16
  %177 = load i64*, i64** %kp, align 8
  %add.ptr412 = getelementptr inbounds i64, i64* %177, i64 4
  %arrayidx413 = getelementptr inbounds i64, i64* %add.ptr412, i64 3
  %178 = load i64, i64* %arrayidx413, align 8
  %arrayidx414 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %179 = load i64, i64* %arrayidx414, align 8
  %shr415 = lshr i64 %179, 0
  %conv416 = trunc i64 %shr415 to i8
  %idxprom417 = zext i8 %conv416 to i64
  %arrayidx418 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom417
  %180 = load i64, i64* %arrayidx418, align 8
  %arrayidx419 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %181 = load i64, i64* %arrayidx419, align 16
  %shr420 = lshr i64 %181, 8
  %conv421 = trunc i64 %shr420 to i8
  %idxprom422 = zext i8 %conv421 to i64
  %arrayidx423 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom422
  %182 = load i64, i64* %arrayidx423, align 8
  %xor424 = xor i64 %180, %182
  %arrayidx425 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %183 = load i64, i64* %arrayidx425, align 8
  %shr426 = lshr i64 %183, 16
  %conv427 = trunc i64 %shr426 to i8
  %idxprom428 = zext i8 %conv427 to i64
  %arrayidx429 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom428
  %184 = load i64, i64* %arrayidx429, align 8
  %xor430 = xor i64 %xor424, %184
  %arrayidx431 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %185 = load i64, i64* %arrayidx431, align 16
  %shr432 = lshr i64 %185, 24
  %conv433 = trunc i64 %shr432 to i8
  %idxprom434 = zext i8 %conv433 to i64
  %arrayidx435 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom434
  %186 = load i64, i64* %arrayidx435, align 8
  %xor436 = xor i64 %xor430, %186
  %xor437 = xor i64 %178, %xor436
  %arrayidx438 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor437, i64* %arrayidx438, align 8
  %187 = load i64*, i64** %kp, align 8
  %add.ptr439 = getelementptr inbounds i64, i64* %187, i64 8
  store i64* %add.ptr439, i64** %kp, align 8
  br label %sw.bb440

sw.bb440:                                         ; preds = %if.end, %sw.bb226
  %188 = load i64*, i64** %kp, align 8
  %arrayidx441 = getelementptr inbounds i64, i64* %188, i64 0
  %189 = load i64, i64* %arrayidx441, align 8
  %arrayidx442 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %190 = load i64, i64* %arrayidx442, align 16
  %shr443 = lshr i64 %190, 0
  %conv444 = trunc i64 %shr443 to i8
  %idxprom445 = zext i8 %conv444 to i64
  %arrayidx446 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom445
  %191 = load i64, i64* %arrayidx446, align 8
  %arrayidx447 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %192 = load i64, i64* %arrayidx447, align 8
  %shr448 = lshr i64 %192, 8
  %conv449 = trunc i64 %shr448 to i8
  %idxprom450 = zext i8 %conv449 to i64
  %arrayidx451 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom450
  %193 = load i64, i64* %arrayidx451, align 8
  %xor452 = xor i64 %191, %193
  %arrayidx453 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %194 = load i64, i64* %arrayidx453, align 16
  %shr454 = lshr i64 %194, 16
  %conv455 = trunc i64 %shr454 to i8
  %idxprom456 = zext i8 %conv455 to i64
  %arrayidx457 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom456
  %195 = load i64, i64* %arrayidx457, align 8
  %xor458 = xor i64 %xor452, %195
  %arrayidx459 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %196 = load i64, i64* %arrayidx459, align 8
  %shr460 = lshr i64 %196, 24
  %conv461 = trunc i64 %shr460 to i8
  %idxprom462 = zext i8 %conv461 to i64
  %arrayidx463 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom462
  %197 = load i64, i64* %arrayidx463, align 8
  %xor464 = xor i64 %xor458, %197
  %xor465 = xor i64 %189, %xor464
  %arrayidx466 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor465, i64* %arrayidx466, align 16
  %198 = load i64*, i64** %kp, align 8
  %arrayidx467 = getelementptr inbounds i64, i64* %198, i64 1
  %199 = load i64, i64* %arrayidx467, align 8
  %arrayidx468 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %200 = load i64, i64* %arrayidx468, align 8
  %shr469 = lshr i64 %200, 0
  %conv470 = trunc i64 %shr469 to i8
  %idxprom471 = zext i8 %conv470 to i64
  %arrayidx472 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom471
  %201 = load i64, i64* %arrayidx472, align 8
  %arrayidx473 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %202 = load i64, i64* %arrayidx473, align 16
  %shr474 = lshr i64 %202, 8
  %conv475 = trunc i64 %shr474 to i8
  %idxprom476 = zext i8 %conv475 to i64
  %arrayidx477 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom476
  %203 = load i64, i64* %arrayidx477, align 8
  %xor478 = xor i64 %201, %203
  %arrayidx479 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %204 = load i64, i64* %arrayidx479, align 8
  %shr480 = lshr i64 %204, 16
  %conv481 = trunc i64 %shr480 to i8
  %idxprom482 = zext i8 %conv481 to i64
  %arrayidx483 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom482
  %205 = load i64, i64* %arrayidx483, align 8
  %xor484 = xor i64 %xor478, %205
  %arrayidx485 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %206 = load i64, i64* %arrayidx485, align 16
  %shr486 = lshr i64 %206, 24
  %conv487 = trunc i64 %shr486 to i8
  %idxprom488 = zext i8 %conv487 to i64
  %arrayidx489 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom488
  %207 = load i64, i64* %arrayidx489, align 8
  %xor490 = xor i64 %xor484, %207
  %xor491 = xor i64 %199, %xor490
  %arrayidx492 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor491, i64* %arrayidx492, align 8
  %208 = load i64*, i64** %kp, align 8
  %arrayidx493 = getelementptr inbounds i64, i64* %208, i64 2
  %209 = load i64, i64* %arrayidx493, align 8
  %arrayidx494 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %210 = load i64, i64* %arrayidx494, align 16
  %shr495 = lshr i64 %210, 0
  %conv496 = trunc i64 %shr495 to i8
  %idxprom497 = zext i8 %conv496 to i64
  %arrayidx498 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom497
  %211 = load i64, i64* %arrayidx498, align 8
  %arrayidx499 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %212 = load i64, i64* %arrayidx499, align 8
  %shr500 = lshr i64 %212, 8
  %conv501 = trunc i64 %shr500 to i8
  %idxprom502 = zext i8 %conv501 to i64
  %arrayidx503 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom502
  %213 = load i64, i64* %arrayidx503, align 8
  %xor504 = xor i64 %211, %213
  %arrayidx505 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %214 = load i64, i64* %arrayidx505, align 16
  %shr506 = lshr i64 %214, 16
  %conv507 = trunc i64 %shr506 to i8
  %idxprom508 = zext i8 %conv507 to i64
  %arrayidx509 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom508
  %215 = load i64, i64* %arrayidx509, align 8
  %xor510 = xor i64 %xor504, %215
  %arrayidx511 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %216 = load i64, i64* %arrayidx511, align 8
  %shr512 = lshr i64 %216, 24
  %conv513 = trunc i64 %shr512 to i8
  %idxprom514 = zext i8 %conv513 to i64
  %arrayidx515 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom514
  %217 = load i64, i64* %arrayidx515, align 8
  %xor516 = xor i64 %xor510, %217
  %xor517 = xor i64 %209, %xor516
  %arrayidx518 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor517, i64* %arrayidx518, align 16
  %218 = load i64*, i64** %kp, align 8
  %arrayidx519 = getelementptr inbounds i64, i64* %218, i64 3
  %219 = load i64, i64* %arrayidx519, align 8
  %arrayidx520 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %220 = load i64, i64* %arrayidx520, align 8
  %shr521 = lshr i64 %220, 0
  %conv522 = trunc i64 %shr521 to i8
  %idxprom523 = zext i8 %conv522 to i64
  %arrayidx524 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom523
  %221 = load i64, i64* %arrayidx524, align 8
  %arrayidx525 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %222 = load i64, i64* %arrayidx525, align 16
  %shr526 = lshr i64 %222, 8
  %conv527 = trunc i64 %shr526 to i8
  %idxprom528 = zext i8 %conv527 to i64
  %arrayidx529 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom528
  %223 = load i64, i64* %arrayidx529, align 8
  %xor530 = xor i64 %221, %223
  %arrayidx531 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %224 = load i64, i64* %arrayidx531, align 8
  %shr532 = lshr i64 %224, 16
  %conv533 = trunc i64 %shr532 to i8
  %idxprom534 = zext i8 %conv533 to i64
  %arrayidx535 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom534
  %225 = load i64, i64* %arrayidx535, align 8
  %xor536 = xor i64 %xor530, %225
  %arrayidx537 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %226 = load i64, i64* %arrayidx537, align 16
  %shr538 = lshr i64 %226, 24
  %conv539 = trunc i64 %shr538 to i8
  %idxprom540 = zext i8 %conv539 to i64
  %arrayidx541 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom540
  %227 = load i64, i64* %arrayidx541, align 8
  %xor542 = xor i64 %xor536, %227
  %xor543 = xor i64 %219, %xor542
  %arrayidx544 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor543, i64* %arrayidx544, align 8
  %228 = load i64*, i64** %kp, align 8
  %add.ptr545 = getelementptr inbounds i64, i64* %228, i64 4
  %arrayidx546 = getelementptr inbounds i64, i64* %add.ptr545, i64 0
  %229 = load i64, i64* %arrayidx546, align 8
  %arrayidx547 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %230 = load i64, i64* %arrayidx547, align 16
  %shr548 = lshr i64 %230, 0
  %conv549 = trunc i64 %shr548 to i8
  %idxprom550 = zext i8 %conv549 to i64
  %arrayidx551 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom550
  %231 = load i64, i64* %arrayidx551, align 8
  %arrayidx552 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %232 = load i64, i64* %arrayidx552, align 8
  %shr553 = lshr i64 %232, 8
  %conv554 = trunc i64 %shr553 to i8
  %idxprom555 = zext i8 %conv554 to i64
  %arrayidx556 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom555
  %233 = load i64, i64* %arrayidx556, align 8
  %xor557 = xor i64 %231, %233
  %arrayidx558 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %234 = load i64, i64* %arrayidx558, align 16
  %shr559 = lshr i64 %234, 16
  %conv560 = trunc i64 %shr559 to i8
  %idxprom561 = zext i8 %conv560 to i64
  %arrayidx562 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom561
  %235 = load i64, i64* %arrayidx562, align 8
  %xor563 = xor i64 %xor557, %235
  %arrayidx564 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %236 = load i64, i64* %arrayidx564, align 8
  %shr565 = lshr i64 %236, 24
  %conv566 = trunc i64 %shr565 to i8
  %idxprom567 = zext i8 %conv566 to i64
  %arrayidx568 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom567
  %237 = load i64, i64* %arrayidx568, align 8
  %xor569 = xor i64 %xor563, %237
  %xor570 = xor i64 %229, %xor569
  %arrayidx571 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor570, i64* %arrayidx571, align 16
  %238 = load i64*, i64** %kp, align 8
  %add.ptr572 = getelementptr inbounds i64, i64* %238, i64 4
  %arrayidx573 = getelementptr inbounds i64, i64* %add.ptr572, i64 1
  %239 = load i64, i64* %arrayidx573, align 8
  %arrayidx574 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %240 = load i64, i64* %arrayidx574, align 8
  %shr575 = lshr i64 %240, 0
  %conv576 = trunc i64 %shr575 to i8
  %idxprom577 = zext i8 %conv576 to i64
  %arrayidx578 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom577
  %241 = load i64, i64* %arrayidx578, align 8
  %arrayidx579 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %242 = load i64, i64* %arrayidx579, align 16
  %shr580 = lshr i64 %242, 8
  %conv581 = trunc i64 %shr580 to i8
  %idxprom582 = zext i8 %conv581 to i64
  %arrayidx583 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom582
  %243 = load i64, i64* %arrayidx583, align 8
  %xor584 = xor i64 %241, %243
  %arrayidx585 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %244 = load i64, i64* %arrayidx585, align 8
  %shr586 = lshr i64 %244, 16
  %conv587 = trunc i64 %shr586 to i8
  %idxprom588 = zext i8 %conv587 to i64
  %arrayidx589 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom588
  %245 = load i64, i64* %arrayidx589, align 8
  %xor590 = xor i64 %xor584, %245
  %arrayidx591 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %246 = load i64, i64* %arrayidx591, align 16
  %shr592 = lshr i64 %246, 24
  %conv593 = trunc i64 %shr592 to i8
  %idxprom594 = zext i8 %conv593 to i64
  %arrayidx595 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom594
  %247 = load i64, i64* %arrayidx595, align 8
  %xor596 = xor i64 %xor590, %247
  %xor597 = xor i64 %239, %xor596
  %arrayidx598 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor597, i64* %arrayidx598, align 8
  %248 = load i64*, i64** %kp, align 8
  %add.ptr599 = getelementptr inbounds i64, i64* %248, i64 4
  %arrayidx600 = getelementptr inbounds i64, i64* %add.ptr599, i64 2
  %249 = load i64, i64* %arrayidx600, align 8
  %arrayidx601 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %250 = load i64, i64* %arrayidx601, align 16
  %shr602 = lshr i64 %250, 0
  %conv603 = trunc i64 %shr602 to i8
  %idxprom604 = zext i8 %conv603 to i64
  %arrayidx605 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom604
  %251 = load i64, i64* %arrayidx605, align 8
  %arrayidx606 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %252 = load i64, i64* %arrayidx606, align 8
  %shr607 = lshr i64 %252, 8
  %conv608 = trunc i64 %shr607 to i8
  %idxprom609 = zext i8 %conv608 to i64
  %arrayidx610 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom609
  %253 = load i64, i64* %arrayidx610, align 8
  %xor611 = xor i64 %251, %253
  %arrayidx612 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %254 = load i64, i64* %arrayidx612, align 16
  %shr613 = lshr i64 %254, 16
  %conv614 = trunc i64 %shr613 to i8
  %idxprom615 = zext i8 %conv614 to i64
  %arrayidx616 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom615
  %255 = load i64, i64* %arrayidx616, align 8
  %xor617 = xor i64 %xor611, %255
  %arrayidx618 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %256 = load i64, i64* %arrayidx618, align 8
  %shr619 = lshr i64 %256, 24
  %conv620 = trunc i64 %shr619 to i8
  %idxprom621 = zext i8 %conv620 to i64
  %arrayidx622 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom621
  %257 = load i64, i64* %arrayidx622, align 8
  %xor623 = xor i64 %xor617, %257
  %xor624 = xor i64 %249, %xor623
  %arrayidx625 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor624, i64* %arrayidx625, align 16
  %258 = load i64*, i64** %kp, align 8
  %add.ptr626 = getelementptr inbounds i64, i64* %258, i64 4
  %arrayidx627 = getelementptr inbounds i64, i64* %add.ptr626, i64 3
  %259 = load i64, i64* %arrayidx627, align 8
  %arrayidx628 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %260 = load i64, i64* %arrayidx628, align 8
  %shr629 = lshr i64 %260, 0
  %conv630 = trunc i64 %shr629 to i8
  %idxprom631 = zext i8 %conv630 to i64
  %arrayidx632 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom631
  %261 = load i64, i64* %arrayidx632, align 8
  %arrayidx633 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %262 = load i64, i64* %arrayidx633, align 16
  %shr634 = lshr i64 %262, 8
  %conv635 = trunc i64 %shr634 to i8
  %idxprom636 = zext i8 %conv635 to i64
  %arrayidx637 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom636
  %263 = load i64, i64* %arrayidx637, align 8
  %xor638 = xor i64 %261, %263
  %arrayidx639 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %264 = load i64, i64* %arrayidx639, align 8
  %shr640 = lshr i64 %264, 16
  %conv641 = trunc i64 %shr640 to i8
  %idxprom642 = zext i8 %conv641 to i64
  %arrayidx643 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom642
  %265 = load i64, i64* %arrayidx643, align 8
  %xor644 = xor i64 %xor638, %265
  %arrayidx645 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %266 = load i64, i64* %arrayidx645, align 16
  %shr646 = lshr i64 %266, 24
  %conv647 = trunc i64 %shr646 to i8
  %idxprom648 = zext i8 %conv647 to i64
  %arrayidx649 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom648
  %267 = load i64, i64* %arrayidx649, align 8
  %xor650 = xor i64 %xor644, %267
  %xor651 = xor i64 %259, %xor650
  %arrayidx652 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor651, i64* %arrayidx652, align 8
  %268 = load i64*, i64** %kp, align 8
  %add.ptr653 = getelementptr inbounds i64, i64* %268, i64 8
  %arrayidx654 = getelementptr inbounds i64, i64* %add.ptr653, i64 0
  %269 = load i64, i64* %arrayidx654, align 8
  %arrayidx655 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %270 = load i64, i64* %arrayidx655, align 16
  %shr656 = lshr i64 %270, 0
  %conv657 = trunc i64 %shr656 to i8
  %idxprom658 = zext i8 %conv657 to i64
  %arrayidx659 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom658
  %271 = load i64, i64* %arrayidx659, align 8
  %arrayidx660 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %272 = load i64, i64* %arrayidx660, align 8
  %shr661 = lshr i64 %272, 8
  %conv662 = trunc i64 %shr661 to i8
  %idxprom663 = zext i8 %conv662 to i64
  %arrayidx664 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom663
  %273 = load i64, i64* %arrayidx664, align 8
  %xor665 = xor i64 %271, %273
  %arrayidx666 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %274 = load i64, i64* %arrayidx666, align 16
  %shr667 = lshr i64 %274, 16
  %conv668 = trunc i64 %shr667 to i8
  %idxprom669 = zext i8 %conv668 to i64
  %arrayidx670 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom669
  %275 = load i64, i64* %arrayidx670, align 8
  %xor671 = xor i64 %xor665, %275
  %arrayidx672 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %276 = load i64, i64* %arrayidx672, align 8
  %shr673 = lshr i64 %276, 24
  %conv674 = trunc i64 %shr673 to i8
  %idxprom675 = zext i8 %conv674 to i64
  %arrayidx676 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom675
  %277 = load i64, i64* %arrayidx676, align 8
  %xor677 = xor i64 %xor671, %277
  %xor678 = xor i64 %269, %xor677
  %arrayidx679 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor678, i64* %arrayidx679, align 16
  %278 = load i64*, i64** %kp, align 8
  %add.ptr680 = getelementptr inbounds i64, i64* %278, i64 8
  %arrayidx681 = getelementptr inbounds i64, i64* %add.ptr680, i64 1
  %279 = load i64, i64* %arrayidx681, align 8
  %arrayidx682 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %280 = load i64, i64* %arrayidx682, align 8
  %shr683 = lshr i64 %280, 0
  %conv684 = trunc i64 %shr683 to i8
  %idxprom685 = zext i8 %conv684 to i64
  %arrayidx686 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom685
  %281 = load i64, i64* %arrayidx686, align 8
  %arrayidx687 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %282 = load i64, i64* %arrayidx687, align 16
  %shr688 = lshr i64 %282, 8
  %conv689 = trunc i64 %shr688 to i8
  %idxprom690 = zext i8 %conv689 to i64
  %arrayidx691 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom690
  %283 = load i64, i64* %arrayidx691, align 8
  %xor692 = xor i64 %281, %283
  %arrayidx693 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %284 = load i64, i64* %arrayidx693, align 8
  %shr694 = lshr i64 %284, 16
  %conv695 = trunc i64 %shr694 to i8
  %idxprom696 = zext i8 %conv695 to i64
  %arrayidx697 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom696
  %285 = load i64, i64* %arrayidx697, align 8
  %xor698 = xor i64 %xor692, %285
  %arrayidx699 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %286 = load i64, i64* %arrayidx699, align 16
  %shr700 = lshr i64 %286, 24
  %conv701 = trunc i64 %shr700 to i8
  %idxprom702 = zext i8 %conv701 to i64
  %arrayidx703 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom702
  %287 = load i64, i64* %arrayidx703, align 8
  %xor704 = xor i64 %xor698, %287
  %xor705 = xor i64 %279, %xor704
  %arrayidx706 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor705, i64* %arrayidx706, align 8
  %288 = load i64*, i64** %kp, align 8
  %add.ptr707 = getelementptr inbounds i64, i64* %288, i64 8
  %arrayidx708 = getelementptr inbounds i64, i64* %add.ptr707, i64 2
  %289 = load i64, i64* %arrayidx708, align 8
  %arrayidx709 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %290 = load i64, i64* %arrayidx709, align 16
  %shr710 = lshr i64 %290, 0
  %conv711 = trunc i64 %shr710 to i8
  %idxprom712 = zext i8 %conv711 to i64
  %arrayidx713 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom712
  %291 = load i64, i64* %arrayidx713, align 8
  %arrayidx714 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %292 = load i64, i64* %arrayidx714, align 8
  %shr715 = lshr i64 %292, 8
  %conv716 = trunc i64 %shr715 to i8
  %idxprom717 = zext i8 %conv716 to i64
  %arrayidx718 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom717
  %293 = load i64, i64* %arrayidx718, align 8
  %xor719 = xor i64 %291, %293
  %arrayidx720 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %294 = load i64, i64* %arrayidx720, align 16
  %shr721 = lshr i64 %294, 16
  %conv722 = trunc i64 %shr721 to i8
  %idxprom723 = zext i8 %conv722 to i64
  %arrayidx724 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom723
  %295 = load i64, i64* %arrayidx724, align 8
  %xor725 = xor i64 %xor719, %295
  %arrayidx726 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %296 = load i64, i64* %arrayidx726, align 8
  %shr727 = lshr i64 %296, 24
  %conv728 = trunc i64 %shr727 to i8
  %idxprom729 = zext i8 %conv728 to i64
  %arrayidx730 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom729
  %297 = load i64, i64* %arrayidx730, align 8
  %xor731 = xor i64 %xor725, %297
  %xor732 = xor i64 %289, %xor731
  %arrayidx733 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor732, i64* %arrayidx733, align 16
  %298 = load i64*, i64** %kp, align 8
  %add.ptr734 = getelementptr inbounds i64, i64* %298, i64 8
  %arrayidx735 = getelementptr inbounds i64, i64* %add.ptr734, i64 3
  %299 = load i64, i64* %arrayidx735, align 8
  %arrayidx736 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %300 = load i64, i64* %arrayidx736, align 8
  %shr737 = lshr i64 %300, 0
  %conv738 = trunc i64 %shr737 to i8
  %idxprom739 = zext i8 %conv738 to i64
  %arrayidx740 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom739
  %301 = load i64, i64* %arrayidx740, align 8
  %arrayidx741 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %302 = load i64, i64* %arrayidx741, align 16
  %shr742 = lshr i64 %302, 8
  %conv743 = trunc i64 %shr742 to i8
  %idxprom744 = zext i8 %conv743 to i64
  %arrayidx745 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom744
  %303 = load i64, i64* %arrayidx745, align 8
  %xor746 = xor i64 %301, %303
  %arrayidx747 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %304 = load i64, i64* %arrayidx747, align 8
  %shr748 = lshr i64 %304, 16
  %conv749 = trunc i64 %shr748 to i8
  %idxprom750 = zext i8 %conv749 to i64
  %arrayidx751 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom750
  %305 = load i64, i64* %arrayidx751, align 8
  %xor752 = xor i64 %xor746, %305
  %arrayidx753 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %306 = load i64, i64* %arrayidx753, align 16
  %shr754 = lshr i64 %306, 24
  %conv755 = trunc i64 %shr754 to i8
  %idxprom756 = zext i8 %conv755 to i64
  %arrayidx757 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom756
  %307 = load i64, i64* %arrayidx757, align 8
  %xor758 = xor i64 %xor752, %307
  %xor759 = xor i64 %299, %xor758
  %arrayidx760 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor759, i64* %arrayidx760, align 8
  %308 = load i64*, i64** %kp, align 8
  %add.ptr761 = getelementptr inbounds i64, i64* %308, i64 12
  %arrayidx762 = getelementptr inbounds i64, i64* %add.ptr761, i64 0
  %309 = load i64, i64* %arrayidx762, align 8
  %arrayidx763 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %310 = load i64, i64* %arrayidx763, align 16
  %shr764 = lshr i64 %310, 0
  %conv765 = trunc i64 %shr764 to i8
  %idxprom766 = zext i8 %conv765 to i64
  %arrayidx767 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom766
  %311 = load i64, i64* %arrayidx767, align 8
  %arrayidx768 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %312 = load i64, i64* %arrayidx768, align 8
  %shr769 = lshr i64 %312, 8
  %conv770 = trunc i64 %shr769 to i8
  %idxprom771 = zext i8 %conv770 to i64
  %arrayidx772 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom771
  %313 = load i64, i64* %arrayidx772, align 8
  %xor773 = xor i64 %311, %313
  %arrayidx774 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %314 = load i64, i64* %arrayidx774, align 16
  %shr775 = lshr i64 %314, 16
  %conv776 = trunc i64 %shr775 to i8
  %idxprom777 = zext i8 %conv776 to i64
  %arrayidx778 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom777
  %315 = load i64, i64* %arrayidx778, align 8
  %xor779 = xor i64 %xor773, %315
  %arrayidx780 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %316 = load i64, i64* %arrayidx780, align 8
  %shr781 = lshr i64 %316, 24
  %conv782 = trunc i64 %shr781 to i8
  %idxprom783 = zext i8 %conv782 to i64
  %arrayidx784 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom783
  %317 = load i64, i64* %arrayidx784, align 8
  %xor785 = xor i64 %xor779, %317
  %xor786 = xor i64 %309, %xor785
  %arrayidx787 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor786, i64* %arrayidx787, align 16
  %318 = load i64*, i64** %kp, align 8
  %add.ptr788 = getelementptr inbounds i64, i64* %318, i64 12
  %arrayidx789 = getelementptr inbounds i64, i64* %add.ptr788, i64 1
  %319 = load i64, i64* %arrayidx789, align 8
  %arrayidx790 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %320 = load i64, i64* %arrayidx790, align 8
  %shr791 = lshr i64 %320, 0
  %conv792 = trunc i64 %shr791 to i8
  %idxprom793 = zext i8 %conv792 to i64
  %arrayidx794 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom793
  %321 = load i64, i64* %arrayidx794, align 8
  %arrayidx795 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %322 = load i64, i64* %arrayidx795, align 16
  %shr796 = lshr i64 %322, 8
  %conv797 = trunc i64 %shr796 to i8
  %idxprom798 = zext i8 %conv797 to i64
  %arrayidx799 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom798
  %323 = load i64, i64* %arrayidx799, align 8
  %xor800 = xor i64 %321, %323
  %arrayidx801 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %324 = load i64, i64* %arrayidx801, align 8
  %shr802 = lshr i64 %324, 16
  %conv803 = trunc i64 %shr802 to i8
  %idxprom804 = zext i8 %conv803 to i64
  %arrayidx805 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom804
  %325 = load i64, i64* %arrayidx805, align 8
  %xor806 = xor i64 %xor800, %325
  %arrayidx807 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %326 = load i64, i64* %arrayidx807, align 16
  %shr808 = lshr i64 %326, 24
  %conv809 = trunc i64 %shr808 to i8
  %idxprom810 = zext i8 %conv809 to i64
  %arrayidx811 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom810
  %327 = load i64, i64* %arrayidx811, align 8
  %xor812 = xor i64 %xor806, %327
  %xor813 = xor i64 %319, %xor812
  %arrayidx814 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor813, i64* %arrayidx814, align 8
  %328 = load i64*, i64** %kp, align 8
  %add.ptr815 = getelementptr inbounds i64, i64* %328, i64 12
  %arrayidx816 = getelementptr inbounds i64, i64* %add.ptr815, i64 2
  %329 = load i64, i64* %arrayidx816, align 8
  %arrayidx817 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %330 = load i64, i64* %arrayidx817, align 16
  %shr818 = lshr i64 %330, 0
  %conv819 = trunc i64 %shr818 to i8
  %idxprom820 = zext i8 %conv819 to i64
  %arrayidx821 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom820
  %331 = load i64, i64* %arrayidx821, align 8
  %arrayidx822 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %332 = load i64, i64* %arrayidx822, align 8
  %shr823 = lshr i64 %332, 8
  %conv824 = trunc i64 %shr823 to i8
  %idxprom825 = zext i8 %conv824 to i64
  %arrayidx826 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom825
  %333 = load i64, i64* %arrayidx826, align 8
  %xor827 = xor i64 %331, %333
  %arrayidx828 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %334 = load i64, i64* %arrayidx828, align 16
  %shr829 = lshr i64 %334, 16
  %conv830 = trunc i64 %shr829 to i8
  %idxprom831 = zext i8 %conv830 to i64
  %arrayidx832 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom831
  %335 = load i64, i64* %arrayidx832, align 8
  %xor833 = xor i64 %xor827, %335
  %arrayidx834 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %336 = load i64, i64* %arrayidx834, align 8
  %shr835 = lshr i64 %336, 24
  %conv836 = trunc i64 %shr835 to i8
  %idxprom837 = zext i8 %conv836 to i64
  %arrayidx838 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom837
  %337 = load i64, i64* %arrayidx838, align 8
  %xor839 = xor i64 %xor833, %337
  %xor840 = xor i64 %329, %xor839
  %arrayidx841 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor840, i64* %arrayidx841, align 16
  %338 = load i64*, i64** %kp, align 8
  %add.ptr842 = getelementptr inbounds i64, i64* %338, i64 12
  %arrayidx843 = getelementptr inbounds i64, i64* %add.ptr842, i64 3
  %339 = load i64, i64* %arrayidx843, align 8
  %arrayidx844 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %340 = load i64, i64* %arrayidx844, align 8
  %shr845 = lshr i64 %340, 0
  %conv846 = trunc i64 %shr845 to i8
  %idxprom847 = zext i8 %conv846 to i64
  %arrayidx848 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom847
  %341 = load i64, i64* %arrayidx848, align 8
  %arrayidx849 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %342 = load i64, i64* %arrayidx849, align 16
  %shr850 = lshr i64 %342, 8
  %conv851 = trunc i64 %shr850 to i8
  %idxprom852 = zext i8 %conv851 to i64
  %arrayidx853 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom852
  %343 = load i64, i64* %arrayidx853, align 8
  %xor854 = xor i64 %341, %343
  %arrayidx855 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %344 = load i64, i64* %arrayidx855, align 8
  %shr856 = lshr i64 %344, 16
  %conv857 = trunc i64 %shr856 to i8
  %idxprom858 = zext i8 %conv857 to i64
  %arrayidx859 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom858
  %345 = load i64, i64* %arrayidx859, align 8
  %xor860 = xor i64 %xor854, %345
  %arrayidx861 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %346 = load i64, i64* %arrayidx861, align 16
  %shr862 = lshr i64 %346, 24
  %conv863 = trunc i64 %shr862 to i8
  %idxprom864 = zext i8 %conv863 to i64
  %arrayidx865 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom864
  %347 = load i64, i64* %arrayidx865, align 8
  %xor866 = xor i64 %xor860, %347
  %xor867 = xor i64 %339, %xor866
  %arrayidx868 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor867, i64* %arrayidx868, align 8
  %348 = load i64*, i64** %kp, align 8
  %add.ptr869 = getelementptr inbounds i64, i64* %348, i64 16
  %arrayidx870 = getelementptr inbounds i64, i64* %add.ptr869, i64 0
  %349 = load i64, i64* %arrayidx870, align 8
  %arrayidx871 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %350 = load i64, i64* %arrayidx871, align 16
  %shr872 = lshr i64 %350, 0
  %conv873 = trunc i64 %shr872 to i8
  %idxprom874 = zext i8 %conv873 to i64
  %arrayidx875 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom874
  %351 = load i64, i64* %arrayidx875, align 8
  %arrayidx876 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %352 = load i64, i64* %arrayidx876, align 8
  %shr877 = lshr i64 %352, 8
  %conv878 = trunc i64 %shr877 to i8
  %idxprom879 = zext i8 %conv878 to i64
  %arrayidx880 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom879
  %353 = load i64, i64* %arrayidx880, align 8
  %xor881 = xor i64 %351, %353
  %arrayidx882 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %354 = load i64, i64* %arrayidx882, align 16
  %shr883 = lshr i64 %354, 16
  %conv884 = trunc i64 %shr883 to i8
  %idxprom885 = zext i8 %conv884 to i64
  %arrayidx886 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom885
  %355 = load i64, i64* %arrayidx886, align 8
  %xor887 = xor i64 %xor881, %355
  %arrayidx888 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %356 = load i64, i64* %arrayidx888, align 8
  %shr889 = lshr i64 %356, 24
  %conv890 = trunc i64 %shr889 to i8
  %idxprom891 = zext i8 %conv890 to i64
  %arrayidx892 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom891
  %357 = load i64, i64* %arrayidx892, align 8
  %xor893 = xor i64 %xor887, %357
  %xor894 = xor i64 %349, %xor893
  %arrayidx895 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor894, i64* %arrayidx895, align 16
  %358 = load i64*, i64** %kp, align 8
  %add.ptr896 = getelementptr inbounds i64, i64* %358, i64 16
  %arrayidx897 = getelementptr inbounds i64, i64* %add.ptr896, i64 1
  %359 = load i64, i64* %arrayidx897, align 8
  %arrayidx898 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %360 = load i64, i64* %arrayidx898, align 8
  %shr899 = lshr i64 %360, 0
  %conv900 = trunc i64 %shr899 to i8
  %idxprom901 = zext i8 %conv900 to i64
  %arrayidx902 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom901
  %361 = load i64, i64* %arrayidx902, align 8
  %arrayidx903 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %362 = load i64, i64* %arrayidx903, align 16
  %shr904 = lshr i64 %362, 8
  %conv905 = trunc i64 %shr904 to i8
  %idxprom906 = zext i8 %conv905 to i64
  %arrayidx907 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom906
  %363 = load i64, i64* %arrayidx907, align 8
  %xor908 = xor i64 %361, %363
  %arrayidx909 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %364 = load i64, i64* %arrayidx909, align 8
  %shr910 = lshr i64 %364, 16
  %conv911 = trunc i64 %shr910 to i8
  %idxprom912 = zext i8 %conv911 to i64
  %arrayidx913 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom912
  %365 = load i64, i64* %arrayidx913, align 8
  %xor914 = xor i64 %xor908, %365
  %arrayidx915 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %366 = load i64, i64* %arrayidx915, align 16
  %shr916 = lshr i64 %366, 24
  %conv917 = trunc i64 %shr916 to i8
  %idxprom918 = zext i8 %conv917 to i64
  %arrayidx919 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom918
  %367 = load i64, i64* %arrayidx919, align 8
  %xor920 = xor i64 %xor914, %367
  %xor921 = xor i64 %359, %xor920
  %arrayidx922 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor921, i64* %arrayidx922, align 8
  %368 = load i64*, i64** %kp, align 8
  %add.ptr923 = getelementptr inbounds i64, i64* %368, i64 16
  %arrayidx924 = getelementptr inbounds i64, i64* %add.ptr923, i64 2
  %369 = load i64, i64* %arrayidx924, align 8
  %arrayidx925 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %370 = load i64, i64* %arrayidx925, align 16
  %shr926 = lshr i64 %370, 0
  %conv927 = trunc i64 %shr926 to i8
  %idxprom928 = zext i8 %conv927 to i64
  %arrayidx929 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom928
  %371 = load i64, i64* %arrayidx929, align 8
  %arrayidx930 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %372 = load i64, i64* %arrayidx930, align 8
  %shr931 = lshr i64 %372, 8
  %conv932 = trunc i64 %shr931 to i8
  %idxprom933 = zext i8 %conv932 to i64
  %arrayidx934 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom933
  %373 = load i64, i64* %arrayidx934, align 8
  %xor935 = xor i64 %371, %373
  %arrayidx936 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %374 = load i64, i64* %arrayidx936, align 16
  %shr937 = lshr i64 %374, 16
  %conv938 = trunc i64 %shr937 to i8
  %idxprom939 = zext i8 %conv938 to i64
  %arrayidx940 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom939
  %375 = load i64, i64* %arrayidx940, align 8
  %xor941 = xor i64 %xor935, %375
  %arrayidx942 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %376 = load i64, i64* %arrayidx942, align 8
  %shr943 = lshr i64 %376, 24
  %conv944 = trunc i64 %shr943 to i8
  %idxprom945 = zext i8 %conv944 to i64
  %arrayidx946 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom945
  %377 = load i64, i64* %arrayidx946, align 8
  %xor947 = xor i64 %xor941, %377
  %xor948 = xor i64 %369, %xor947
  %arrayidx949 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor948, i64* %arrayidx949, align 16
  %378 = load i64*, i64** %kp, align 8
  %add.ptr950 = getelementptr inbounds i64, i64* %378, i64 16
  %arrayidx951 = getelementptr inbounds i64, i64* %add.ptr950, i64 3
  %379 = load i64, i64* %arrayidx951, align 8
  %arrayidx952 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %380 = load i64, i64* %arrayidx952, align 8
  %shr953 = lshr i64 %380, 0
  %conv954 = trunc i64 %shr953 to i8
  %idxprom955 = zext i8 %conv954 to i64
  %arrayidx956 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom955
  %381 = load i64, i64* %arrayidx956, align 8
  %arrayidx957 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %382 = load i64, i64* %arrayidx957, align 16
  %shr958 = lshr i64 %382, 8
  %conv959 = trunc i64 %shr958 to i8
  %idxprom960 = zext i8 %conv959 to i64
  %arrayidx961 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom960
  %383 = load i64, i64* %arrayidx961, align 8
  %xor962 = xor i64 %381, %383
  %arrayidx963 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %384 = load i64, i64* %arrayidx963, align 8
  %shr964 = lshr i64 %384, 16
  %conv965 = trunc i64 %shr964 to i8
  %idxprom966 = zext i8 %conv965 to i64
  %arrayidx967 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom966
  %385 = load i64, i64* %arrayidx967, align 8
  %xor968 = xor i64 %xor962, %385
  %arrayidx969 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %386 = load i64, i64* %arrayidx969, align 16
  %shr970 = lshr i64 %386, 24
  %conv971 = trunc i64 %shr970 to i8
  %idxprom972 = zext i8 %conv971 to i64
  %arrayidx973 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom972
  %387 = load i64, i64* %arrayidx973, align 8
  %xor974 = xor i64 %xor968, %387
  %xor975 = xor i64 %379, %xor974
  %arrayidx976 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor975, i64* %arrayidx976, align 8
  %388 = load i64*, i64** %kp, align 8
  %add.ptr977 = getelementptr inbounds i64, i64* %388, i64 20
  %arrayidx978 = getelementptr inbounds i64, i64* %add.ptr977, i64 0
  %389 = load i64, i64* %arrayidx978, align 8
  %arrayidx979 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %390 = load i64, i64* %arrayidx979, align 16
  %shr980 = lshr i64 %390, 0
  %conv981 = trunc i64 %shr980 to i8
  %idxprom982 = zext i8 %conv981 to i64
  %arrayidx983 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom982
  %391 = load i64, i64* %arrayidx983, align 8
  %arrayidx984 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %392 = load i64, i64* %arrayidx984, align 8
  %shr985 = lshr i64 %392, 8
  %conv986 = trunc i64 %shr985 to i8
  %idxprom987 = zext i8 %conv986 to i64
  %arrayidx988 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom987
  %393 = load i64, i64* %arrayidx988, align 8
  %xor989 = xor i64 %391, %393
  %arrayidx990 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %394 = load i64, i64* %arrayidx990, align 16
  %shr991 = lshr i64 %394, 16
  %conv992 = trunc i64 %shr991 to i8
  %idxprom993 = zext i8 %conv992 to i64
  %arrayidx994 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom993
  %395 = load i64, i64* %arrayidx994, align 8
  %xor995 = xor i64 %xor989, %395
  %arrayidx996 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %396 = load i64, i64* %arrayidx996, align 8
  %shr997 = lshr i64 %396, 24
  %conv998 = trunc i64 %shr997 to i8
  %idxprom999 = zext i8 %conv998 to i64
  %arrayidx1000 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom999
  %397 = load i64, i64* %arrayidx1000, align 8
  %xor1001 = xor i64 %xor995, %397
  %xor1002 = xor i64 %389, %xor1001
  %arrayidx1003 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor1002, i64* %arrayidx1003, align 16
  %398 = load i64*, i64** %kp, align 8
  %add.ptr1004 = getelementptr inbounds i64, i64* %398, i64 20
  %arrayidx1005 = getelementptr inbounds i64, i64* %add.ptr1004, i64 1
  %399 = load i64, i64* %arrayidx1005, align 8
  %arrayidx1006 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %400 = load i64, i64* %arrayidx1006, align 8
  %shr1007 = lshr i64 %400, 0
  %conv1008 = trunc i64 %shr1007 to i8
  %idxprom1009 = zext i8 %conv1008 to i64
  %arrayidx1010 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1009
  %401 = load i64, i64* %arrayidx1010, align 8
  %arrayidx1011 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %402 = load i64, i64* %arrayidx1011, align 16
  %shr1012 = lshr i64 %402, 8
  %conv1013 = trunc i64 %shr1012 to i8
  %idxprom1014 = zext i8 %conv1013 to i64
  %arrayidx1015 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1014
  %403 = load i64, i64* %arrayidx1015, align 8
  %xor1016 = xor i64 %401, %403
  %arrayidx1017 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %404 = load i64, i64* %arrayidx1017, align 8
  %shr1018 = lshr i64 %404, 16
  %conv1019 = trunc i64 %shr1018 to i8
  %idxprom1020 = zext i8 %conv1019 to i64
  %arrayidx1021 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1020
  %405 = load i64, i64* %arrayidx1021, align 8
  %xor1022 = xor i64 %xor1016, %405
  %arrayidx1023 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %406 = load i64, i64* %arrayidx1023, align 16
  %shr1024 = lshr i64 %406, 24
  %conv1025 = trunc i64 %shr1024 to i8
  %idxprom1026 = zext i8 %conv1025 to i64
  %arrayidx1027 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1026
  %407 = load i64, i64* %arrayidx1027, align 8
  %xor1028 = xor i64 %xor1022, %407
  %xor1029 = xor i64 %399, %xor1028
  %arrayidx1030 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor1029, i64* %arrayidx1030, align 8
  %408 = load i64*, i64** %kp, align 8
  %add.ptr1031 = getelementptr inbounds i64, i64* %408, i64 20
  %arrayidx1032 = getelementptr inbounds i64, i64* %add.ptr1031, i64 2
  %409 = load i64, i64* %arrayidx1032, align 8
  %arrayidx1033 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %410 = load i64, i64* %arrayidx1033, align 16
  %shr1034 = lshr i64 %410, 0
  %conv1035 = trunc i64 %shr1034 to i8
  %idxprom1036 = zext i8 %conv1035 to i64
  %arrayidx1037 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1036
  %411 = load i64, i64* %arrayidx1037, align 8
  %arrayidx1038 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %412 = load i64, i64* %arrayidx1038, align 8
  %shr1039 = lshr i64 %412, 8
  %conv1040 = trunc i64 %shr1039 to i8
  %idxprom1041 = zext i8 %conv1040 to i64
  %arrayidx1042 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1041
  %413 = load i64, i64* %arrayidx1042, align 8
  %xor1043 = xor i64 %411, %413
  %arrayidx1044 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %414 = load i64, i64* %arrayidx1044, align 16
  %shr1045 = lshr i64 %414, 16
  %conv1046 = trunc i64 %shr1045 to i8
  %idxprom1047 = zext i8 %conv1046 to i64
  %arrayidx1048 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1047
  %415 = load i64, i64* %arrayidx1048, align 8
  %xor1049 = xor i64 %xor1043, %415
  %arrayidx1050 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %416 = load i64, i64* %arrayidx1050, align 8
  %shr1051 = lshr i64 %416, 24
  %conv1052 = trunc i64 %shr1051 to i8
  %idxprom1053 = zext i8 %conv1052 to i64
  %arrayidx1054 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1053
  %417 = load i64, i64* %arrayidx1054, align 8
  %xor1055 = xor i64 %xor1049, %417
  %xor1056 = xor i64 %409, %xor1055
  %arrayidx1057 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor1056, i64* %arrayidx1057, align 16
  %418 = load i64*, i64** %kp, align 8
  %add.ptr1058 = getelementptr inbounds i64, i64* %418, i64 20
  %arrayidx1059 = getelementptr inbounds i64, i64* %add.ptr1058, i64 3
  %419 = load i64, i64* %arrayidx1059, align 8
  %arrayidx1060 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %420 = load i64, i64* %arrayidx1060, align 8
  %shr1061 = lshr i64 %420, 0
  %conv1062 = trunc i64 %shr1061 to i8
  %idxprom1063 = zext i8 %conv1062 to i64
  %arrayidx1064 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1063
  %421 = load i64, i64* %arrayidx1064, align 8
  %arrayidx1065 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %422 = load i64, i64* %arrayidx1065, align 16
  %shr1066 = lshr i64 %422, 8
  %conv1067 = trunc i64 %shr1066 to i8
  %idxprom1068 = zext i8 %conv1067 to i64
  %arrayidx1069 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1068
  %423 = load i64, i64* %arrayidx1069, align 8
  %xor1070 = xor i64 %421, %423
  %arrayidx1071 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %424 = load i64, i64* %arrayidx1071, align 8
  %shr1072 = lshr i64 %424, 16
  %conv1073 = trunc i64 %shr1072 to i8
  %idxprom1074 = zext i8 %conv1073 to i64
  %arrayidx1075 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1074
  %425 = load i64, i64* %arrayidx1075, align 8
  %xor1076 = xor i64 %xor1070, %425
  %arrayidx1077 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %426 = load i64, i64* %arrayidx1077, align 16
  %shr1078 = lshr i64 %426, 24
  %conv1079 = trunc i64 %shr1078 to i8
  %idxprom1080 = zext i8 %conv1079 to i64
  %arrayidx1081 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1080
  %427 = load i64, i64* %arrayidx1081, align 8
  %xor1082 = xor i64 %xor1076, %427
  %xor1083 = xor i64 %419, %xor1082
  %arrayidx1084 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor1083, i64* %arrayidx1084, align 8
  %428 = load i64*, i64** %kp, align 8
  %add.ptr1085 = getelementptr inbounds i64, i64* %428, i64 24
  %arrayidx1086 = getelementptr inbounds i64, i64* %add.ptr1085, i64 0
  %429 = load i64, i64* %arrayidx1086, align 8
  %arrayidx1087 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %430 = load i64, i64* %arrayidx1087, align 16
  %shr1088 = lshr i64 %430, 0
  %conv1089 = trunc i64 %shr1088 to i8
  %idxprom1090 = zext i8 %conv1089 to i64
  %arrayidx1091 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1090
  %431 = load i64, i64* %arrayidx1091, align 8
  %arrayidx1092 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %432 = load i64, i64* %arrayidx1092, align 8
  %shr1093 = lshr i64 %432, 8
  %conv1094 = trunc i64 %shr1093 to i8
  %idxprom1095 = zext i8 %conv1094 to i64
  %arrayidx1096 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1095
  %433 = load i64, i64* %arrayidx1096, align 8
  %xor1097 = xor i64 %431, %433
  %arrayidx1098 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %434 = load i64, i64* %arrayidx1098, align 16
  %shr1099 = lshr i64 %434, 16
  %conv1100 = trunc i64 %shr1099 to i8
  %idxprom1101 = zext i8 %conv1100 to i64
  %arrayidx1102 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1101
  %435 = load i64, i64* %arrayidx1102, align 8
  %xor1103 = xor i64 %xor1097, %435
  %arrayidx1104 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %436 = load i64, i64* %arrayidx1104, align 8
  %shr1105 = lshr i64 %436, 24
  %conv1106 = trunc i64 %shr1105 to i8
  %idxprom1107 = zext i8 %conv1106 to i64
  %arrayidx1108 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1107
  %437 = load i64, i64* %arrayidx1108, align 8
  %xor1109 = xor i64 %xor1103, %437
  %xor1110 = xor i64 %429, %xor1109
  %arrayidx1111 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor1110, i64* %arrayidx1111, align 16
  %438 = load i64*, i64** %kp, align 8
  %add.ptr1112 = getelementptr inbounds i64, i64* %438, i64 24
  %arrayidx1113 = getelementptr inbounds i64, i64* %add.ptr1112, i64 1
  %439 = load i64, i64* %arrayidx1113, align 8
  %arrayidx1114 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %440 = load i64, i64* %arrayidx1114, align 8
  %shr1115 = lshr i64 %440, 0
  %conv1116 = trunc i64 %shr1115 to i8
  %idxprom1117 = zext i8 %conv1116 to i64
  %arrayidx1118 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1117
  %441 = load i64, i64* %arrayidx1118, align 8
  %arrayidx1119 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %442 = load i64, i64* %arrayidx1119, align 16
  %shr1120 = lshr i64 %442, 8
  %conv1121 = trunc i64 %shr1120 to i8
  %idxprom1122 = zext i8 %conv1121 to i64
  %arrayidx1123 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1122
  %443 = load i64, i64* %arrayidx1123, align 8
  %xor1124 = xor i64 %441, %443
  %arrayidx1125 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %444 = load i64, i64* %arrayidx1125, align 8
  %shr1126 = lshr i64 %444, 16
  %conv1127 = trunc i64 %shr1126 to i8
  %idxprom1128 = zext i8 %conv1127 to i64
  %arrayidx1129 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1128
  %445 = load i64, i64* %arrayidx1129, align 8
  %xor1130 = xor i64 %xor1124, %445
  %arrayidx1131 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %446 = load i64, i64* %arrayidx1131, align 16
  %shr1132 = lshr i64 %446, 24
  %conv1133 = trunc i64 %shr1132 to i8
  %idxprom1134 = zext i8 %conv1133 to i64
  %arrayidx1135 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1134
  %447 = load i64, i64* %arrayidx1135, align 8
  %xor1136 = xor i64 %xor1130, %447
  %xor1137 = xor i64 %439, %xor1136
  %arrayidx1138 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor1137, i64* %arrayidx1138, align 8
  %448 = load i64*, i64** %kp, align 8
  %add.ptr1139 = getelementptr inbounds i64, i64* %448, i64 24
  %arrayidx1140 = getelementptr inbounds i64, i64* %add.ptr1139, i64 2
  %449 = load i64, i64* %arrayidx1140, align 8
  %arrayidx1141 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %450 = load i64, i64* %arrayidx1141, align 16
  %shr1142 = lshr i64 %450, 0
  %conv1143 = trunc i64 %shr1142 to i8
  %idxprom1144 = zext i8 %conv1143 to i64
  %arrayidx1145 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1144
  %451 = load i64, i64* %arrayidx1145, align 8
  %arrayidx1146 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %452 = load i64, i64* %arrayidx1146, align 8
  %shr1147 = lshr i64 %452, 8
  %conv1148 = trunc i64 %shr1147 to i8
  %idxprom1149 = zext i8 %conv1148 to i64
  %arrayidx1150 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1149
  %453 = load i64, i64* %arrayidx1150, align 8
  %xor1151 = xor i64 %451, %453
  %arrayidx1152 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %454 = load i64, i64* %arrayidx1152, align 16
  %shr1153 = lshr i64 %454, 16
  %conv1154 = trunc i64 %shr1153 to i8
  %idxprom1155 = zext i8 %conv1154 to i64
  %arrayidx1156 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1155
  %455 = load i64, i64* %arrayidx1156, align 8
  %xor1157 = xor i64 %xor1151, %455
  %arrayidx1158 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %456 = load i64, i64* %arrayidx1158, align 8
  %shr1159 = lshr i64 %456, 24
  %conv1160 = trunc i64 %shr1159 to i8
  %idxprom1161 = zext i8 %conv1160 to i64
  %arrayidx1162 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1161
  %457 = load i64, i64* %arrayidx1162, align 8
  %xor1163 = xor i64 %xor1157, %457
  %xor1164 = xor i64 %449, %xor1163
  %arrayidx1165 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor1164, i64* %arrayidx1165, align 16
  %458 = load i64*, i64** %kp, align 8
  %add.ptr1166 = getelementptr inbounds i64, i64* %458, i64 24
  %arrayidx1167 = getelementptr inbounds i64, i64* %add.ptr1166, i64 3
  %459 = load i64, i64* %arrayidx1167, align 8
  %arrayidx1168 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %460 = load i64, i64* %arrayidx1168, align 8
  %shr1169 = lshr i64 %460, 0
  %conv1170 = trunc i64 %shr1169 to i8
  %idxprom1171 = zext i8 %conv1170 to i64
  %arrayidx1172 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1171
  %461 = load i64, i64* %arrayidx1172, align 8
  %arrayidx1173 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %462 = load i64, i64* %arrayidx1173, align 16
  %shr1174 = lshr i64 %462, 8
  %conv1175 = trunc i64 %shr1174 to i8
  %idxprom1176 = zext i8 %conv1175 to i64
  %arrayidx1177 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1176
  %463 = load i64, i64* %arrayidx1177, align 8
  %xor1178 = xor i64 %461, %463
  %arrayidx1179 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %464 = load i64, i64* %arrayidx1179, align 8
  %shr1180 = lshr i64 %464, 16
  %conv1181 = trunc i64 %shr1180 to i8
  %idxprom1182 = zext i8 %conv1181 to i64
  %arrayidx1183 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1182
  %465 = load i64, i64* %arrayidx1183, align 8
  %xor1184 = xor i64 %xor1178, %465
  %arrayidx1185 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %466 = load i64, i64* %arrayidx1185, align 16
  %shr1186 = lshr i64 %466, 24
  %conv1187 = trunc i64 %shr1186 to i8
  %idxprom1188 = zext i8 %conv1187 to i64
  %arrayidx1189 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1188
  %467 = load i64, i64* %arrayidx1189, align 8
  %xor1190 = xor i64 %xor1184, %467
  %xor1191 = xor i64 %459, %xor1190
  %arrayidx1192 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor1191, i64* %arrayidx1192, align 8
  %468 = load i64*, i64** %kp, align 8
  %add.ptr1193 = getelementptr inbounds i64, i64* %468, i64 28
  %arrayidx1194 = getelementptr inbounds i64, i64* %add.ptr1193, i64 0
  %469 = load i64, i64* %arrayidx1194, align 8
  %arrayidx1195 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %470 = load i64, i64* %arrayidx1195, align 16
  %shr1196 = lshr i64 %470, 0
  %conv1197 = trunc i64 %shr1196 to i8
  %idxprom1198 = zext i8 %conv1197 to i64
  %arrayidx1199 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1198
  %471 = load i64, i64* %arrayidx1199, align 8
  %arrayidx1200 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %472 = load i64, i64* %arrayidx1200, align 8
  %shr1201 = lshr i64 %472, 8
  %conv1202 = trunc i64 %shr1201 to i8
  %idxprom1203 = zext i8 %conv1202 to i64
  %arrayidx1204 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1203
  %473 = load i64, i64* %arrayidx1204, align 8
  %xor1205 = xor i64 %471, %473
  %arrayidx1206 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %474 = load i64, i64* %arrayidx1206, align 16
  %shr1207 = lshr i64 %474, 16
  %conv1208 = trunc i64 %shr1207 to i8
  %idxprom1209 = zext i8 %conv1208 to i64
  %arrayidx1210 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1209
  %475 = load i64, i64* %arrayidx1210, align 8
  %xor1211 = xor i64 %xor1205, %475
  %arrayidx1212 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %476 = load i64, i64* %arrayidx1212, align 8
  %shr1213 = lshr i64 %476, 24
  %conv1214 = trunc i64 %shr1213 to i8
  %idxprom1215 = zext i8 %conv1214 to i64
  %arrayidx1216 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1215
  %477 = load i64, i64* %arrayidx1216, align 8
  %xor1217 = xor i64 %xor1211, %477
  %xor1218 = xor i64 %469, %xor1217
  %arrayidx1219 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor1218, i64* %arrayidx1219, align 16
  %478 = load i64*, i64** %kp, align 8
  %add.ptr1220 = getelementptr inbounds i64, i64* %478, i64 28
  %arrayidx1221 = getelementptr inbounds i64, i64* %add.ptr1220, i64 1
  %479 = load i64, i64* %arrayidx1221, align 8
  %arrayidx1222 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %480 = load i64, i64* %arrayidx1222, align 8
  %shr1223 = lshr i64 %480, 0
  %conv1224 = trunc i64 %shr1223 to i8
  %idxprom1225 = zext i8 %conv1224 to i64
  %arrayidx1226 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1225
  %481 = load i64, i64* %arrayidx1226, align 8
  %arrayidx1227 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %482 = load i64, i64* %arrayidx1227, align 16
  %shr1228 = lshr i64 %482, 8
  %conv1229 = trunc i64 %shr1228 to i8
  %idxprom1230 = zext i8 %conv1229 to i64
  %arrayidx1231 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1230
  %483 = load i64, i64* %arrayidx1231, align 8
  %xor1232 = xor i64 %481, %483
  %arrayidx1233 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %484 = load i64, i64* %arrayidx1233, align 8
  %shr1234 = lshr i64 %484, 16
  %conv1235 = trunc i64 %shr1234 to i8
  %idxprom1236 = zext i8 %conv1235 to i64
  %arrayidx1237 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1236
  %485 = load i64, i64* %arrayidx1237, align 8
  %xor1238 = xor i64 %xor1232, %485
  %arrayidx1239 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %486 = load i64, i64* %arrayidx1239, align 16
  %shr1240 = lshr i64 %486, 24
  %conv1241 = trunc i64 %shr1240 to i8
  %idxprom1242 = zext i8 %conv1241 to i64
  %arrayidx1243 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1242
  %487 = load i64, i64* %arrayidx1243, align 8
  %xor1244 = xor i64 %xor1238, %487
  %xor1245 = xor i64 %479, %xor1244
  %arrayidx1246 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor1245, i64* %arrayidx1246, align 8
  %488 = load i64*, i64** %kp, align 8
  %add.ptr1247 = getelementptr inbounds i64, i64* %488, i64 28
  %arrayidx1248 = getelementptr inbounds i64, i64* %add.ptr1247, i64 2
  %489 = load i64, i64* %arrayidx1248, align 8
  %arrayidx1249 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %490 = load i64, i64* %arrayidx1249, align 16
  %shr1250 = lshr i64 %490, 0
  %conv1251 = trunc i64 %shr1250 to i8
  %idxprom1252 = zext i8 %conv1251 to i64
  %arrayidx1253 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1252
  %491 = load i64, i64* %arrayidx1253, align 8
  %arrayidx1254 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %492 = load i64, i64* %arrayidx1254, align 8
  %shr1255 = lshr i64 %492, 8
  %conv1256 = trunc i64 %shr1255 to i8
  %idxprom1257 = zext i8 %conv1256 to i64
  %arrayidx1258 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1257
  %493 = load i64, i64* %arrayidx1258, align 8
  %xor1259 = xor i64 %491, %493
  %arrayidx1260 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %494 = load i64, i64* %arrayidx1260, align 16
  %shr1261 = lshr i64 %494, 16
  %conv1262 = trunc i64 %shr1261 to i8
  %idxprom1263 = zext i8 %conv1262 to i64
  %arrayidx1264 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1263
  %495 = load i64, i64* %arrayidx1264, align 8
  %xor1265 = xor i64 %xor1259, %495
  %arrayidx1266 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %496 = load i64, i64* %arrayidx1266, align 8
  %shr1267 = lshr i64 %496, 24
  %conv1268 = trunc i64 %shr1267 to i8
  %idxprom1269 = zext i8 %conv1268 to i64
  %arrayidx1270 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1269
  %497 = load i64, i64* %arrayidx1270, align 8
  %xor1271 = xor i64 %xor1265, %497
  %xor1272 = xor i64 %489, %xor1271
  %arrayidx1273 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor1272, i64* %arrayidx1273, align 16
  %498 = load i64*, i64** %kp, align 8
  %add.ptr1274 = getelementptr inbounds i64, i64* %498, i64 28
  %arrayidx1275 = getelementptr inbounds i64, i64* %add.ptr1274, i64 3
  %499 = load i64, i64* %arrayidx1275, align 8
  %arrayidx1276 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %500 = load i64, i64* %arrayidx1276, align 8
  %shr1277 = lshr i64 %500, 0
  %conv1278 = trunc i64 %shr1277 to i8
  %idxprom1279 = zext i8 %conv1278 to i64
  %arrayidx1280 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1279
  %501 = load i64, i64* %arrayidx1280, align 8
  %arrayidx1281 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %502 = load i64, i64* %arrayidx1281, align 16
  %shr1282 = lshr i64 %502, 8
  %conv1283 = trunc i64 %shr1282 to i8
  %idxprom1284 = zext i8 %conv1283 to i64
  %arrayidx1285 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1284
  %503 = load i64, i64* %arrayidx1285, align 8
  %xor1286 = xor i64 %501, %503
  %arrayidx1287 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %504 = load i64, i64* %arrayidx1287, align 8
  %shr1288 = lshr i64 %504, 16
  %conv1289 = trunc i64 %shr1288 to i8
  %idxprom1290 = zext i8 %conv1289 to i64
  %arrayidx1291 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1290
  %505 = load i64, i64* %arrayidx1291, align 8
  %xor1292 = xor i64 %xor1286, %505
  %arrayidx1293 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %506 = load i64, i64* %arrayidx1293, align 16
  %shr1294 = lshr i64 %506, 24
  %conv1295 = trunc i64 %shr1294 to i8
  %idxprom1296 = zext i8 %conv1295 to i64
  %arrayidx1297 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1296
  %507 = load i64, i64* %arrayidx1297, align 8
  %xor1298 = xor i64 %xor1292, %507
  %xor1299 = xor i64 %499, %xor1298
  %arrayidx1300 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor1299, i64* %arrayidx1300, align 8
  %508 = load i64*, i64** %kp, align 8
  %add.ptr1301 = getelementptr inbounds i64, i64* %508, i64 32
  %arrayidx1302 = getelementptr inbounds i64, i64* %add.ptr1301, i64 0
  %509 = load i64, i64* %arrayidx1302, align 8
  %arrayidx1303 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %510 = load i64, i64* %arrayidx1303, align 16
  %shr1304 = lshr i64 %510, 0
  %conv1305 = trunc i64 %shr1304 to i8
  %idxprom1306 = zext i8 %conv1305 to i64
  %arrayidx1307 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1306
  %511 = load i64, i64* %arrayidx1307, align 8
  %arrayidx1308 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %512 = load i64, i64* %arrayidx1308, align 8
  %shr1309 = lshr i64 %512, 8
  %conv1310 = trunc i64 %shr1309 to i8
  %idxprom1311 = zext i8 %conv1310 to i64
  %arrayidx1312 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1311
  %513 = load i64, i64* %arrayidx1312, align 8
  %xor1313 = xor i64 %511, %513
  %arrayidx1314 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %514 = load i64, i64* %arrayidx1314, align 16
  %shr1315 = lshr i64 %514, 16
  %conv1316 = trunc i64 %shr1315 to i8
  %idxprom1317 = zext i8 %conv1316 to i64
  %arrayidx1318 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1317
  %515 = load i64, i64* %arrayidx1318, align 8
  %xor1319 = xor i64 %xor1313, %515
  %arrayidx1320 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %516 = load i64, i64* %arrayidx1320, align 8
  %shr1321 = lshr i64 %516, 24
  %conv1322 = trunc i64 %shr1321 to i8
  %idxprom1323 = zext i8 %conv1322 to i64
  %arrayidx1324 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1323
  %517 = load i64, i64* %arrayidx1324, align 8
  %xor1325 = xor i64 %xor1319, %517
  %xor1326 = xor i64 %509, %xor1325
  %arrayidx1327 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor1326, i64* %arrayidx1327, align 16
  %518 = load i64*, i64** %kp, align 8
  %add.ptr1328 = getelementptr inbounds i64, i64* %518, i64 32
  %arrayidx1329 = getelementptr inbounds i64, i64* %add.ptr1328, i64 1
  %519 = load i64, i64* %arrayidx1329, align 8
  %arrayidx1330 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %520 = load i64, i64* %arrayidx1330, align 8
  %shr1331 = lshr i64 %520, 0
  %conv1332 = trunc i64 %shr1331 to i8
  %idxprom1333 = zext i8 %conv1332 to i64
  %arrayidx1334 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1333
  %521 = load i64, i64* %arrayidx1334, align 8
  %arrayidx1335 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %522 = load i64, i64* %arrayidx1335, align 16
  %shr1336 = lshr i64 %522, 8
  %conv1337 = trunc i64 %shr1336 to i8
  %idxprom1338 = zext i8 %conv1337 to i64
  %arrayidx1339 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1338
  %523 = load i64, i64* %arrayidx1339, align 8
  %xor1340 = xor i64 %521, %523
  %arrayidx1341 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %524 = load i64, i64* %arrayidx1341, align 8
  %shr1342 = lshr i64 %524, 16
  %conv1343 = trunc i64 %shr1342 to i8
  %idxprom1344 = zext i8 %conv1343 to i64
  %arrayidx1345 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1344
  %525 = load i64, i64* %arrayidx1345, align 8
  %xor1346 = xor i64 %xor1340, %525
  %arrayidx1347 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %526 = load i64, i64* %arrayidx1347, align 16
  %shr1348 = lshr i64 %526, 24
  %conv1349 = trunc i64 %shr1348 to i8
  %idxprom1350 = zext i8 %conv1349 to i64
  %arrayidx1351 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1350
  %527 = load i64, i64* %arrayidx1351, align 8
  %xor1352 = xor i64 %xor1346, %527
  %xor1353 = xor i64 %519, %xor1352
  %arrayidx1354 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor1353, i64* %arrayidx1354, align 8
  %528 = load i64*, i64** %kp, align 8
  %add.ptr1355 = getelementptr inbounds i64, i64* %528, i64 32
  %arrayidx1356 = getelementptr inbounds i64, i64* %add.ptr1355, i64 2
  %529 = load i64, i64* %arrayidx1356, align 8
  %arrayidx1357 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %530 = load i64, i64* %arrayidx1357, align 16
  %shr1358 = lshr i64 %530, 0
  %conv1359 = trunc i64 %shr1358 to i8
  %idxprom1360 = zext i8 %conv1359 to i64
  %arrayidx1361 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1360
  %531 = load i64, i64* %arrayidx1361, align 8
  %arrayidx1362 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %532 = load i64, i64* %arrayidx1362, align 8
  %shr1363 = lshr i64 %532, 8
  %conv1364 = trunc i64 %shr1363 to i8
  %idxprom1365 = zext i8 %conv1364 to i64
  %arrayidx1366 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1365
  %533 = load i64, i64* %arrayidx1366, align 8
  %xor1367 = xor i64 %531, %533
  %arrayidx1368 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %534 = load i64, i64* %arrayidx1368, align 16
  %shr1369 = lshr i64 %534, 16
  %conv1370 = trunc i64 %shr1369 to i8
  %idxprom1371 = zext i8 %conv1370 to i64
  %arrayidx1372 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1371
  %535 = load i64, i64* %arrayidx1372, align 8
  %xor1373 = xor i64 %xor1367, %535
  %arrayidx1374 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %536 = load i64, i64* %arrayidx1374, align 8
  %shr1375 = lshr i64 %536, 24
  %conv1376 = trunc i64 %shr1375 to i8
  %idxprom1377 = zext i8 %conv1376 to i64
  %arrayidx1378 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1377
  %537 = load i64, i64* %arrayidx1378, align 8
  %xor1379 = xor i64 %xor1373, %537
  %xor1380 = xor i64 %529, %xor1379
  %arrayidx1381 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor1380, i64* %arrayidx1381, align 16
  %538 = load i64*, i64** %kp, align 8
  %add.ptr1382 = getelementptr inbounds i64, i64* %538, i64 32
  %arrayidx1383 = getelementptr inbounds i64, i64* %add.ptr1382, i64 3
  %539 = load i64, i64* %arrayidx1383, align 8
  %arrayidx1384 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %540 = load i64, i64* %arrayidx1384, align 8
  %shr1385 = lshr i64 %540, 0
  %conv1386 = trunc i64 %shr1385 to i8
  %idxprom1387 = zext i8 %conv1386 to i64
  %arrayidx1388 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 0), i64 0, i64 %idxprom1387
  %541 = load i64, i64* %arrayidx1388, align 8
  %arrayidx1389 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %542 = load i64, i64* %arrayidx1389, align 16
  %shr1390 = lshr i64 %542, 8
  %conv1391 = trunc i64 %shr1390 to i8
  %idxprom1392 = zext i8 %conv1391 to i64
  %arrayidx1393 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 1), i64 0, i64 %idxprom1392
  %543 = load i64, i64* %arrayidx1393, align 8
  %xor1394 = xor i64 %541, %543
  %arrayidx1395 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %544 = load i64, i64* %arrayidx1395, align 8
  %shr1396 = lshr i64 %544, 16
  %conv1397 = trunc i64 %shr1396 to i8
  %idxprom1398 = zext i8 %conv1397 to i64
  %arrayidx1399 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 2), i64 0, i64 %idxprom1398
  %545 = load i64, i64* %arrayidx1399, align 8
  %xor1400 = xor i64 %xor1394, %545
  %arrayidx1401 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %546 = load i64, i64* %arrayidx1401, align 16
  %shr1402 = lshr i64 %546, 24
  %conv1403 = trunc i64 %shr1402 to i8
  %idxprom1404 = zext i8 %conv1403 to i64
  %arrayidx1405 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @ft_tab, i64 0, i64 3), i64 0, i64 %idxprom1404
  %547 = load i64, i64* %arrayidx1405, align 8
  %xor1406 = xor i64 %xor1400, %547
  %xor1407 = xor i64 %539, %xor1406
  %arrayidx1408 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor1407, i64* %arrayidx1408, align 8
  %548 = load i64*, i64** %kp, align 8
  %add.ptr1409 = getelementptr inbounds i64, i64* %548, i64 36
  %arrayidx1410 = getelementptr inbounds i64, i64* %add.ptr1409, i64 0
  %549 = load i64, i64* %arrayidx1410, align 8
  %arrayidx1411 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %550 = load i64, i64* %arrayidx1411, align 16
  %shr1412 = lshr i64 %550, 0
  %conv1413 = trunc i64 %shr1412 to i8
  %idxprom1414 = zext i8 %conv1413 to i64
  %arrayidx1415 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 0), i64 0, i64 %idxprom1414
  %551 = load i64, i64* %arrayidx1415, align 8
  %arrayidx1416 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %552 = load i64, i64* %arrayidx1416, align 8
  %shr1417 = lshr i64 %552, 8
  %conv1418 = trunc i64 %shr1417 to i8
  %idxprom1419 = zext i8 %conv1418 to i64
  %arrayidx1420 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 1), i64 0, i64 %idxprom1419
  %553 = load i64, i64* %arrayidx1420, align 8
  %xor1421 = xor i64 %551, %553
  %arrayidx1422 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %554 = load i64, i64* %arrayidx1422, align 16
  %shr1423 = lshr i64 %554, 16
  %conv1424 = trunc i64 %shr1423 to i8
  %idxprom1425 = zext i8 %conv1424 to i64
  %arrayidx1426 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 2), i64 0, i64 %idxprom1425
  %555 = load i64, i64* %arrayidx1426, align 8
  %xor1427 = xor i64 %xor1421, %555
  %arrayidx1428 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %556 = load i64, i64* %arrayidx1428, align 8
  %shr1429 = lshr i64 %556, 24
  %conv1430 = trunc i64 %shr1429 to i8
  %idxprom1431 = zext i8 %conv1430 to i64
  %arrayidx1432 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 3), i64 0, i64 %idxprom1431
  %557 = load i64, i64* %arrayidx1432, align 8
  %xor1433 = xor i64 %xor1427, %557
  %xor1434 = xor i64 %549, %xor1433
  %arrayidx1435 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor1434, i64* %arrayidx1435, align 16
  %558 = load i64*, i64** %kp, align 8
  %add.ptr1436 = getelementptr inbounds i64, i64* %558, i64 36
  %arrayidx1437 = getelementptr inbounds i64, i64* %add.ptr1436, i64 1
  %559 = load i64, i64* %arrayidx1437, align 8
  %arrayidx1438 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %560 = load i64, i64* %arrayidx1438, align 8
  %shr1439 = lshr i64 %560, 0
  %conv1440 = trunc i64 %shr1439 to i8
  %idxprom1441 = zext i8 %conv1440 to i64
  %arrayidx1442 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 0), i64 0, i64 %idxprom1441
  %561 = load i64, i64* %arrayidx1442, align 8
  %arrayidx1443 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %562 = load i64, i64* %arrayidx1443, align 16
  %shr1444 = lshr i64 %562, 8
  %conv1445 = trunc i64 %shr1444 to i8
  %idxprom1446 = zext i8 %conv1445 to i64
  %arrayidx1447 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 1), i64 0, i64 %idxprom1446
  %563 = load i64, i64* %arrayidx1447, align 8
  %xor1448 = xor i64 %561, %563
  %arrayidx1449 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %564 = load i64, i64* %arrayidx1449, align 8
  %shr1450 = lshr i64 %564, 16
  %conv1451 = trunc i64 %shr1450 to i8
  %idxprom1452 = zext i8 %conv1451 to i64
  %arrayidx1453 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 2), i64 0, i64 %idxprom1452
  %565 = load i64, i64* %arrayidx1453, align 8
  %xor1454 = xor i64 %xor1448, %565
  %arrayidx1455 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %566 = load i64, i64* %arrayidx1455, align 16
  %shr1456 = lshr i64 %566, 24
  %conv1457 = trunc i64 %shr1456 to i8
  %idxprom1458 = zext i8 %conv1457 to i64
  %arrayidx1459 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 3), i64 0, i64 %idxprom1458
  %567 = load i64, i64* %arrayidx1459, align 8
  %xor1460 = xor i64 %xor1454, %567
  %xor1461 = xor i64 %559, %xor1460
  %arrayidx1462 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor1461, i64* %arrayidx1462, align 8
  %568 = load i64*, i64** %kp, align 8
  %add.ptr1463 = getelementptr inbounds i64, i64* %568, i64 36
  %arrayidx1464 = getelementptr inbounds i64, i64* %add.ptr1463, i64 2
  %569 = load i64, i64* %arrayidx1464, align 8
  %arrayidx1465 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %570 = load i64, i64* %arrayidx1465, align 16
  %shr1466 = lshr i64 %570, 0
  %conv1467 = trunc i64 %shr1466 to i8
  %idxprom1468 = zext i8 %conv1467 to i64
  %arrayidx1469 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 0), i64 0, i64 %idxprom1468
  %571 = load i64, i64* %arrayidx1469, align 8
  %arrayidx1470 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %572 = load i64, i64* %arrayidx1470, align 8
  %shr1471 = lshr i64 %572, 8
  %conv1472 = trunc i64 %shr1471 to i8
  %idxprom1473 = zext i8 %conv1472 to i64
  %arrayidx1474 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 1), i64 0, i64 %idxprom1473
  %573 = load i64, i64* %arrayidx1474, align 8
  %xor1475 = xor i64 %571, %573
  %arrayidx1476 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %574 = load i64, i64* %arrayidx1476, align 16
  %shr1477 = lshr i64 %574, 16
  %conv1478 = trunc i64 %shr1477 to i8
  %idxprom1479 = zext i8 %conv1478 to i64
  %arrayidx1480 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 2), i64 0, i64 %idxprom1479
  %575 = load i64, i64* %arrayidx1480, align 8
  %xor1481 = xor i64 %xor1475, %575
  %arrayidx1482 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %576 = load i64, i64* %arrayidx1482, align 8
  %shr1483 = lshr i64 %576, 24
  %conv1484 = trunc i64 %shr1483 to i8
  %idxprom1485 = zext i8 %conv1484 to i64
  %arrayidx1486 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 3), i64 0, i64 %idxprom1485
  %577 = load i64, i64* %arrayidx1486, align 8
  %xor1487 = xor i64 %xor1481, %577
  %xor1488 = xor i64 %569, %xor1487
  %arrayidx1489 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor1488, i64* %arrayidx1489, align 16
  %578 = load i64*, i64** %kp, align 8
  %add.ptr1490 = getelementptr inbounds i64, i64* %578, i64 36
  %arrayidx1491 = getelementptr inbounds i64, i64* %add.ptr1490, i64 3
  %579 = load i64, i64* %arrayidx1491, align 8
  %arrayidx1492 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %580 = load i64, i64* %arrayidx1492, align 8
  %shr1493 = lshr i64 %580, 0
  %conv1494 = trunc i64 %shr1493 to i8
  %idxprom1495 = zext i8 %conv1494 to i64
  %arrayidx1496 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 0), i64 0, i64 %idxprom1495
  %581 = load i64, i64* %arrayidx1496, align 8
  %arrayidx1497 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %582 = load i64, i64* %arrayidx1497, align 16
  %shr1498 = lshr i64 %582, 8
  %conv1499 = trunc i64 %shr1498 to i8
  %idxprom1500 = zext i8 %conv1499 to i64
  %arrayidx1501 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 1), i64 0, i64 %idxprom1500
  %583 = load i64, i64* %arrayidx1501, align 8
  %xor1502 = xor i64 %581, %583
  %arrayidx1503 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %584 = load i64, i64* %arrayidx1503, align 8
  %shr1504 = lshr i64 %584, 16
  %conv1505 = trunc i64 %shr1504 to i8
  %idxprom1506 = zext i8 %conv1505 to i64
  %arrayidx1507 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 2), i64 0, i64 %idxprom1506
  %585 = load i64, i64* %arrayidx1507, align 8
  %xor1508 = xor i64 %xor1502, %585
  %arrayidx1509 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %586 = load i64, i64* %arrayidx1509, align 16
  %shr1510 = lshr i64 %586, 24
  %conv1511 = trunc i64 %shr1510 to i8
  %idxprom1512 = zext i8 %conv1511 to i64
  %arrayidx1513 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @fl_tab, i64 0, i64 3), i64 0, i64 %idxprom1512
  %587 = load i64, i64* %arrayidx1513, align 8
  %xor1514 = xor i64 %xor1508, %587
  %xor1515 = xor i64 %579, %xor1514
  %arrayidx1516 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor1515, i64* %arrayidx1516, align 8
  br label %sw.epilog

sw.epilog:                                        ; preds = %sw.bb440, %if.end
  %arrayidx1517 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %588 = load i64, i64* %arrayidx1517, align 16
  %589 = load i8*, i8** %out_blk.addr, align 8
  %add.ptr1518 = getelementptr inbounds i8, i8* %589, i64 0
  %590 = bitcast i8* %add.ptr1518 to i64*
  store i64 %588, i64* %590, align 8
  %arrayidx1519 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %591 = load i64, i64* %arrayidx1519, align 8
  %592 = load i8*, i8** %out_blk.addr, align 8
  %add.ptr1520 = getelementptr inbounds i8, i8* %592, i64 4
  %593 = bitcast i8* %add.ptr1520 to i64*
  store i64 %591, i64* %593, align 8
  %arrayidx1521 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %594 = load i64, i64* %arrayidx1521, align 16
  %595 = load i8*, i8** %out_blk.addr, align 8
  %add.ptr1522 = getelementptr inbounds i8, i8* %595, i64 8
  %596 = bitcast i8* %add.ptr1522 to i64*
  store i64 %594, i64* %596, align 8
  %arrayidx1523 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %597 = load i64, i64* %arrayidx1523, align 8
  %598 = load i8*, i8** %out_blk.addr, align 8
  %add.ptr1524 = getelementptr inbounds i8, i8* %598, i64 12
  %599 = bitcast i8* %add.ptr1524 to i64*
  store i64 %597, i64* %599, align 8
  store i16 1, i16* %retval, align 2
  br label %return

return:                                           ; preds = %sw.epilog, %if.then
  %600 = load i16, i16* %retval, align 2
  ret i16 %600
}

; Function Attrs: nounwind uwtable
define signext i16 @decrypt(i8* %in_blk, i8* %out_blk, %struct.aes* %cx) #0 {
entry:
  %retval = alloca i16, align 2
  %in_blk.addr = alloca i8*, align 8
  %out_blk.addr = alloca i8*, align 8
  %cx.addr = alloca %struct.aes*, align 8
  %b1 = alloca [4 x i64], align 16
  %b0 = alloca [4 x i64], align 16
  %kp = alloca i64*, align 8
  store i8* %in_blk, i8** %in_blk.addr, align 8
  store i8* %out_blk, i8** %out_blk.addr, align 8
  store %struct.aes* %cx, %struct.aes** %cx.addr, align 8
  %0 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %d_key = getelementptr inbounds %struct.aes, %struct.aes* %0, i32 0, i32 3
  %arraydecay = getelementptr inbounds [64 x i64], [64 x i64]* %d_key, i32 0, i32 0
  store i64* %arraydecay, i64** %kp, align 8
  %1 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %mode = getelementptr inbounds %struct.aes, %struct.aes* %1, i32 0, i32 4
  %2 = load i8, i8* %mode, align 8
  %conv = zext i8 %2 to i32
  %and = and i32 %conv, 2
  %tobool = icmp ne i32 %and, 0
  br i1 %tobool, label %if.end, label %if.then

if.then:                                          ; preds = %entry
  store i16 0, i16* %retval, align 2
  br label %return

if.end:                                           ; preds = %entry
  %3 = load i8*, i8** %in_blk.addr, align 8
  %add.ptr = getelementptr inbounds i8, i8* %3, i64 0
  %4 = bitcast i8* %add.ptr to i64*
  %5 = load i64, i64* %4, align 8
  %6 = load i64*, i64** %kp, align 8
  %arrayidx = getelementptr inbounds i64, i64* %6, i64 0
  %7 = load i64, i64* %arrayidx, align 8
  %xor = xor i64 %5, %7
  %arrayidx1 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor, i64* %arrayidx1, align 16
  %8 = load i8*, i8** %in_blk.addr, align 8
  %add.ptr2 = getelementptr inbounds i8, i8* %8, i64 4
  %9 = bitcast i8* %add.ptr2 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = load i64*, i64** %kp, align 8
  %arrayidx3 = getelementptr inbounds i64, i64* %11, i64 1
  %12 = load i64, i64* %arrayidx3, align 8
  %xor4 = xor i64 %10, %12
  %arrayidx5 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor4, i64* %arrayidx5, align 8
  %13 = load i8*, i8** %in_blk.addr, align 8
  %add.ptr6 = getelementptr inbounds i8, i8* %13, i64 8
  %14 = bitcast i8* %add.ptr6 to i64*
  %15 = load i64, i64* %14, align 8
  %16 = load i64*, i64** %kp, align 8
  %arrayidx7 = getelementptr inbounds i64, i64* %16, i64 2
  %17 = load i64, i64* %arrayidx7, align 8
  %xor8 = xor i64 %15, %17
  %arrayidx9 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor8, i64* %arrayidx9, align 16
  %18 = load i8*, i8** %in_blk.addr, align 8
  %add.ptr10 = getelementptr inbounds i8, i8* %18, i64 12
  %19 = bitcast i8* %add.ptr10 to i64*
  %20 = load i64, i64* %19, align 8
  %21 = load i64*, i64** %kp, align 8
  %arrayidx11 = getelementptr inbounds i64, i64* %21, i64 3
  %22 = load i64, i64* %arrayidx11, align 8
  %xor12 = xor i64 %20, %22
  %arrayidx13 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor12, i64* %arrayidx13, align 8
  %23 = load i64*, i64** %kp, align 8
  %add.ptr14 = getelementptr inbounds i64, i64* %23, i64 4
  store i64* %add.ptr14, i64** %kp, align 8
  %24 = load %struct.aes*, %struct.aes** %cx.addr, align 8
  %Nrnd = getelementptr inbounds %struct.aes, %struct.aes* %24, i32 0, i32 1
  %25 = load i64, i64* %Nrnd, align 8
  switch i64 %25, label %sw.epilog [
    i64 14, label %sw.bb
    i64 12, label %sw.bb226
    i64 10, label %sw.bb440
  ]

sw.bb:                                            ; preds = %if.end
  %26 = load i64*, i64** %kp, align 8
  %arrayidx15 = getelementptr inbounds i64, i64* %26, i64 0
  %27 = load i64, i64* %arrayidx15, align 8
  %arrayidx16 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %28 = load i64, i64* %arrayidx16, align 16
  %shr = lshr i64 %28, 0
  %conv17 = trunc i64 %shr to i8
  %idxprom = zext i8 %conv17 to i64
  %arrayidx18 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom
  %29 = load i64, i64* %arrayidx18, align 8
  %arrayidx19 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %30 = load i64, i64* %arrayidx19, align 8
  %shr20 = lshr i64 %30, 8
  %conv21 = trunc i64 %shr20 to i8
  %idxprom22 = zext i8 %conv21 to i64
  %arrayidx23 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom22
  %31 = load i64, i64* %arrayidx23, align 8
  %xor24 = xor i64 %29, %31
  %arrayidx25 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %32 = load i64, i64* %arrayidx25, align 16
  %shr26 = lshr i64 %32, 16
  %conv27 = trunc i64 %shr26 to i8
  %idxprom28 = zext i8 %conv27 to i64
  %arrayidx29 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom28
  %33 = load i64, i64* %arrayidx29, align 8
  %xor30 = xor i64 %xor24, %33
  %arrayidx31 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %34 = load i64, i64* %arrayidx31, align 8
  %shr32 = lshr i64 %34, 24
  %conv33 = trunc i64 %shr32 to i8
  %idxprom34 = zext i8 %conv33 to i64
  %arrayidx35 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom34
  %35 = load i64, i64* %arrayidx35, align 8
  %xor36 = xor i64 %xor30, %35
  %xor37 = xor i64 %27, %xor36
  %arrayidx38 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor37, i64* %arrayidx38, align 16
  %36 = load i64*, i64** %kp, align 8
  %arrayidx39 = getelementptr inbounds i64, i64* %36, i64 1
  %37 = load i64, i64* %arrayidx39, align 8
  %arrayidx40 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %38 = load i64, i64* %arrayidx40, align 8
  %shr41 = lshr i64 %38, 0
  %conv42 = trunc i64 %shr41 to i8
  %idxprom43 = zext i8 %conv42 to i64
  %arrayidx44 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom43
  %39 = load i64, i64* %arrayidx44, align 8
  %arrayidx45 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %40 = load i64, i64* %arrayidx45, align 16
  %shr46 = lshr i64 %40, 8
  %conv47 = trunc i64 %shr46 to i8
  %idxprom48 = zext i8 %conv47 to i64
  %arrayidx49 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom48
  %41 = load i64, i64* %arrayidx49, align 8
  %xor50 = xor i64 %39, %41
  %arrayidx51 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %42 = load i64, i64* %arrayidx51, align 8
  %shr52 = lshr i64 %42, 16
  %conv53 = trunc i64 %shr52 to i8
  %idxprom54 = zext i8 %conv53 to i64
  %arrayidx55 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom54
  %43 = load i64, i64* %arrayidx55, align 8
  %xor56 = xor i64 %xor50, %43
  %arrayidx57 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %44 = load i64, i64* %arrayidx57, align 16
  %shr58 = lshr i64 %44, 24
  %conv59 = trunc i64 %shr58 to i8
  %idxprom60 = zext i8 %conv59 to i64
  %arrayidx61 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom60
  %45 = load i64, i64* %arrayidx61, align 8
  %xor62 = xor i64 %xor56, %45
  %xor63 = xor i64 %37, %xor62
  %arrayidx64 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor63, i64* %arrayidx64, align 8
  %46 = load i64*, i64** %kp, align 8
  %arrayidx65 = getelementptr inbounds i64, i64* %46, i64 2
  %47 = load i64, i64* %arrayidx65, align 8
  %arrayidx66 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %48 = load i64, i64* %arrayidx66, align 16
  %shr67 = lshr i64 %48, 0
  %conv68 = trunc i64 %shr67 to i8
  %idxprom69 = zext i8 %conv68 to i64
  %arrayidx70 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom69
  %49 = load i64, i64* %arrayidx70, align 8
  %arrayidx71 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %50 = load i64, i64* %arrayidx71, align 8
  %shr72 = lshr i64 %50, 8
  %conv73 = trunc i64 %shr72 to i8
  %idxprom74 = zext i8 %conv73 to i64
  %arrayidx75 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom74
  %51 = load i64, i64* %arrayidx75, align 8
  %xor76 = xor i64 %49, %51
  %arrayidx77 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %52 = load i64, i64* %arrayidx77, align 16
  %shr78 = lshr i64 %52, 16
  %conv79 = trunc i64 %shr78 to i8
  %idxprom80 = zext i8 %conv79 to i64
  %arrayidx81 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom80
  %53 = load i64, i64* %arrayidx81, align 8
  %xor82 = xor i64 %xor76, %53
  %arrayidx83 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %54 = load i64, i64* %arrayidx83, align 8
  %shr84 = lshr i64 %54, 24
  %conv85 = trunc i64 %shr84 to i8
  %idxprom86 = zext i8 %conv85 to i64
  %arrayidx87 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom86
  %55 = load i64, i64* %arrayidx87, align 8
  %xor88 = xor i64 %xor82, %55
  %xor89 = xor i64 %47, %xor88
  %arrayidx90 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor89, i64* %arrayidx90, align 16
  %56 = load i64*, i64** %kp, align 8
  %arrayidx91 = getelementptr inbounds i64, i64* %56, i64 3
  %57 = load i64, i64* %arrayidx91, align 8
  %arrayidx92 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %58 = load i64, i64* %arrayidx92, align 8
  %shr93 = lshr i64 %58, 0
  %conv94 = trunc i64 %shr93 to i8
  %idxprom95 = zext i8 %conv94 to i64
  %arrayidx96 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom95
  %59 = load i64, i64* %arrayidx96, align 8
  %arrayidx97 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %60 = load i64, i64* %arrayidx97, align 16
  %shr98 = lshr i64 %60, 8
  %conv99 = trunc i64 %shr98 to i8
  %idxprom100 = zext i8 %conv99 to i64
  %arrayidx101 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom100
  %61 = load i64, i64* %arrayidx101, align 8
  %xor102 = xor i64 %59, %61
  %arrayidx103 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %62 = load i64, i64* %arrayidx103, align 8
  %shr104 = lshr i64 %62, 16
  %conv105 = trunc i64 %shr104 to i8
  %idxprom106 = zext i8 %conv105 to i64
  %arrayidx107 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom106
  %63 = load i64, i64* %arrayidx107, align 8
  %xor108 = xor i64 %xor102, %63
  %arrayidx109 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %64 = load i64, i64* %arrayidx109, align 16
  %shr110 = lshr i64 %64, 24
  %conv111 = trunc i64 %shr110 to i8
  %idxprom112 = zext i8 %conv111 to i64
  %arrayidx113 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom112
  %65 = load i64, i64* %arrayidx113, align 8
  %xor114 = xor i64 %xor108, %65
  %xor115 = xor i64 %57, %xor114
  %arrayidx116 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor115, i64* %arrayidx116, align 8
  %66 = load i64*, i64** %kp, align 8
  %add.ptr117 = getelementptr inbounds i64, i64* %66, i64 4
  %arrayidx118 = getelementptr inbounds i64, i64* %add.ptr117, i64 0
  %67 = load i64, i64* %arrayidx118, align 8
  %arrayidx119 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %68 = load i64, i64* %arrayidx119, align 16
  %shr120 = lshr i64 %68, 0
  %conv121 = trunc i64 %shr120 to i8
  %idxprom122 = zext i8 %conv121 to i64
  %arrayidx123 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom122
  %69 = load i64, i64* %arrayidx123, align 8
  %arrayidx124 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %70 = load i64, i64* %arrayidx124, align 8
  %shr125 = lshr i64 %70, 8
  %conv126 = trunc i64 %shr125 to i8
  %idxprom127 = zext i8 %conv126 to i64
  %arrayidx128 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom127
  %71 = load i64, i64* %arrayidx128, align 8
  %xor129 = xor i64 %69, %71
  %arrayidx130 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %72 = load i64, i64* %arrayidx130, align 16
  %shr131 = lshr i64 %72, 16
  %conv132 = trunc i64 %shr131 to i8
  %idxprom133 = zext i8 %conv132 to i64
  %arrayidx134 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom133
  %73 = load i64, i64* %arrayidx134, align 8
  %xor135 = xor i64 %xor129, %73
  %arrayidx136 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %74 = load i64, i64* %arrayidx136, align 8
  %shr137 = lshr i64 %74, 24
  %conv138 = trunc i64 %shr137 to i8
  %idxprom139 = zext i8 %conv138 to i64
  %arrayidx140 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom139
  %75 = load i64, i64* %arrayidx140, align 8
  %xor141 = xor i64 %xor135, %75
  %xor142 = xor i64 %67, %xor141
  %arrayidx143 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor142, i64* %arrayidx143, align 16
  %76 = load i64*, i64** %kp, align 8
  %add.ptr144 = getelementptr inbounds i64, i64* %76, i64 4
  %arrayidx145 = getelementptr inbounds i64, i64* %add.ptr144, i64 1
  %77 = load i64, i64* %arrayidx145, align 8
  %arrayidx146 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %78 = load i64, i64* %arrayidx146, align 8
  %shr147 = lshr i64 %78, 0
  %conv148 = trunc i64 %shr147 to i8
  %idxprom149 = zext i8 %conv148 to i64
  %arrayidx150 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom149
  %79 = load i64, i64* %arrayidx150, align 8
  %arrayidx151 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %80 = load i64, i64* %arrayidx151, align 16
  %shr152 = lshr i64 %80, 8
  %conv153 = trunc i64 %shr152 to i8
  %idxprom154 = zext i8 %conv153 to i64
  %arrayidx155 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom154
  %81 = load i64, i64* %arrayidx155, align 8
  %xor156 = xor i64 %79, %81
  %arrayidx157 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %82 = load i64, i64* %arrayidx157, align 8
  %shr158 = lshr i64 %82, 16
  %conv159 = trunc i64 %shr158 to i8
  %idxprom160 = zext i8 %conv159 to i64
  %arrayidx161 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom160
  %83 = load i64, i64* %arrayidx161, align 8
  %xor162 = xor i64 %xor156, %83
  %arrayidx163 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %84 = load i64, i64* %arrayidx163, align 16
  %shr164 = lshr i64 %84, 24
  %conv165 = trunc i64 %shr164 to i8
  %idxprom166 = zext i8 %conv165 to i64
  %arrayidx167 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom166
  %85 = load i64, i64* %arrayidx167, align 8
  %xor168 = xor i64 %xor162, %85
  %xor169 = xor i64 %77, %xor168
  %arrayidx170 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor169, i64* %arrayidx170, align 8
  %86 = load i64*, i64** %kp, align 8
  %add.ptr171 = getelementptr inbounds i64, i64* %86, i64 4
  %arrayidx172 = getelementptr inbounds i64, i64* %add.ptr171, i64 2
  %87 = load i64, i64* %arrayidx172, align 8
  %arrayidx173 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %88 = load i64, i64* %arrayidx173, align 16
  %shr174 = lshr i64 %88, 0
  %conv175 = trunc i64 %shr174 to i8
  %idxprom176 = zext i8 %conv175 to i64
  %arrayidx177 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom176
  %89 = load i64, i64* %arrayidx177, align 8
  %arrayidx178 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %90 = load i64, i64* %arrayidx178, align 8
  %shr179 = lshr i64 %90, 8
  %conv180 = trunc i64 %shr179 to i8
  %idxprom181 = zext i8 %conv180 to i64
  %arrayidx182 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom181
  %91 = load i64, i64* %arrayidx182, align 8
  %xor183 = xor i64 %89, %91
  %arrayidx184 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %92 = load i64, i64* %arrayidx184, align 16
  %shr185 = lshr i64 %92, 16
  %conv186 = trunc i64 %shr185 to i8
  %idxprom187 = zext i8 %conv186 to i64
  %arrayidx188 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom187
  %93 = load i64, i64* %arrayidx188, align 8
  %xor189 = xor i64 %xor183, %93
  %arrayidx190 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %94 = load i64, i64* %arrayidx190, align 8
  %shr191 = lshr i64 %94, 24
  %conv192 = trunc i64 %shr191 to i8
  %idxprom193 = zext i8 %conv192 to i64
  %arrayidx194 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom193
  %95 = load i64, i64* %arrayidx194, align 8
  %xor195 = xor i64 %xor189, %95
  %xor196 = xor i64 %87, %xor195
  %arrayidx197 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor196, i64* %arrayidx197, align 16
  %96 = load i64*, i64** %kp, align 8
  %add.ptr198 = getelementptr inbounds i64, i64* %96, i64 4
  %arrayidx199 = getelementptr inbounds i64, i64* %add.ptr198, i64 3
  %97 = load i64, i64* %arrayidx199, align 8
  %arrayidx200 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %98 = load i64, i64* %arrayidx200, align 8
  %shr201 = lshr i64 %98, 0
  %conv202 = trunc i64 %shr201 to i8
  %idxprom203 = zext i8 %conv202 to i64
  %arrayidx204 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom203
  %99 = load i64, i64* %arrayidx204, align 8
  %arrayidx205 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %100 = load i64, i64* %arrayidx205, align 16
  %shr206 = lshr i64 %100, 8
  %conv207 = trunc i64 %shr206 to i8
  %idxprom208 = zext i8 %conv207 to i64
  %arrayidx209 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom208
  %101 = load i64, i64* %arrayidx209, align 8
  %xor210 = xor i64 %99, %101
  %arrayidx211 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %102 = load i64, i64* %arrayidx211, align 8
  %shr212 = lshr i64 %102, 16
  %conv213 = trunc i64 %shr212 to i8
  %idxprom214 = zext i8 %conv213 to i64
  %arrayidx215 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom214
  %103 = load i64, i64* %arrayidx215, align 8
  %xor216 = xor i64 %xor210, %103
  %arrayidx217 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %104 = load i64, i64* %arrayidx217, align 16
  %shr218 = lshr i64 %104, 24
  %conv219 = trunc i64 %shr218 to i8
  %idxprom220 = zext i8 %conv219 to i64
  %arrayidx221 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom220
  %105 = load i64, i64* %arrayidx221, align 8
  %xor222 = xor i64 %xor216, %105
  %xor223 = xor i64 %97, %xor222
  %arrayidx224 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor223, i64* %arrayidx224, align 8
  %106 = load i64*, i64** %kp, align 8
  %add.ptr225 = getelementptr inbounds i64, i64* %106, i64 8
  store i64* %add.ptr225, i64** %kp, align 8
  br label %sw.bb226

sw.bb226:                                         ; preds = %if.end, %sw.bb
  %107 = load i64*, i64** %kp, align 8
  %arrayidx227 = getelementptr inbounds i64, i64* %107, i64 0
  %108 = load i64, i64* %arrayidx227, align 8
  %arrayidx228 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %109 = load i64, i64* %arrayidx228, align 16
  %shr229 = lshr i64 %109, 0
  %conv230 = trunc i64 %shr229 to i8
  %idxprom231 = zext i8 %conv230 to i64
  %arrayidx232 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom231
  %110 = load i64, i64* %arrayidx232, align 8
  %arrayidx233 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %111 = load i64, i64* %arrayidx233, align 8
  %shr234 = lshr i64 %111, 8
  %conv235 = trunc i64 %shr234 to i8
  %idxprom236 = zext i8 %conv235 to i64
  %arrayidx237 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom236
  %112 = load i64, i64* %arrayidx237, align 8
  %xor238 = xor i64 %110, %112
  %arrayidx239 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %113 = load i64, i64* %arrayidx239, align 16
  %shr240 = lshr i64 %113, 16
  %conv241 = trunc i64 %shr240 to i8
  %idxprom242 = zext i8 %conv241 to i64
  %arrayidx243 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom242
  %114 = load i64, i64* %arrayidx243, align 8
  %xor244 = xor i64 %xor238, %114
  %arrayidx245 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %115 = load i64, i64* %arrayidx245, align 8
  %shr246 = lshr i64 %115, 24
  %conv247 = trunc i64 %shr246 to i8
  %idxprom248 = zext i8 %conv247 to i64
  %arrayidx249 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom248
  %116 = load i64, i64* %arrayidx249, align 8
  %xor250 = xor i64 %xor244, %116
  %xor251 = xor i64 %108, %xor250
  %arrayidx252 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor251, i64* %arrayidx252, align 16
  %117 = load i64*, i64** %kp, align 8
  %arrayidx253 = getelementptr inbounds i64, i64* %117, i64 1
  %118 = load i64, i64* %arrayidx253, align 8
  %arrayidx254 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %119 = load i64, i64* %arrayidx254, align 8
  %shr255 = lshr i64 %119, 0
  %conv256 = trunc i64 %shr255 to i8
  %idxprom257 = zext i8 %conv256 to i64
  %arrayidx258 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom257
  %120 = load i64, i64* %arrayidx258, align 8
  %arrayidx259 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %121 = load i64, i64* %arrayidx259, align 16
  %shr260 = lshr i64 %121, 8
  %conv261 = trunc i64 %shr260 to i8
  %idxprom262 = zext i8 %conv261 to i64
  %arrayidx263 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom262
  %122 = load i64, i64* %arrayidx263, align 8
  %xor264 = xor i64 %120, %122
  %arrayidx265 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %123 = load i64, i64* %arrayidx265, align 8
  %shr266 = lshr i64 %123, 16
  %conv267 = trunc i64 %shr266 to i8
  %idxprom268 = zext i8 %conv267 to i64
  %arrayidx269 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom268
  %124 = load i64, i64* %arrayidx269, align 8
  %xor270 = xor i64 %xor264, %124
  %arrayidx271 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %125 = load i64, i64* %arrayidx271, align 16
  %shr272 = lshr i64 %125, 24
  %conv273 = trunc i64 %shr272 to i8
  %idxprom274 = zext i8 %conv273 to i64
  %arrayidx275 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom274
  %126 = load i64, i64* %arrayidx275, align 8
  %xor276 = xor i64 %xor270, %126
  %xor277 = xor i64 %118, %xor276
  %arrayidx278 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor277, i64* %arrayidx278, align 8
  %127 = load i64*, i64** %kp, align 8
  %arrayidx279 = getelementptr inbounds i64, i64* %127, i64 2
  %128 = load i64, i64* %arrayidx279, align 8
  %arrayidx280 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %129 = load i64, i64* %arrayidx280, align 16
  %shr281 = lshr i64 %129, 0
  %conv282 = trunc i64 %shr281 to i8
  %idxprom283 = zext i8 %conv282 to i64
  %arrayidx284 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom283
  %130 = load i64, i64* %arrayidx284, align 8
  %arrayidx285 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %131 = load i64, i64* %arrayidx285, align 8
  %shr286 = lshr i64 %131, 8
  %conv287 = trunc i64 %shr286 to i8
  %idxprom288 = zext i8 %conv287 to i64
  %arrayidx289 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom288
  %132 = load i64, i64* %arrayidx289, align 8
  %xor290 = xor i64 %130, %132
  %arrayidx291 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %133 = load i64, i64* %arrayidx291, align 16
  %shr292 = lshr i64 %133, 16
  %conv293 = trunc i64 %shr292 to i8
  %idxprom294 = zext i8 %conv293 to i64
  %arrayidx295 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom294
  %134 = load i64, i64* %arrayidx295, align 8
  %xor296 = xor i64 %xor290, %134
  %arrayidx297 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %135 = load i64, i64* %arrayidx297, align 8
  %shr298 = lshr i64 %135, 24
  %conv299 = trunc i64 %shr298 to i8
  %idxprom300 = zext i8 %conv299 to i64
  %arrayidx301 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom300
  %136 = load i64, i64* %arrayidx301, align 8
  %xor302 = xor i64 %xor296, %136
  %xor303 = xor i64 %128, %xor302
  %arrayidx304 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor303, i64* %arrayidx304, align 16
  %137 = load i64*, i64** %kp, align 8
  %arrayidx305 = getelementptr inbounds i64, i64* %137, i64 3
  %138 = load i64, i64* %arrayidx305, align 8
  %arrayidx306 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %139 = load i64, i64* %arrayidx306, align 8
  %shr307 = lshr i64 %139, 0
  %conv308 = trunc i64 %shr307 to i8
  %idxprom309 = zext i8 %conv308 to i64
  %arrayidx310 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom309
  %140 = load i64, i64* %arrayidx310, align 8
  %arrayidx311 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %141 = load i64, i64* %arrayidx311, align 16
  %shr312 = lshr i64 %141, 8
  %conv313 = trunc i64 %shr312 to i8
  %idxprom314 = zext i8 %conv313 to i64
  %arrayidx315 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom314
  %142 = load i64, i64* %arrayidx315, align 8
  %xor316 = xor i64 %140, %142
  %arrayidx317 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %143 = load i64, i64* %arrayidx317, align 8
  %shr318 = lshr i64 %143, 16
  %conv319 = trunc i64 %shr318 to i8
  %idxprom320 = zext i8 %conv319 to i64
  %arrayidx321 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom320
  %144 = load i64, i64* %arrayidx321, align 8
  %xor322 = xor i64 %xor316, %144
  %arrayidx323 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %145 = load i64, i64* %arrayidx323, align 16
  %shr324 = lshr i64 %145, 24
  %conv325 = trunc i64 %shr324 to i8
  %idxprom326 = zext i8 %conv325 to i64
  %arrayidx327 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom326
  %146 = load i64, i64* %arrayidx327, align 8
  %xor328 = xor i64 %xor322, %146
  %xor329 = xor i64 %138, %xor328
  %arrayidx330 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor329, i64* %arrayidx330, align 8
  %147 = load i64*, i64** %kp, align 8
  %add.ptr331 = getelementptr inbounds i64, i64* %147, i64 4
  %arrayidx332 = getelementptr inbounds i64, i64* %add.ptr331, i64 0
  %148 = load i64, i64* %arrayidx332, align 8
  %arrayidx333 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %149 = load i64, i64* %arrayidx333, align 16
  %shr334 = lshr i64 %149, 0
  %conv335 = trunc i64 %shr334 to i8
  %idxprom336 = zext i8 %conv335 to i64
  %arrayidx337 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom336
  %150 = load i64, i64* %arrayidx337, align 8
  %arrayidx338 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %151 = load i64, i64* %arrayidx338, align 8
  %shr339 = lshr i64 %151, 8
  %conv340 = trunc i64 %shr339 to i8
  %idxprom341 = zext i8 %conv340 to i64
  %arrayidx342 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom341
  %152 = load i64, i64* %arrayidx342, align 8
  %xor343 = xor i64 %150, %152
  %arrayidx344 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %153 = load i64, i64* %arrayidx344, align 16
  %shr345 = lshr i64 %153, 16
  %conv346 = trunc i64 %shr345 to i8
  %idxprom347 = zext i8 %conv346 to i64
  %arrayidx348 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom347
  %154 = load i64, i64* %arrayidx348, align 8
  %xor349 = xor i64 %xor343, %154
  %arrayidx350 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %155 = load i64, i64* %arrayidx350, align 8
  %shr351 = lshr i64 %155, 24
  %conv352 = trunc i64 %shr351 to i8
  %idxprom353 = zext i8 %conv352 to i64
  %arrayidx354 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom353
  %156 = load i64, i64* %arrayidx354, align 8
  %xor355 = xor i64 %xor349, %156
  %xor356 = xor i64 %148, %xor355
  %arrayidx357 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor356, i64* %arrayidx357, align 16
  %157 = load i64*, i64** %kp, align 8
  %add.ptr358 = getelementptr inbounds i64, i64* %157, i64 4
  %arrayidx359 = getelementptr inbounds i64, i64* %add.ptr358, i64 1
  %158 = load i64, i64* %arrayidx359, align 8
  %arrayidx360 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %159 = load i64, i64* %arrayidx360, align 8
  %shr361 = lshr i64 %159, 0
  %conv362 = trunc i64 %shr361 to i8
  %idxprom363 = zext i8 %conv362 to i64
  %arrayidx364 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom363
  %160 = load i64, i64* %arrayidx364, align 8
  %arrayidx365 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %161 = load i64, i64* %arrayidx365, align 16
  %shr366 = lshr i64 %161, 8
  %conv367 = trunc i64 %shr366 to i8
  %idxprom368 = zext i8 %conv367 to i64
  %arrayidx369 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom368
  %162 = load i64, i64* %arrayidx369, align 8
  %xor370 = xor i64 %160, %162
  %arrayidx371 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %163 = load i64, i64* %arrayidx371, align 8
  %shr372 = lshr i64 %163, 16
  %conv373 = trunc i64 %shr372 to i8
  %idxprom374 = zext i8 %conv373 to i64
  %arrayidx375 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom374
  %164 = load i64, i64* %arrayidx375, align 8
  %xor376 = xor i64 %xor370, %164
  %arrayidx377 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %165 = load i64, i64* %arrayidx377, align 16
  %shr378 = lshr i64 %165, 24
  %conv379 = trunc i64 %shr378 to i8
  %idxprom380 = zext i8 %conv379 to i64
  %arrayidx381 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom380
  %166 = load i64, i64* %arrayidx381, align 8
  %xor382 = xor i64 %xor376, %166
  %xor383 = xor i64 %158, %xor382
  %arrayidx384 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor383, i64* %arrayidx384, align 8
  %167 = load i64*, i64** %kp, align 8
  %add.ptr385 = getelementptr inbounds i64, i64* %167, i64 4
  %arrayidx386 = getelementptr inbounds i64, i64* %add.ptr385, i64 2
  %168 = load i64, i64* %arrayidx386, align 8
  %arrayidx387 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %169 = load i64, i64* %arrayidx387, align 16
  %shr388 = lshr i64 %169, 0
  %conv389 = trunc i64 %shr388 to i8
  %idxprom390 = zext i8 %conv389 to i64
  %arrayidx391 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom390
  %170 = load i64, i64* %arrayidx391, align 8
  %arrayidx392 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %171 = load i64, i64* %arrayidx392, align 8
  %shr393 = lshr i64 %171, 8
  %conv394 = trunc i64 %shr393 to i8
  %idxprom395 = zext i8 %conv394 to i64
  %arrayidx396 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom395
  %172 = load i64, i64* %arrayidx396, align 8
  %xor397 = xor i64 %170, %172
  %arrayidx398 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %173 = load i64, i64* %arrayidx398, align 16
  %shr399 = lshr i64 %173, 16
  %conv400 = trunc i64 %shr399 to i8
  %idxprom401 = zext i8 %conv400 to i64
  %arrayidx402 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom401
  %174 = load i64, i64* %arrayidx402, align 8
  %xor403 = xor i64 %xor397, %174
  %arrayidx404 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %175 = load i64, i64* %arrayidx404, align 8
  %shr405 = lshr i64 %175, 24
  %conv406 = trunc i64 %shr405 to i8
  %idxprom407 = zext i8 %conv406 to i64
  %arrayidx408 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom407
  %176 = load i64, i64* %arrayidx408, align 8
  %xor409 = xor i64 %xor403, %176
  %xor410 = xor i64 %168, %xor409
  %arrayidx411 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor410, i64* %arrayidx411, align 16
  %177 = load i64*, i64** %kp, align 8
  %add.ptr412 = getelementptr inbounds i64, i64* %177, i64 4
  %arrayidx413 = getelementptr inbounds i64, i64* %add.ptr412, i64 3
  %178 = load i64, i64* %arrayidx413, align 8
  %arrayidx414 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %179 = load i64, i64* %arrayidx414, align 8
  %shr415 = lshr i64 %179, 0
  %conv416 = trunc i64 %shr415 to i8
  %idxprom417 = zext i8 %conv416 to i64
  %arrayidx418 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom417
  %180 = load i64, i64* %arrayidx418, align 8
  %arrayidx419 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %181 = load i64, i64* %arrayidx419, align 16
  %shr420 = lshr i64 %181, 8
  %conv421 = trunc i64 %shr420 to i8
  %idxprom422 = zext i8 %conv421 to i64
  %arrayidx423 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom422
  %182 = load i64, i64* %arrayidx423, align 8
  %xor424 = xor i64 %180, %182
  %arrayidx425 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %183 = load i64, i64* %arrayidx425, align 8
  %shr426 = lshr i64 %183, 16
  %conv427 = trunc i64 %shr426 to i8
  %idxprom428 = zext i8 %conv427 to i64
  %arrayidx429 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom428
  %184 = load i64, i64* %arrayidx429, align 8
  %xor430 = xor i64 %xor424, %184
  %arrayidx431 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %185 = load i64, i64* %arrayidx431, align 16
  %shr432 = lshr i64 %185, 24
  %conv433 = trunc i64 %shr432 to i8
  %idxprom434 = zext i8 %conv433 to i64
  %arrayidx435 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom434
  %186 = load i64, i64* %arrayidx435, align 8
  %xor436 = xor i64 %xor430, %186
  %xor437 = xor i64 %178, %xor436
  %arrayidx438 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor437, i64* %arrayidx438, align 8
  %187 = load i64*, i64** %kp, align 8
  %add.ptr439 = getelementptr inbounds i64, i64* %187, i64 8
  store i64* %add.ptr439, i64** %kp, align 8
  br label %sw.bb440

sw.bb440:                                         ; preds = %if.end, %sw.bb226
  %188 = load i64*, i64** %kp, align 8
  %arrayidx441 = getelementptr inbounds i64, i64* %188, i64 0
  %189 = load i64, i64* %arrayidx441, align 8
  %arrayidx442 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %190 = load i64, i64* %arrayidx442, align 16
  %shr443 = lshr i64 %190, 0
  %conv444 = trunc i64 %shr443 to i8
  %idxprom445 = zext i8 %conv444 to i64
  %arrayidx446 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom445
  %191 = load i64, i64* %arrayidx446, align 8
  %arrayidx447 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %192 = load i64, i64* %arrayidx447, align 8
  %shr448 = lshr i64 %192, 8
  %conv449 = trunc i64 %shr448 to i8
  %idxprom450 = zext i8 %conv449 to i64
  %arrayidx451 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom450
  %193 = load i64, i64* %arrayidx451, align 8
  %xor452 = xor i64 %191, %193
  %arrayidx453 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %194 = load i64, i64* %arrayidx453, align 16
  %shr454 = lshr i64 %194, 16
  %conv455 = trunc i64 %shr454 to i8
  %idxprom456 = zext i8 %conv455 to i64
  %arrayidx457 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom456
  %195 = load i64, i64* %arrayidx457, align 8
  %xor458 = xor i64 %xor452, %195
  %arrayidx459 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %196 = load i64, i64* %arrayidx459, align 8
  %shr460 = lshr i64 %196, 24
  %conv461 = trunc i64 %shr460 to i8
  %idxprom462 = zext i8 %conv461 to i64
  %arrayidx463 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom462
  %197 = load i64, i64* %arrayidx463, align 8
  %xor464 = xor i64 %xor458, %197
  %xor465 = xor i64 %189, %xor464
  %arrayidx466 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor465, i64* %arrayidx466, align 16
  %198 = load i64*, i64** %kp, align 8
  %arrayidx467 = getelementptr inbounds i64, i64* %198, i64 1
  %199 = load i64, i64* %arrayidx467, align 8
  %arrayidx468 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %200 = load i64, i64* %arrayidx468, align 8
  %shr469 = lshr i64 %200, 0
  %conv470 = trunc i64 %shr469 to i8
  %idxprom471 = zext i8 %conv470 to i64
  %arrayidx472 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom471
  %201 = load i64, i64* %arrayidx472, align 8
  %arrayidx473 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %202 = load i64, i64* %arrayidx473, align 16
  %shr474 = lshr i64 %202, 8
  %conv475 = trunc i64 %shr474 to i8
  %idxprom476 = zext i8 %conv475 to i64
  %arrayidx477 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom476
  %203 = load i64, i64* %arrayidx477, align 8
  %xor478 = xor i64 %201, %203
  %arrayidx479 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %204 = load i64, i64* %arrayidx479, align 8
  %shr480 = lshr i64 %204, 16
  %conv481 = trunc i64 %shr480 to i8
  %idxprom482 = zext i8 %conv481 to i64
  %arrayidx483 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom482
  %205 = load i64, i64* %arrayidx483, align 8
  %xor484 = xor i64 %xor478, %205
  %arrayidx485 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %206 = load i64, i64* %arrayidx485, align 16
  %shr486 = lshr i64 %206, 24
  %conv487 = trunc i64 %shr486 to i8
  %idxprom488 = zext i8 %conv487 to i64
  %arrayidx489 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom488
  %207 = load i64, i64* %arrayidx489, align 8
  %xor490 = xor i64 %xor484, %207
  %xor491 = xor i64 %199, %xor490
  %arrayidx492 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor491, i64* %arrayidx492, align 8
  %208 = load i64*, i64** %kp, align 8
  %arrayidx493 = getelementptr inbounds i64, i64* %208, i64 2
  %209 = load i64, i64* %arrayidx493, align 8
  %arrayidx494 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %210 = load i64, i64* %arrayidx494, align 16
  %shr495 = lshr i64 %210, 0
  %conv496 = trunc i64 %shr495 to i8
  %idxprom497 = zext i8 %conv496 to i64
  %arrayidx498 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom497
  %211 = load i64, i64* %arrayidx498, align 8
  %arrayidx499 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %212 = load i64, i64* %arrayidx499, align 8
  %shr500 = lshr i64 %212, 8
  %conv501 = trunc i64 %shr500 to i8
  %idxprom502 = zext i8 %conv501 to i64
  %arrayidx503 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom502
  %213 = load i64, i64* %arrayidx503, align 8
  %xor504 = xor i64 %211, %213
  %arrayidx505 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %214 = load i64, i64* %arrayidx505, align 16
  %shr506 = lshr i64 %214, 16
  %conv507 = trunc i64 %shr506 to i8
  %idxprom508 = zext i8 %conv507 to i64
  %arrayidx509 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom508
  %215 = load i64, i64* %arrayidx509, align 8
  %xor510 = xor i64 %xor504, %215
  %arrayidx511 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %216 = load i64, i64* %arrayidx511, align 8
  %shr512 = lshr i64 %216, 24
  %conv513 = trunc i64 %shr512 to i8
  %idxprom514 = zext i8 %conv513 to i64
  %arrayidx515 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom514
  %217 = load i64, i64* %arrayidx515, align 8
  %xor516 = xor i64 %xor510, %217
  %xor517 = xor i64 %209, %xor516
  %arrayidx518 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor517, i64* %arrayidx518, align 16
  %218 = load i64*, i64** %kp, align 8
  %arrayidx519 = getelementptr inbounds i64, i64* %218, i64 3
  %219 = load i64, i64* %arrayidx519, align 8
  %arrayidx520 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %220 = load i64, i64* %arrayidx520, align 8
  %shr521 = lshr i64 %220, 0
  %conv522 = trunc i64 %shr521 to i8
  %idxprom523 = zext i8 %conv522 to i64
  %arrayidx524 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom523
  %221 = load i64, i64* %arrayidx524, align 8
  %arrayidx525 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %222 = load i64, i64* %arrayidx525, align 16
  %shr526 = lshr i64 %222, 8
  %conv527 = trunc i64 %shr526 to i8
  %idxprom528 = zext i8 %conv527 to i64
  %arrayidx529 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom528
  %223 = load i64, i64* %arrayidx529, align 8
  %xor530 = xor i64 %221, %223
  %arrayidx531 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %224 = load i64, i64* %arrayidx531, align 8
  %shr532 = lshr i64 %224, 16
  %conv533 = trunc i64 %shr532 to i8
  %idxprom534 = zext i8 %conv533 to i64
  %arrayidx535 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom534
  %225 = load i64, i64* %arrayidx535, align 8
  %xor536 = xor i64 %xor530, %225
  %arrayidx537 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %226 = load i64, i64* %arrayidx537, align 16
  %shr538 = lshr i64 %226, 24
  %conv539 = trunc i64 %shr538 to i8
  %idxprom540 = zext i8 %conv539 to i64
  %arrayidx541 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom540
  %227 = load i64, i64* %arrayidx541, align 8
  %xor542 = xor i64 %xor536, %227
  %xor543 = xor i64 %219, %xor542
  %arrayidx544 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor543, i64* %arrayidx544, align 8
  %228 = load i64*, i64** %kp, align 8
  %add.ptr545 = getelementptr inbounds i64, i64* %228, i64 4
  %arrayidx546 = getelementptr inbounds i64, i64* %add.ptr545, i64 0
  %229 = load i64, i64* %arrayidx546, align 8
  %arrayidx547 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %230 = load i64, i64* %arrayidx547, align 16
  %shr548 = lshr i64 %230, 0
  %conv549 = trunc i64 %shr548 to i8
  %idxprom550 = zext i8 %conv549 to i64
  %arrayidx551 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom550
  %231 = load i64, i64* %arrayidx551, align 8
  %arrayidx552 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %232 = load i64, i64* %arrayidx552, align 8
  %shr553 = lshr i64 %232, 8
  %conv554 = trunc i64 %shr553 to i8
  %idxprom555 = zext i8 %conv554 to i64
  %arrayidx556 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom555
  %233 = load i64, i64* %arrayidx556, align 8
  %xor557 = xor i64 %231, %233
  %arrayidx558 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %234 = load i64, i64* %arrayidx558, align 16
  %shr559 = lshr i64 %234, 16
  %conv560 = trunc i64 %shr559 to i8
  %idxprom561 = zext i8 %conv560 to i64
  %arrayidx562 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom561
  %235 = load i64, i64* %arrayidx562, align 8
  %xor563 = xor i64 %xor557, %235
  %arrayidx564 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %236 = load i64, i64* %arrayidx564, align 8
  %shr565 = lshr i64 %236, 24
  %conv566 = trunc i64 %shr565 to i8
  %idxprom567 = zext i8 %conv566 to i64
  %arrayidx568 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom567
  %237 = load i64, i64* %arrayidx568, align 8
  %xor569 = xor i64 %xor563, %237
  %xor570 = xor i64 %229, %xor569
  %arrayidx571 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor570, i64* %arrayidx571, align 16
  %238 = load i64*, i64** %kp, align 8
  %add.ptr572 = getelementptr inbounds i64, i64* %238, i64 4
  %arrayidx573 = getelementptr inbounds i64, i64* %add.ptr572, i64 1
  %239 = load i64, i64* %arrayidx573, align 8
  %arrayidx574 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %240 = load i64, i64* %arrayidx574, align 8
  %shr575 = lshr i64 %240, 0
  %conv576 = trunc i64 %shr575 to i8
  %idxprom577 = zext i8 %conv576 to i64
  %arrayidx578 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom577
  %241 = load i64, i64* %arrayidx578, align 8
  %arrayidx579 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %242 = load i64, i64* %arrayidx579, align 16
  %shr580 = lshr i64 %242, 8
  %conv581 = trunc i64 %shr580 to i8
  %idxprom582 = zext i8 %conv581 to i64
  %arrayidx583 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom582
  %243 = load i64, i64* %arrayidx583, align 8
  %xor584 = xor i64 %241, %243
  %arrayidx585 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %244 = load i64, i64* %arrayidx585, align 8
  %shr586 = lshr i64 %244, 16
  %conv587 = trunc i64 %shr586 to i8
  %idxprom588 = zext i8 %conv587 to i64
  %arrayidx589 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom588
  %245 = load i64, i64* %arrayidx589, align 8
  %xor590 = xor i64 %xor584, %245
  %arrayidx591 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %246 = load i64, i64* %arrayidx591, align 16
  %shr592 = lshr i64 %246, 24
  %conv593 = trunc i64 %shr592 to i8
  %idxprom594 = zext i8 %conv593 to i64
  %arrayidx595 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom594
  %247 = load i64, i64* %arrayidx595, align 8
  %xor596 = xor i64 %xor590, %247
  %xor597 = xor i64 %239, %xor596
  %arrayidx598 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor597, i64* %arrayidx598, align 8
  %248 = load i64*, i64** %kp, align 8
  %add.ptr599 = getelementptr inbounds i64, i64* %248, i64 4
  %arrayidx600 = getelementptr inbounds i64, i64* %add.ptr599, i64 2
  %249 = load i64, i64* %arrayidx600, align 8
  %arrayidx601 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %250 = load i64, i64* %arrayidx601, align 16
  %shr602 = lshr i64 %250, 0
  %conv603 = trunc i64 %shr602 to i8
  %idxprom604 = zext i8 %conv603 to i64
  %arrayidx605 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom604
  %251 = load i64, i64* %arrayidx605, align 8
  %arrayidx606 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %252 = load i64, i64* %arrayidx606, align 8
  %shr607 = lshr i64 %252, 8
  %conv608 = trunc i64 %shr607 to i8
  %idxprom609 = zext i8 %conv608 to i64
  %arrayidx610 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom609
  %253 = load i64, i64* %arrayidx610, align 8
  %xor611 = xor i64 %251, %253
  %arrayidx612 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %254 = load i64, i64* %arrayidx612, align 16
  %shr613 = lshr i64 %254, 16
  %conv614 = trunc i64 %shr613 to i8
  %idxprom615 = zext i8 %conv614 to i64
  %arrayidx616 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom615
  %255 = load i64, i64* %arrayidx616, align 8
  %xor617 = xor i64 %xor611, %255
  %arrayidx618 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %256 = load i64, i64* %arrayidx618, align 8
  %shr619 = lshr i64 %256, 24
  %conv620 = trunc i64 %shr619 to i8
  %idxprom621 = zext i8 %conv620 to i64
  %arrayidx622 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom621
  %257 = load i64, i64* %arrayidx622, align 8
  %xor623 = xor i64 %xor617, %257
  %xor624 = xor i64 %249, %xor623
  %arrayidx625 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor624, i64* %arrayidx625, align 16
  %258 = load i64*, i64** %kp, align 8
  %add.ptr626 = getelementptr inbounds i64, i64* %258, i64 4
  %arrayidx627 = getelementptr inbounds i64, i64* %add.ptr626, i64 3
  %259 = load i64, i64* %arrayidx627, align 8
  %arrayidx628 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %260 = load i64, i64* %arrayidx628, align 8
  %shr629 = lshr i64 %260, 0
  %conv630 = trunc i64 %shr629 to i8
  %idxprom631 = zext i8 %conv630 to i64
  %arrayidx632 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom631
  %261 = load i64, i64* %arrayidx632, align 8
  %arrayidx633 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %262 = load i64, i64* %arrayidx633, align 16
  %shr634 = lshr i64 %262, 8
  %conv635 = trunc i64 %shr634 to i8
  %idxprom636 = zext i8 %conv635 to i64
  %arrayidx637 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom636
  %263 = load i64, i64* %arrayidx637, align 8
  %xor638 = xor i64 %261, %263
  %arrayidx639 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %264 = load i64, i64* %arrayidx639, align 8
  %shr640 = lshr i64 %264, 16
  %conv641 = trunc i64 %shr640 to i8
  %idxprom642 = zext i8 %conv641 to i64
  %arrayidx643 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom642
  %265 = load i64, i64* %arrayidx643, align 8
  %xor644 = xor i64 %xor638, %265
  %arrayidx645 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %266 = load i64, i64* %arrayidx645, align 16
  %shr646 = lshr i64 %266, 24
  %conv647 = trunc i64 %shr646 to i8
  %idxprom648 = zext i8 %conv647 to i64
  %arrayidx649 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom648
  %267 = load i64, i64* %arrayidx649, align 8
  %xor650 = xor i64 %xor644, %267
  %xor651 = xor i64 %259, %xor650
  %arrayidx652 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor651, i64* %arrayidx652, align 8
  %268 = load i64*, i64** %kp, align 8
  %add.ptr653 = getelementptr inbounds i64, i64* %268, i64 8
  %arrayidx654 = getelementptr inbounds i64, i64* %add.ptr653, i64 0
  %269 = load i64, i64* %arrayidx654, align 8
  %arrayidx655 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %270 = load i64, i64* %arrayidx655, align 16
  %shr656 = lshr i64 %270, 0
  %conv657 = trunc i64 %shr656 to i8
  %idxprom658 = zext i8 %conv657 to i64
  %arrayidx659 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom658
  %271 = load i64, i64* %arrayidx659, align 8
  %arrayidx660 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %272 = load i64, i64* %arrayidx660, align 8
  %shr661 = lshr i64 %272, 8
  %conv662 = trunc i64 %shr661 to i8
  %idxprom663 = zext i8 %conv662 to i64
  %arrayidx664 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom663
  %273 = load i64, i64* %arrayidx664, align 8
  %xor665 = xor i64 %271, %273
  %arrayidx666 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %274 = load i64, i64* %arrayidx666, align 16
  %shr667 = lshr i64 %274, 16
  %conv668 = trunc i64 %shr667 to i8
  %idxprom669 = zext i8 %conv668 to i64
  %arrayidx670 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom669
  %275 = load i64, i64* %arrayidx670, align 8
  %xor671 = xor i64 %xor665, %275
  %arrayidx672 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %276 = load i64, i64* %arrayidx672, align 8
  %shr673 = lshr i64 %276, 24
  %conv674 = trunc i64 %shr673 to i8
  %idxprom675 = zext i8 %conv674 to i64
  %arrayidx676 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom675
  %277 = load i64, i64* %arrayidx676, align 8
  %xor677 = xor i64 %xor671, %277
  %xor678 = xor i64 %269, %xor677
  %arrayidx679 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor678, i64* %arrayidx679, align 16
  %278 = load i64*, i64** %kp, align 8
  %add.ptr680 = getelementptr inbounds i64, i64* %278, i64 8
  %arrayidx681 = getelementptr inbounds i64, i64* %add.ptr680, i64 1
  %279 = load i64, i64* %arrayidx681, align 8
  %arrayidx682 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %280 = load i64, i64* %arrayidx682, align 8
  %shr683 = lshr i64 %280, 0
  %conv684 = trunc i64 %shr683 to i8
  %idxprom685 = zext i8 %conv684 to i64
  %arrayidx686 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom685
  %281 = load i64, i64* %arrayidx686, align 8
  %arrayidx687 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %282 = load i64, i64* %arrayidx687, align 16
  %shr688 = lshr i64 %282, 8
  %conv689 = trunc i64 %shr688 to i8
  %idxprom690 = zext i8 %conv689 to i64
  %arrayidx691 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom690
  %283 = load i64, i64* %arrayidx691, align 8
  %xor692 = xor i64 %281, %283
  %arrayidx693 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %284 = load i64, i64* %arrayidx693, align 8
  %shr694 = lshr i64 %284, 16
  %conv695 = trunc i64 %shr694 to i8
  %idxprom696 = zext i8 %conv695 to i64
  %arrayidx697 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom696
  %285 = load i64, i64* %arrayidx697, align 8
  %xor698 = xor i64 %xor692, %285
  %arrayidx699 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %286 = load i64, i64* %arrayidx699, align 16
  %shr700 = lshr i64 %286, 24
  %conv701 = trunc i64 %shr700 to i8
  %idxprom702 = zext i8 %conv701 to i64
  %arrayidx703 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom702
  %287 = load i64, i64* %arrayidx703, align 8
  %xor704 = xor i64 %xor698, %287
  %xor705 = xor i64 %279, %xor704
  %arrayidx706 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor705, i64* %arrayidx706, align 8
  %288 = load i64*, i64** %kp, align 8
  %add.ptr707 = getelementptr inbounds i64, i64* %288, i64 8
  %arrayidx708 = getelementptr inbounds i64, i64* %add.ptr707, i64 2
  %289 = load i64, i64* %arrayidx708, align 8
  %arrayidx709 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %290 = load i64, i64* %arrayidx709, align 16
  %shr710 = lshr i64 %290, 0
  %conv711 = trunc i64 %shr710 to i8
  %idxprom712 = zext i8 %conv711 to i64
  %arrayidx713 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom712
  %291 = load i64, i64* %arrayidx713, align 8
  %arrayidx714 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %292 = load i64, i64* %arrayidx714, align 8
  %shr715 = lshr i64 %292, 8
  %conv716 = trunc i64 %shr715 to i8
  %idxprom717 = zext i8 %conv716 to i64
  %arrayidx718 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom717
  %293 = load i64, i64* %arrayidx718, align 8
  %xor719 = xor i64 %291, %293
  %arrayidx720 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %294 = load i64, i64* %arrayidx720, align 16
  %shr721 = lshr i64 %294, 16
  %conv722 = trunc i64 %shr721 to i8
  %idxprom723 = zext i8 %conv722 to i64
  %arrayidx724 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom723
  %295 = load i64, i64* %arrayidx724, align 8
  %xor725 = xor i64 %xor719, %295
  %arrayidx726 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %296 = load i64, i64* %arrayidx726, align 8
  %shr727 = lshr i64 %296, 24
  %conv728 = trunc i64 %shr727 to i8
  %idxprom729 = zext i8 %conv728 to i64
  %arrayidx730 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom729
  %297 = load i64, i64* %arrayidx730, align 8
  %xor731 = xor i64 %xor725, %297
  %xor732 = xor i64 %289, %xor731
  %arrayidx733 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor732, i64* %arrayidx733, align 16
  %298 = load i64*, i64** %kp, align 8
  %add.ptr734 = getelementptr inbounds i64, i64* %298, i64 8
  %arrayidx735 = getelementptr inbounds i64, i64* %add.ptr734, i64 3
  %299 = load i64, i64* %arrayidx735, align 8
  %arrayidx736 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %300 = load i64, i64* %arrayidx736, align 8
  %shr737 = lshr i64 %300, 0
  %conv738 = trunc i64 %shr737 to i8
  %idxprom739 = zext i8 %conv738 to i64
  %arrayidx740 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom739
  %301 = load i64, i64* %arrayidx740, align 8
  %arrayidx741 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %302 = load i64, i64* %arrayidx741, align 16
  %shr742 = lshr i64 %302, 8
  %conv743 = trunc i64 %shr742 to i8
  %idxprom744 = zext i8 %conv743 to i64
  %arrayidx745 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom744
  %303 = load i64, i64* %arrayidx745, align 8
  %xor746 = xor i64 %301, %303
  %arrayidx747 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %304 = load i64, i64* %arrayidx747, align 8
  %shr748 = lshr i64 %304, 16
  %conv749 = trunc i64 %shr748 to i8
  %idxprom750 = zext i8 %conv749 to i64
  %arrayidx751 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom750
  %305 = load i64, i64* %arrayidx751, align 8
  %xor752 = xor i64 %xor746, %305
  %arrayidx753 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %306 = load i64, i64* %arrayidx753, align 16
  %shr754 = lshr i64 %306, 24
  %conv755 = trunc i64 %shr754 to i8
  %idxprom756 = zext i8 %conv755 to i64
  %arrayidx757 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom756
  %307 = load i64, i64* %arrayidx757, align 8
  %xor758 = xor i64 %xor752, %307
  %xor759 = xor i64 %299, %xor758
  %arrayidx760 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor759, i64* %arrayidx760, align 8
  %308 = load i64*, i64** %kp, align 8
  %add.ptr761 = getelementptr inbounds i64, i64* %308, i64 12
  %arrayidx762 = getelementptr inbounds i64, i64* %add.ptr761, i64 0
  %309 = load i64, i64* %arrayidx762, align 8
  %arrayidx763 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %310 = load i64, i64* %arrayidx763, align 16
  %shr764 = lshr i64 %310, 0
  %conv765 = trunc i64 %shr764 to i8
  %idxprom766 = zext i8 %conv765 to i64
  %arrayidx767 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom766
  %311 = load i64, i64* %arrayidx767, align 8
  %arrayidx768 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %312 = load i64, i64* %arrayidx768, align 8
  %shr769 = lshr i64 %312, 8
  %conv770 = trunc i64 %shr769 to i8
  %idxprom771 = zext i8 %conv770 to i64
  %arrayidx772 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom771
  %313 = load i64, i64* %arrayidx772, align 8
  %xor773 = xor i64 %311, %313
  %arrayidx774 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %314 = load i64, i64* %arrayidx774, align 16
  %shr775 = lshr i64 %314, 16
  %conv776 = trunc i64 %shr775 to i8
  %idxprom777 = zext i8 %conv776 to i64
  %arrayidx778 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom777
  %315 = load i64, i64* %arrayidx778, align 8
  %xor779 = xor i64 %xor773, %315
  %arrayidx780 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %316 = load i64, i64* %arrayidx780, align 8
  %shr781 = lshr i64 %316, 24
  %conv782 = trunc i64 %shr781 to i8
  %idxprom783 = zext i8 %conv782 to i64
  %arrayidx784 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom783
  %317 = load i64, i64* %arrayidx784, align 8
  %xor785 = xor i64 %xor779, %317
  %xor786 = xor i64 %309, %xor785
  %arrayidx787 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor786, i64* %arrayidx787, align 16
  %318 = load i64*, i64** %kp, align 8
  %add.ptr788 = getelementptr inbounds i64, i64* %318, i64 12
  %arrayidx789 = getelementptr inbounds i64, i64* %add.ptr788, i64 1
  %319 = load i64, i64* %arrayidx789, align 8
  %arrayidx790 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %320 = load i64, i64* %arrayidx790, align 8
  %shr791 = lshr i64 %320, 0
  %conv792 = trunc i64 %shr791 to i8
  %idxprom793 = zext i8 %conv792 to i64
  %arrayidx794 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom793
  %321 = load i64, i64* %arrayidx794, align 8
  %arrayidx795 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %322 = load i64, i64* %arrayidx795, align 16
  %shr796 = lshr i64 %322, 8
  %conv797 = trunc i64 %shr796 to i8
  %idxprom798 = zext i8 %conv797 to i64
  %arrayidx799 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom798
  %323 = load i64, i64* %arrayidx799, align 8
  %xor800 = xor i64 %321, %323
  %arrayidx801 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %324 = load i64, i64* %arrayidx801, align 8
  %shr802 = lshr i64 %324, 16
  %conv803 = trunc i64 %shr802 to i8
  %idxprom804 = zext i8 %conv803 to i64
  %arrayidx805 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom804
  %325 = load i64, i64* %arrayidx805, align 8
  %xor806 = xor i64 %xor800, %325
  %arrayidx807 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %326 = load i64, i64* %arrayidx807, align 16
  %shr808 = lshr i64 %326, 24
  %conv809 = trunc i64 %shr808 to i8
  %idxprom810 = zext i8 %conv809 to i64
  %arrayidx811 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom810
  %327 = load i64, i64* %arrayidx811, align 8
  %xor812 = xor i64 %xor806, %327
  %xor813 = xor i64 %319, %xor812
  %arrayidx814 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor813, i64* %arrayidx814, align 8
  %328 = load i64*, i64** %kp, align 8
  %add.ptr815 = getelementptr inbounds i64, i64* %328, i64 12
  %arrayidx816 = getelementptr inbounds i64, i64* %add.ptr815, i64 2
  %329 = load i64, i64* %arrayidx816, align 8
  %arrayidx817 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %330 = load i64, i64* %arrayidx817, align 16
  %shr818 = lshr i64 %330, 0
  %conv819 = trunc i64 %shr818 to i8
  %idxprom820 = zext i8 %conv819 to i64
  %arrayidx821 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom820
  %331 = load i64, i64* %arrayidx821, align 8
  %arrayidx822 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %332 = load i64, i64* %arrayidx822, align 8
  %shr823 = lshr i64 %332, 8
  %conv824 = trunc i64 %shr823 to i8
  %idxprom825 = zext i8 %conv824 to i64
  %arrayidx826 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom825
  %333 = load i64, i64* %arrayidx826, align 8
  %xor827 = xor i64 %331, %333
  %arrayidx828 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %334 = load i64, i64* %arrayidx828, align 16
  %shr829 = lshr i64 %334, 16
  %conv830 = trunc i64 %shr829 to i8
  %idxprom831 = zext i8 %conv830 to i64
  %arrayidx832 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom831
  %335 = load i64, i64* %arrayidx832, align 8
  %xor833 = xor i64 %xor827, %335
  %arrayidx834 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %336 = load i64, i64* %arrayidx834, align 8
  %shr835 = lshr i64 %336, 24
  %conv836 = trunc i64 %shr835 to i8
  %idxprom837 = zext i8 %conv836 to i64
  %arrayidx838 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom837
  %337 = load i64, i64* %arrayidx838, align 8
  %xor839 = xor i64 %xor833, %337
  %xor840 = xor i64 %329, %xor839
  %arrayidx841 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor840, i64* %arrayidx841, align 16
  %338 = load i64*, i64** %kp, align 8
  %add.ptr842 = getelementptr inbounds i64, i64* %338, i64 12
  %arrayidx843 = getelementptr inbounds i64, i64* %add.ptr842, i64 3
  %339 = load i64, i64* %arrayidx843, align 8
  %arrayidx844 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %340 = load i64, i64* %arrayidx844, align 8
  %shr845 = lshr i64 %340, 0
  %conv846 = trunc i64 %shr845 to i8
  %idxprom847 = zext i8 %conv846 to i64
  %arrayidx848 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom847
  %341 = load i64, i64* %arrayidx848, align 8
  %arrayidx849 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %342 = load i64, i64* %arrayidx849, align 16
  %shr850 = lshr i64 %342, 8
  %conv851 = trunc i64 %shr850 to i8
  %idxprom852 = zext i8 %conv851 to i64
  %arrayidx853 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom852
  %343 = load i64, i64* %arrayidx853, align 8
  %xor854 = xor i64 %341, %343
  %arrayidx855 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %344 = load i64, i64* %arrayidx855, align 8
  %shr856 = lshr i64 %344, 16
  %conv857 = trunc i64 %shr856 to i8
  %idxprom858 = zext i8 %conv857 to i64
  %arrayidx859 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom858
  %345 = load i64, i64* %arrayidx859, align 8
  %xor860 = xor i64 %xor854, %345
  %arrayidx861 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %346 = load i64, i64* %arrayidx861, align 16
  %shr862 = lshr i64 %346, 24
  %conv863 = trunc i64 %shr862 to i8
  %idxprom864 = zext i8 %conv863 to i64
  %arrayidx865 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom864
  %347 = load i64, i64* %arrayidx865, align 8
  %xor866 = xor i64 %xor860, %347
  %xor867 = xor i64 %339, %xor866
  %arrayidx868 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor867, i64* %arrayidx868, align 8
  %348 = load i64*, i64** %kp, align 8
  %add.ptr869 = getelementptr inbounds i64, i64* %348, i64 16
  %arrayidx870 = getelementptr inbounds i64, i64* %add.ptr869, i64 0
  %349 = load i64, i64* %arrayidx870, align 8
  %arrayidx871 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %350 = load i64, i64* %arrayidx871, align 16
  %shr872 = lshr i64 %350, 0
  %conv873 = trunc i64 %shr872 to i8
  %idxprom874 = zext i8 %conv873 to i64
  %arrayidx875 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom874
  %351 = load i64, i64* %arrayidx875, align 8
  %arrayidx876 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %352 = load i64, i64* %arrayidx876, align 8
  %shr877 = lshr i64 %352, 8
  %conv878 = trunc i64 %shr877 to i8
  %idxprom879 = zext i8 %conv878 to i64
  %arrayidx880 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom879
  %353 = load i64, i64* %arrayidx880, align 8
  %xor881 = xor i64 %351, %353
  %arrayidx882 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %354 = load i64, i64* %arrayidx882, align 16
  %shr883 = lshr i64 %354, 16
  %conv884 = trunc i64 %shr883 to i8
  %idxprom885 = zext i8 %conv884 to i64
  %arrayidx886 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom885
  %355 = load i64, i64* %arrayidx886, align 8
  %xor887 = xor i64 %xor881, %355
  %arrayidx888 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %356 = load i64, i64* %arrayidx888, align 8
  %shr889 = lshr i64 %356, 24
  %conv890 = trunc i64 %shr889 to i8
  %idxprom891 = zext i8 %conv890 to i64
  %arrayidx892 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom891
  %357 = load i64, i64* %arrayidx892, align 8
  %xor893 = xor i64 %xor887, %357
  %xor894 = xor i64 %349, %xor893
  %arrayidx895 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor894, i64* %arrayidx895, align 16
  %358 = load i64*, i64** %kp, align 8
  %add.ptr896 = getelementptr inbounds i64, i64* %358, i64 16
  %arrayidx897 = getelementptr inbounds i64, i64* %add.ptr896, i64 1
  %359 = load i64, i64* %arrayidx897, align 8
  %arrayidx898 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %360 = load i64, i64* %arrayidx898, align 8
  %shr899 = lshr i64 %360, 0
  %conv900 = trunc i64 %shr899 to i8
  %idxprom901 = zext i8 %conv900 to i64
  %arrayidx902 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom901
  %361 = load i64, i64* %arrayidx902, align 8
  %arrayidx903 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %362 = load i64, i64* %arrayidx903, align 16
  %shr904 = lshr i64 %362, 8
  %conv905 = trunc i64 %shr904 to i8
  %idxprom906 = zext i8 %conv905 to i64
  %arrayidx907 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom906
  %363 = load i64, i64* %arrayidx907, align 8
  %xor908 = xor i64 %361, %363
  %arrayidx909 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %364 = load i64, i64* %arrayidx909, align 8
  %shr910 = lshr i64 %364, 16
  %conv911 = trunc i64 %shr910 to i8
  %idxprom912 = zext i8 %conv911 to i64
  %arrayidx913 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom912
  %365 = load i64, i64* %arrayidx913, align 8
  %xor914 = xor i64 %xor908, %365
  %arrayidx915 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %366 = load i64, i64* %arrayidx915, align 16
  %shr916 = lshr i64 %366, 24
  %conv917 = trunc i64 %shr916 to i8
  %idxprom918 = zext i8 %conv917 to i64
  %arrayidx919 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom918
  %367 = load i64, i64* %arrayidx919, align 8
  %xor920 = xor i64 %xor914, %367
  %xor921 = xor i64 %359, %xor920
  %arrayidx922 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor921, i64* %arrayidx922, align 8
  %368 = load i64*, i64** %kp, align 8
  %add.ptr923 = getelementptr inbounds i64, i64* %368, i64 16
  %arrayidx924 = getelementptr inbounds i64, i64* %add.ptr923, i64 2
  %369 = load i64, i64* %arrayidx924, align 8
  %arrayidx925 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %370 = load i64, i64* %arrayidx925, align 16
  %shr926 = lshr i64 %370, 0
  %conv927 = trunc i64 %shr926 to i8
  %idxprom928 = zext i8 %conv927 to i64
  %arrayidx929 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom928
  %371 = load i64, i64* %arrayidx929, align 8
  %arrayidx930 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %372 = load i64, i64* %arrayidx930, align 8
  %shr931 = lshr i64 %372, 8
  %conv932 = trunc i64 %shr931 to i8
  %idxprom933 = zext i8 %conv932 to i64
  %arrayidx934 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom933
  %373 = load i64, i64* %arrayidx934, align 8
  %xor935 = xor i64 %371, %373
  %arrayidx936 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %374 = load i64, i64* %arrayidx936, align 16
  %shr937 = lshr i64 %374, 16
  %conv938 = trunc i64 %shr937 to i8
  %idxprom939 = zext i8 %conv938 to i64
  %arrayidx940 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom939
  %375 = load i64, i64* %arrayidx940, align 8
  %xor941 = xor i64 %xor935, %375
  %arrayidx942 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %376 = load i64, i64* %arrayidx942, align 8
  %shr943 = lshr i64 %376, 24
  %conv944 = trunc i64 %shr943 to i8
  %idxprom945 = zext i8 %conv944 to i64
  %arrayidx946 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom945
  %377 = load i64, i64* %arrayidx946, align 8
  %xor947 = xor i64 %xor941, %377
  %xor948 = xor i64 %369, %xor947
  %arrayidx949 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor948, i64* %arrayidx949, align 16
  %378 = load i64*, i64** %kp, align 8
  %add.ptr950 = getelementptr inbounds i64, i64* %378, i64 16
  %arrayidx951 = getelementptr inbounds i64, i64* %add.ptr950, i64 3
  %379 = load i64, i64* %arrayidx951, align 8
  %arrayidx952 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %380 = load i64, i64* %arrayidx952, align 8
  %shr953 = lshr i64 %380, 0
  %conv954 = trunc i64 %shr953 to i8
  %idxprom955 = zext i8 %conv954 to i64
  %arrayidx956 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom955
  %381 = load i64, i64* %arrayidx956, align 8
  %arrayidx957 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %382 = load i64, i64* %arrayidx957, align 16
  %shr958 = lshr i64 %382, 8
  %conv959 = trunc i64 %shr958 to i8
  %idxprom960 = zext i8 %conv959 to i64
  %arrayidx961 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom960
  %383 = load i64, i64* %arrayidx961, align 8
  %xor962 = xor i64 %381, %383
  %arrayidx963 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %384 = load i64, i64* %arrayidx963, align 8
  %shr964 = lshr i64 %384, 16
  %conv965 = trunc i64 %shr964 to i8
  %idxprom966 = zext i8 %conv965 to i64
  %arrayidx967 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom966
  %385 = load i64, i64* %arrayidx967, align 8
  %xor968 = xor i64 %xor962, %385
  %arrayidx969 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %386 = load i64, i64* %arrayidx969, align 16
  %shr970 = lshr i64 %386, 24
  %conv971 = trunc i64 %shr970 to i8
  %idxprom972 = zext i8 %conv971 to i64
  %arrayidx973 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom972
  %387 = load i64, i64* %arrayidx973, align 8
  %xor974 = xor i64 %xor968, %387
  %xor975 = xor i64 %379, %xor974
  %arrayidx976 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor975, i64* %arrayidx976, align 8
  %388 = load i64*, i64** %kp, align 8
  %add.ptr977 = getelementptr inbounds i64, i64* %388, i64 20
  %arrayidx978 = getelementptr inbounds i64, i64* %add.ptr977, i64 0
  %389 = load i64, i64* %arrayidx978, align 8
  %arrayidx979 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %390 = load i64, i64* %arrayidx979, align 16
  %shr980 = lshr i64 %390, 0
  %conv981 = trunc i64 %shr980 to i8
  %idxprom982 = zext i8 %conv981 to i64
  %arrayidx983 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom982
  %391 = load i64, i64* %arrayidx983, align 8
  %arrayidx984 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %392 = load i64, i64* %arrayidx984, align 8
  %shr985 = lshr i64 %392, 8
  %conv986 = trunc i64 %shr985 to i8
  %idxprom987 = zext i8 %conv986 to i64
  %arrayidx988 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom987
  %393 = load i64, i64* %arrayidx988, align 8
  %xor989 = xor i64 %391, %393
  %arrayidx990 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %394 = load i64, i64* %arrayidx990, align 16
  %shr991 = lshr i64 %394, 16
  %conv992 = trunc i64 %shr991 to i8
  %idxprom993 = zext i8 %conv992 to i64
  %arrayidx994 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom993
  %395 = load i64, i64* %arrayidx994, align 8
  %xor995 = xor i64 %xor989, %395
  %arrayidx996 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %396 = load i64, i64* %arrayidx996, align 8
  %shr997 = lshr i64 %396, 24
  %conv998 = trunc i64 %shr997 to i8
  %idxprom999 = zext i8 %conv998 to i64
  %arrayidx1000 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom999
  %397 = load i64, i64* %arrayidx1000, align 8
  %xor1001 = xor i64 %xor995, %397
  %xor1002 = xor i64 %389, %xor1001
  %arrayidx1003 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor1002, i64* %arrayidx1003, align 16
  %398 = load i64*, i64** %kp, align 8
  %add.ptr1004 = getelementptr inbounds i64, i64* %398, i64 20
  %arrayidx1005 = getelementptr inbounds i64, i64* %add.ptr1004, i64 1
  %399 = load i64, i64* %arrayidx1005, align 8
  %arrayidx1006 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %400 = load i64, i64* %arrayidx1006, align 8
  %shr1007 = lshr i64 %400, 0
  %conv1008 = trunc i64 %shr1007 to i8
  %idxprom1009 = zext i8 %conv1008 to i64
  %arrayidx1010 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1009
  %401 = load i64, i64* %arrayidx1010, align 8
  %arrayidx1011 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %402 = load i64, i64* %arrayidx1011, align 16
  %shr1012 = lshr i64 %402, 8
  %conv1013 = trunc i64 %shr1012 to i8
  %idxprom1014 = zext i8 %conv1013 to i64
  %arrayidx1015 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1014
  %403 = load i64, i64* %arrayidx1015, align 8
  %xor1016 = xor i64 %401, %403
  %arrayidx1017 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %404 = load i64, i64* %arrayidx1017, align 8
  %shr1018 = lshr i64 %404, 16
  %conv1019 = trunc i64 %shr1018 to i8
  %idxprom1020 = zext i8 %conv1019 to i64
  %arrayidx1021 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1020
  %405 = load i64, i64* %arrayidx1021, align 8
  %xor1022 = xor i64 %xor1016, %405
  %arrayidx1023 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %406 = load i64, i64* %arrayidx1023, align 16
  %shr1024 = lshr i64 %406, 24
  %conv1025 = trunc i64 %shr1024 to i8
  %idxprom1026 = zext i8 %conv1025 to i64
  %arrayidx1027 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1026
  %407 = load i64, i64* %arrayidx1027, align 8
  %xor1028 = xor i64 %xor1022, %407
  %xor1029 = xor i64 %399, %xor1028
  %arrayidx1030 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor1029, i64* %arrayidx1030, align 8
  %408 = load i64*, i64** %kp, align 8
  %add.ptr1031 = getelementptr inbounds i64, i64* %408, i64 20
  %arrayidx1032 = getelementptr inbounds i64, i64* %add.ptr1031, i64 2
  %409 = load i64, i64* %arrayidx1032, align 8
  %arrayidx1033 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %410 = load i64, i64* %arrayidx1033, align 16
  %shr1034 = lshr i64 %410, 0
  %conv1035 = trunc i64 %shr1034 to i8
  %idxprom1036 = zext i8 %conv1035 to i64
  %arrayidx1037 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1036
  %411 = load i64, i64* %arrayidx1037, align 8
  %arrayidx1038 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %412 = load i64, i64* %arrayidx1038, align 8
  %shr1039 = lshr i64 %412, 8
  %conv1040 = trunc i64 %shr1039 to i8
  %idxprom1041 = zext i8 %conv1040 to i64
  %arrayidx1042 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1041
  %413 = load i64, i64* %arrayidx1042, align 8
  %xor1043 = xor i64 %411, %413
  %arrayidx1044 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %414 = load i64, i64* %arrayidx1044, align 16
  %shr1045 = lshr i64 %414, 16
  %conv1046 = trunc i64 %shr1045 to i8
  %idxprom1047 = zext i8 %conv1046 to i64
  %arrayidx1048 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1047
  %415 = load i64, i64* %arrayidx1048, align 8
  %xor1049 = xor i64 %xor1043, %415
  %arrayidx1050 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %416 = load i64, i64* %arrayidx1050, align 8
  %shr1051 = lshr i64 %416, 24
  %conv1052 = trunc i64 %shr1051 to i8
  %idxprom1053 = zext i8 %conv1052 to i64
  %arrayidx1054 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1053
  %417 = load i64, i64* %arrayidx1054, align 8
  %xor1055 = xor i64 %xor1049, %417
  %xor1056 = xor i64 %409, %xor1055
  %arrayidx1057 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor1056, i64* %arrayidx1057, align 16
  %418 = load i64*, i64** %kp, align 8
  %add.ptr1058 = getelementptr inbounds i64, i64* %418, i64 20
  %arrayidx1059 = getelementptr inbounds i64, i64* %add.ptr1058, i64 3
  %419 = load i64, i64* %arrayidx1059, align 8
  %arrayidx1060 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %420 = load i64, i64* %arrayidx1060, align 8
  %shr1061 = lshr i64 %420, 0
  %conv1062 = trunc i64 %shr1061 to i8
  %idxprom1063 = zext i8 %conv1062 to i64
  %arrayidx1064 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1063
  %421 = load i64, i64* %arrayidx1064, align 8
  %arrayidx1065 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %422 = load i64, i64* %arrayidx1065, align 16
  %shr1066 = lshr i64 %422, 8
  %conv1067 = trunc i64 %shr1066 to i8
  %idxprom1068 = zext i8 %conv1067 to i64
  %arrayidx1069 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1068
  %423 = load i64, i64* %arrayidx1069, align 8
  %xor1070 = xor i64 %421, %423
  %arrayidx1071 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %424 = load i64, i64* %arrayidx1071, align 8
  %shr1072 = lshr i64 %424, 16
  %conv1073 = trunc i64 %shr1072 to i8
  %idxprom1074 = zext i8 %conv1073 to i64
  %arrayidx1075 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1074
  %425 = load i64, i64* %arrayidx1075, align 8
  %xor1076 = xor i64 %xor1070, %425
  %arrayidx1077 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %426 = load i64, i64* %arrayidx1077, align 16
  %shr1078 = lshr i64 %426, 24
  %conv1079 = trunc i64 %shr1078 to i8
  %idxprom1080 = zext i8 %conv1079 to i64
  %arrayidx1081 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1080
  %427 = load i64, i64* %arrayidx1081, align 8
  %xor1082 = xor i64 %xor1076, %427
  %xor1083 = xor i64 %419, %xor1082
  %arrayidx1084 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor1083, i64* %arrayidx1084, align 8
  %428 = load i64*, i64** %kp, align 8
  %add.ptr1085 = getelementptr inbounds i64, i64* %428, i64 24
  %arrayidx1086 = getelementptr inbounds i64, i64* %add.ptr1085, i64 0
  %429 = load i64, i64* %arrayidx1086, align 8
  %arrayidx1087 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %430 = load i64, i64* %arrayidx1087, align 16
  %shr1088 = lshr i64 %430, 0
  %conv1089 = trunc i64 %shr1088 to i8
  %idxprom1090 = zext i8 %conv1089 to i64
  %arrayidx1091 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1090
  %431 = load i64, i64* %arrayidx1091, align 8
  %arrayidx1092 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %432 = load i64, i64* %arrayidx1092, align 8
  %shr1093 = lshr i64 %432, 8
  %conv1094 = trunc i64 %shr1093 to i8
  %idxprom1095 = zext i8 %conv1094 to i64
  %arrayidx1096 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1095
  %433 = load i64, i64* %arrayidx1096, align 8
  %xor1097 = xor i64 %431, %433
  %arrayidx1098 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %434 = load i64, i64* %arrayidx1098, align 16
  %shr1099 = lshr i64 %434, 16
  %conv1100 = trunc i64 %shr1099 to i8
  %idxprom1101 = zext i8 %conv1100 to i64
  %arrayidx1102 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1101
  %435 = load i64, i64* %arrayidx1102, align 8
  %xor1103 = xor i64 %xor1097, %435
  %arrayidx1104 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %436 = load i64, i64* %arrayidx1104, align 8
  %shr1105 = lshr i64 %436, 24
  %conv1106 = trunc i64 %shr1105 to i8
  %idxprom1107 = zext i8 %conv1106 to i64
  %arrayidx1108 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1107
  %437 = load i64, i64* %arrayidx1108, align 8
  %xor1109 = xor i64 %xor1103, %437
  %xor1110 = xor i64 %429, %xor1109
  %arrayidx1111 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor1110, i64* %arrayidx1111, align 16
  %438 = load i64*, i64** %kp, align 8
  %add.ptr1112 = getelementptr inbounds i64, i64* %438, i64 24
  %arrayidx1113 = getelementptr inbounds i64, i64* %add.ptr1112, i64 1
  %439 = load i64, i64* %arrayidx1113, align 8
  %arrayidx1114 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %440 = load i64, i64* %arrayidx1114, align 8
  %shr1115 = lshr i64 %440, 0
  %conv1116 = trunc i64 %shr1115 to i8
  %idxprom1117 = zext i8 %conv1116 to i64
  %arrayidx1118 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1117
  %441 = load i64, i64* %arrayidx1118, align 8
  %arrayidx1119 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %442 = load i64, i64* %arrayidx1119, align 16
  %shr1120 = lshr i64 %442, 8
  %conv1121 = trunc i64 %shr1120 to i8
  %idxprom1122 = zext i8 %conv1121 to i64
  %arrayidx1123 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1122
  %443 = load i64, i64* %arrayidx1123, align 8
  %xor1124 = xor i64 %441, %443
  %arrayidx1125 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %444 = load i64, i64* %arrayidx1125, align 8
  %shr1126 = lshr i64 %444, 16
  %conv1127 = trunc i64 %shr1126 to i8
  %idxprom1128 = zext i8 %conv1127 to i64
  %arrayidx1129 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1128
  %445 = load i64, i64* %arrayidx1129, align 8
  %xor1130 = xor i64 %xor1124, %445
  %arrayidx1131 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %446 = load i64, i64* %arrayidx1131, align 16
  %shr1132 = lshr i64 %446, 24
  %conv1133 = trunc i64 %shr1132 to i8
  %idxprom1134 = zext i8 %conv1133 to i64
  %arrayidx1135 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1134
  %447 = load i64, i64* %arrayidx1135, align 8
  %xor1136 = xor i64 %xor1130, %447
  %xor1137 = xor i64 %439, %xor1136
  %arrayidx1138 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor1137, i64* %arrayidx1138, align 8
  %448 = load i64*, i64** %kp, align 8
  %add.ptr1139 = getelementptr inbounds i64, i64* %448, i64 24
  %arrayidx1140 = getelementptr inbounds i64, i64* %add.ptr1139, i64 2
  %449 = load i64, i64* %arrayidx1140, align 8
  %arrayidx1141 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %450 = load i64, i64* %arrayidx1141, align 16
  %shr1142 = lshr i64 %450, 0
  %conv1143 = trunc i64 %shr1142 to i8
  %idxprom1144 = zext i8 %conv1143 to i64
  %arrayidx1145 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1144
  %451 = load i64, i64* %arrayidx1145, align 8
  %arrayidx1146 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %452 = load i64, i64* %arrayidx1146, align 8
  %shr1147 = lshr i64 %452, 8
  %conv1148 = trunc i64 %shr1147 to i8
  %idxprom1149 = zext i8 %conv1148 to i64
  %arrayidx1150 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1149
  %453 = load i64, i64* %arrayidx1150, align 8
  %xor1151 = xor i64 %451, %453
  %arrayidx1152 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %454 = load i64, i64* %arrayidx1152, align 16
  %shr1153 = lshr i64 %454, 16
  %conv1154 = trunc i64 %shr1153 to i8
  %idxprom1155 = zext i8 %conv1154 to i64
  %arrayidx1156 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1155
  %455 = load i64, i64* %arrayidx1156, align 8
  %xor1157 = xor i64 %xor1151, %455
  %arrayidx1158 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %456 = load i64, i64* %arrayidx1158, align 8
  %shr1159 = lshr i64 %456, 24
  %conv1160 = trunc i64 %shr1159 to i8
  %idxprom1161 = zext i8 %conv1160 to i64
  %arrayidx1162 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1161
  %457 = load i64, i64* %arrayidx1162, align 8
  %xor1163 = xor i64 %xor1157, %457
  %xor1164 = xor i64 %449, %xor1163
  %arrayidx1165 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor1164, i64* %arrayidx1165, align 16
  %458 = load i64*, i64** %kp, align 8
  %add.ptr1166 = getelementptr inbounds i64, i64* %458, i64 24
  %arrayidx1167 = getelementptr inbounds i64, i64* %add.ptr1166, i64 3
  %459 = load i64, i64* %arrayidx1167, align 8
  %arrayidx1168 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %460 = load i64, i64* %arrayidx1168, align 8
  %shr1169 = lshr i64 %460, 0
  %conv1170 = trunc i64 %shr1169 to i8
  %idxprom1171 = zext i8 %conv1170 to i64
  %arrayidx1172 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1171
  %461 = load i64, i64* %arrayidx1172, align 8
  %arrayidx1173 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %462 = load i64, i64* %arrayidx1173, align 16
  %shr1174 = lshr i64 %462, 8
  %conv1175 = trunc i64 %shr1174 to i8
  %idxprom1176 = zext i8 %conv1175 to i64
  %arrayidx1177 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1176
  %463 = load i64, i64* %arrayidx1177, align 8
  %xor1178 = xor i64 %461, %463
  %arrayidx1179 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %464 = load i64, i64* %arrayidx1179, align 8
  %shr1180 = lshr i64 %464, 16
  %conv1181 = trunc i64 %shr1180 to i8
  %idxprom1182 = zext i8 %conv1181 to i64
  %arrayidx1183 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1182
  %465 = load i64, i64* %arrayidx1183, align 8
  %xor1184 = xor i64 %xor1178, %465
  %arrayidx1185 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %466 = load i64, i64* %arrayidx1185, align 16
  %shr1186 = lshr i64 %466, 24
  %conv1187 = trunc i64 %shr1186 to i8
  %idxprom1188 = zext i8 %conv1187 to i64
  %arrayidx1189 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1188
  %467 = load i64, i64* %arrayidx1189, align 8
  %xor1190 = xor i64 %xor1184, %467
  %xor1191 = xor i64 %459, %xor1190
  %arrayidx1192 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor1191, i64* %arrayidx1192, align 8
  %468 = load i64*, i64** %kp, align 8
  %add.ptr1193 = getelementptr inbounds i64, i64* %468, i64 28
  %arrayidx1194 = getelementptr inbounds i64, i64* %add.ptr1193, i64 0
  %469 = load i64, i64* %arrayidx1194, align 8
  %arrayidx1195 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %470 = load i64, i64* %arrayidx1195, align 16
  %shr1196 = lshr i64 %470, 0
  %conv1197 = trunc i64 %shr1196 to i8
  %idxprom1198 = zext i8 %conv1197 to i64
  %arrayidx1199 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1198
  %471 = load i64, i64* %arrayidx1199, align 8
  %arrayidx1200 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %472 = load i64, i64* %arrayidx1200, align 8
  %shr1201 = lshr i64 %472, 8
  %conv1202 = trunc i64 %shr1201 to i8
  %idxprom1203 = zext i8 %conv1202 to i64
  %arrayidx1204 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1203
  %473 = load i64, i64* %arrayidx1204, align 8
  %xor1205 = xor i64 %471, %473
  %arrayidx1206 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %474 = load i64, i64* %arrayidx1206, align 16
  %shr1207 = lshr i64 %474, 16
  %conv1208 = trunc i64 %shr1207 to i8
  %idxprom1209 = zext i8 %conv1208 to i64
  %arrayidx1210 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1209
  %475 = load i64, i64* %arrayidx1210, align 8
  %xor1211 = xor i64 %xor1205, %475
  %arrayidx1212 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %476 = load i64, i64* %arrayidx1212, align 8
  %shr1213 = lshr i64 %476, 24
  %conv1214 = trunc i64 %shr1213 to i8
  %idxprom1215 = zext i8 %conv1214 to i64
  %arrayidx1216 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1215
  %477 = load i64, i64* %arrayidx1216, align 8
  %xor1217 = xor i64 %xor1211, %477
  %xor1218 = xor i64 %469, %xor1217
  %arrayidx1219 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor1218, i64* %arrayidx1219, align 16
  %478 = load i64*, i64** %kp, align 8
  %add.ptr1220 = getelementptr inbounds i64, i64* %478, i64 28
  %arrayidx1221 = getelementptr inbounds i64, i64* %add.ptr1220, i64 1
  %479 = load i64, i64* %arrayidx1221, align 8
  %arrayidx1222 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %480 = load i64, i64* %arrayidx1222, align 8
  %shr1223 = lshr i64 %480, 0
  %conv1224 = trunc i64 %shr1223 to i8
  %idxprom1225 = zext i8 %conv1224 to i64
  %arrayidx1226 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1225
  %481 = load i64, i64* %arrayidx1226, align 8
  %arrayidx1227 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %482 = load i64, i64* %arrayidx1227, align 16
  %shr1228 = lshr i64 %482, 8
  %conv1229 = trunc i64 %shr1228 to i8
  %idxprom1230 = zext i8 %conv1229 to i64
  %arrayidx1231 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1230
  %483 = load i64, i64* %arrayidx1231, align 8
  %xor1232 = xor i64 %481, %483
  %arrayidx1233 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %484 = load i64, i64* %arrayidx1233, align 8
  %shr1234 = lshr i64 %484, 16
  %conv1235 = trunc i64 %shr1234 to i8
  %idxprom1236 = zext i8 %conv1235 to i64
  %arrayidx1237 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1236
  %485 = load i64, i64* %arrayidx1237, align 8
  %xor1238 = xor i64 %xor1232, %485
  %arrayidx1239 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %486 = load i64, i64* %arrayidx1239, align 16
  %shr1240 = lshr i64 %486, 24
  %conv1241 = trunc i64 %shr1240 to i8
  %idxprom1242 = zext i8 %conv1241 to i64
  %arrayidx1243 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1242
  %487 = load i64, i64* %arrayidx1243, align 8
  %xor1244 = xor i64 %xor1238, %487
  %xor1245 = xor i64 %479, %xor1244
  %arrayidx1246 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor1245, i64* %arrayidx1246, align 8
  %488 = load i64*, i64** %kp, align 8
  %add.ptr1247 = getelementptr inbounds i64, i64* %488, i64 28
  %arrayidx1248 = getelementptr inbounds i64, i64* %add.ptr1247, i64 2
  %489 = load i64, i64* %arrayidx1248, align 8
  %arrayidx1249 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %490 = load i64, i64* %arrayidx1249, align 16
  %shr1250 = lshr i64 %490, 0
  %conv1251 = trunc i64 %shr1250 to i8
  %idxprom1252 = zext i8 %conv1251 to i64
  %arrayidx1253 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1252
  %491 = load i64, i64* %arrayidx1253, align 8
  %arrayidx1254 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %492 = load i64, i64* %arrayidx1254, align 8
  %shr1255 = lshr i64 %492, 8
  %conv1256 = trunc i64 %shr1255 to i8
  %idxprom1257 = zext i8 %conv1256 to i64
  %arrayidx1258 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1257
  %493 = load i64, i64* %arrayidx1258, align 8
  %xor1259 = xor i64 %491, %493
  %arrayidx1260 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %494 = load i64, i64* %arrayidx1260, align 16
  %shr1261 = lshr i64 %494, 16
  %conv1262 = trunc i64 %shr1261 to i8
  %idxprom1263 = zext i8 %conv1262 to i64
  %arrayidx1264 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1263
  %495 = load i64, i64* %arrayidx1264, align 8
  %xor1265 = xor i64 %xor1259, %495
  %arrayidx1266 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %496 = load i64, i64* %arrayidx1266, align 8
  %shr1267 = lshr i64 %496, 24
  %conv1268 = trunc i64 %shr1267 to i8
  %idxprom1269 = zext i8 %conv1268 to i64
  %arrayidx1270 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1269
  %497 = load i64, i64* %arrayidx1270, align 8
  %xor1271 = xor i64 %xor1265, %497
  %xor1272 = xor i64 %489, %xor1271
  %arrayidx1273 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor1272, i64* %arrayidx1273, align 16
  %498 = load i64*, i64** %kp, align 8
  %add.ptr1274 = getelementptr inbounds i64, i64* %498, i64 28
  %arrayidx1275 = getelementptr inbounds i64, i64* %add.ptr1274, i64 3
  %499 = load i64, i64* %arrayidx1275, align 8
  %arrayidx1276 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %500 = load i64, i64* %arrayidx1276, align 8
  %shr1277 = lshr i64 %500, 0
  %conv1278 = trunc i64 %shr1277 to i8
  %idxprom1279 = zext i8 %conv1278 to i64
  %arrayidx1280 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1279
  %501 = load i64, i64* %arrayidx1280, align 8
  %arrayidx1281 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %502 = load i64, i64* %arrayidx1281, align 16
  %shr1282 = lshr i64 %502, 8
  %conv1283 = trunc i64 %shr1282 to i8
  %idxprom1284 = zext i8 %conv1283 to i64
  %arrayidx1285 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1284
  %503 = load i64, i64* %arrayidx1285, align 8
  %xor1286 = xor i64 %501, %503
  %arrayidx1287 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %504 = load i64, i64* %arrayidx1287, align 8
  %shr1288 = lshr i64 %504, 16
  %conv1289 = trunc i64 %shr1288 to i8
  %idxprom1290 = zext i8 %conv1289 to i64
  %arrayidx1291 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1290
  %505 = load i64, i64* %arrayidx1291, align 8
  %xor1292 = xor i64 %xor1286, %505
  %arrayidx1293 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %506 = load i64, i64* %arrayidx1293, align 16
  %shr1294 = lshr i64 %506, 24
  %conv1295 = trunc i64 %shr1294 to i8
  %idxprom1296 = zext i8 %conv1295 to i64
  %arrayidx1297 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1296
  %507 = load i64, i64* %arrayidx1297, align 8
  %xor1298 = xor i64 %xor1292, %507
  %xor1299 = xor i64 %499, %xor1298
  %arrayidx1300 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor1299, i64* %arrayidx1300, align 8
  %508 = load i64*, i64** %kp, align 8
  %add.ptr1301 = getelementptr inbounds i64, i64* %508, i64 32
  %arrayidx1302 = getelementptr inbounds i64, i64* %add.ptr1301, i64 0
  %509 = load i64, i64* %arrayidx1302, align 8
  %arrayidx1303 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %510 = load i64, i64* %arrayidx1303, align 16
  %shr1304 = lshr i64 %510, 0
  %conv1305 = trunc i64 %shr1304 to i8
  %idxprom1306 = zext i8 %conv1305 to i64
  %arrayidx1307 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1306
  %511 = load i64, i64* %arrayidx1307, align 8
  %arrayidx1308 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %512 = load i64, i64* %arrayidx1308, align 8
  %shr1309 = lshr i64 %512, 8
  %conv1310 = trunc i64 %shr1309 to i8
  %idxprom1311 = zext i8 %conv1310 to i64
  %arrayidx1312 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1311
  %513 = load i64, i64* %arrayidx1312, align 8
  %xor1313 = xor i64 %511, %513
  %arrayidx1314 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %514 = load i64, i64* %arrayidx1314, align 16
  %shr1315 = lshr i64 %514, 16
  %conv1316 = trunc i64 %shr1315 to i8
  %idxprom1317 = zext i8 %conv1316 to i64
  %arrayidx1318 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1317
  %515 = load i64, i64* %arrayidx1318, align 8
  %xor1319 = xor i64 %xor1313, %515
  %arrayidx1320 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %516 = load i64, i64* %arrayidx1320, align 8
  %shr1321 = lshr i64 %516, 24
  %conv1322 = trunc i64 %shr1321 to i8
  %idxprom1323 = zext i8 %conv1322 to i64
  %arrayidx1324 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1323
  %517 = load i64, i64* %arrayidx1324, align 8
  %xor1325 = xor i64 %xor1319, %517
  %xor1326 = xor i64 %509, %xor1325
  %arrayidx1327 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  store i64 %xor1326, i64* %arrayidx1327, align 16
  %518 = load i64*, i64** %kp, align 8
  %add.ptr1328 = getelementptr inbounds i64, i64* %518, i64 32
  %arrayidx1329 = getelementptr inbounds i64, i64* %add.ptr1328, i64 1
  %519 = load i64, i64* %arrayidx1329, align 8
  %arrayidx1330 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %520 = load i64, i64* %arrayidx1330, align 8
  %shr1331 = lshr i64 %520, 0
  %conv1332 = trunc i64 %shr1331 to i8
  %idxprom1333 = zext i8 %conv1332 to i64
  %arrayidx1334 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1333
  %521 = load i64, i64* %arrayidx1334, align 8
  %arrayidx1335 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %522 = load i64, i64* %arrayidx1335, align 16
  %shr1336 = lshr i64 %522, 8
  %conv1337 = trunc i64 %shr1336 to i8
  %idxprom1338 = zext i8 %conv1337 to i64
  %arrayidx1339 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1338
  %523 = load i64, i64* %arrayidx1339, align 8
  %xor1340 = xor i64 %521, %523
  %arrayidx1341 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %524 = load i64, i64* %arrayidx1341, align 8
  %shr1342 = lshr i64 %524, 16
  %conv1343 = trunc i64 %shr1342 to i8
  %idxprom1344 = zext i8 %conv1343 to i64
  %arrayidx1345 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1344
  %525 = load i64, i64* %arrayidx1345, align 8
  %xor1346 = xor i64 %xor1340, %525
  %arrayidx1347 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %526 = load i64, i64* %arrayidx1347, align 16
  %shr1348 = lshr i64 %526, 24
  %conv1349 = trunc i64 %shr1348 to i8
  %idxprom1350 = zext i8 %conv1349 to i64
  %arrayidx1351 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1350
  %527 = load i64, i64* %arrayidx1351, align 8
  %xor1352 = xor i64 %xor1346, %527
  %xor1353 = xor i64 %519, %xor1352
  %arrayidx1354 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  store i64 %xor1353, i64* %arrayidx1354, align 8
  %528 = load i64*, i64** %kp, align 8
  %add.ptr1355 = getelementptr inbounds i64, i64* %528, i64 32
  %arrayidx1356 = getelementptr inbounds i64, i64* %add.ptr1355, i64 2
  %529 = load i64, i64* %arrayidx1356, align 8
  %arrayidx1357 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %530 = load i64, i64* %arrayidx1357, align 16
  %shr1358 = lshr i64 %530, 0
  %conv1359 = trunc i64 %shr1358 to i8
  %idxprom1360 = zext i8 %conv1359 to i64
  %arrayidx1361 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1360
  %531 = load i64, i64* %arrayidx1361, align 8
  %arrayidx1362 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %532 = load i64, i64* %arrayidx1362, align 8
  %shr1363 = lshr i64 %532, 8
  %conv1364 = trunc i64 %shr1363 to i8
  %idxprom1365 = zext i8 %conv1364 to i64
  %arrayidx1366 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1365
  %533 = load i64, i64* %arrayidx1366, align 8
  %xor1367 = xor i64 %531, %533
  %arrayidx1368 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %534 = load i64, i64* %arrayidx1368, align 16
  %shr1369 = lshr i64 %534, 16
  %conv1370 = trunc i64 %shr1369 to i8
  %idxprom1371 = zext i8 %conv1370 to i64
  %arrayidx1372 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1371
  %535 = load i64, i64* %arrayidx1372, align 8
  %xor1373 = xor i64 %xor1367, %535
  %arrayidx1374 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %536 = load i64, i64* %arrayidx1374, align 8
  %shr1375 = lshr i64 %536, 24
  %conv1376 = trunc i64 %shr1375 to i8
  %idxprom1377 = zext i8 %conv1376 to i64
  %arrayidx1378 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1377
  %537 = load i64, i64* %arrayidx1378, align 8
  %xor1379 = xor i64 %xor1373, %537
  %xor1380 = xor i64 %529, %xor1379
  %arrayidx1381 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  store i64 %xor1380, i64* %arrayidx1381, align 16
  %538 = load i64*, i64** %kp, align 8
  %add.ptr1382 = getelementptr inbounds i64, i64* %538, i64 32
  %arrayidx1383 = getelementptr inbounds i64, i64* %add.ptr1382, i64 3
  %539 = load i64, i64* %arrayidx1383, align 8
  %arrayidx1384 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %540 = load i64, i64* %arrayidx1384, align 8
  %shr1385 = lshr i64 %540, 0
  %conv1386 = trunc i64 %shr1385 to i8
  %idxprom1387 = zext i8 %conv1386 to i64
  %arrayidx1388 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 0), i64 0, i64 %idxprom1387
  %541 = load i64, i64* %arrayidx1388, align 8
  %arrayidx1389 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %542 = load i64, i64* %arrayidx1389, align 16
  %shr1390 = lshr i64 %542, 8
  %conv1391 = trunc i64 %shr1390 to i8
  %idxprom1392 = zext i8 %conv1391 to i64
  %arrayidx1393 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 1), i64 0, i64 %idxprom1392
  %543 = load i64, i64* %arrayidx1393, align 8
  %xor1394 = xor i64 %541, %543
  %arrayidx1395 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %544 = load i64, i64* %arrayidx1395, align 8
  %shr1396 = lshr i64 %544, 16
  %conv1397 = trunc i64 %shr1396 to i8
  %idxprom1398 = zext i8 %conv1397 to i64
  %arrayidx1399 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 2), i64 0, i64 %idxprom1398
  %545 = load i64, i64* %arrayidx1399, align 8
  %xor1400 = xor i64 %xor1394, %545
  %arrayidx1401 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %546 = load i64, i64* %arrayidx1401, align 16
  %shr1402 = lshr i64 %546, 24
  %conv1403 = trunc i64 %shr1402 to i8
  %idxprom1404 = zext i8 %conv1403 to i64
  %arrayidx1405 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @it_tab, i64 0, i64 3), i64 0, i64 %idxprom1404
  %547 = load i64, i64* %arrayidx1405, align 8
  %xor1406 = xor i64 %xor1400, %547
  %xor1407 = xor i64 %539, %xor1406
  %arrayidx1408 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  store i64 %xor1407, i64* %arrayidx1408, align 8
  %548 = load i64*, i64** %kp, align 8
  %add.ptr1409 = getelementptr inbounds i64, i64* %548, i64 36
  %arrayidx1410 = getelementptr inbounds i64, i64* %add.ptr1409, i64 0
  %549 = load i64, i64* %arrayidx1410, align 8
  %arrayidx1411 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %550 = load i64, i64* %arrayidx1411, align 16
  %shr1412 = lshr i64 %550, 0
  %conv1413 = trunc i64 %shr1412 to i8
  %idxprom1414 = zext i8 %conv1413 to i64
  %arrayidx1415 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 0), i64 0, i64 %idxprom1414
  %551 = load i64, i64* %arrayidx1415, align 8
  %arrayidx1416 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %552 = load i64, i64* %arrayidx1416, align 8
  %shr1417 = lshr i64 %552, 8
  %conv1418 = trunc i64 %shr1417 to i8
  %idxprom1419 = zext i8 %conv1418 to i64
  %arrayidx1420 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 1), i64 0, i64 %idxprom1419
  %553 = load i64, i64* %arrayidx1420, align 8
  %xor1421 = xor i64 %551, %553
  %arrayidx1422 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %554 = load i64, i64* %arrayidx1422, align 16
  %shr1423 = lshr i64 %554, 16
  %conv1424 = trunc i64 %shr1423 to i8
  %idxprom1425 = zext i8 %conv1424 to i64
  %arrayidx1426 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 2), i64 0, i64 %idxprom1425
  %555 = load i64, i64* %arrayidx1426, align 8
  %xor1427 = xor i64 %xor1421, %555
  %arrayidx1428 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %556 = load i64, i64* %arrayidx1428, align 8
  %shr1429 = lshr i64 %556, 24
  %conv1430 = trunc i64 %shr1429 to i8
  %idxprom1431 = zext i8 %conv1430 to i64
  %arrayidx1432 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 3), i64 0, i64 %idxprom1431
  %557 = load i64, i64* %arrayidx1432, align 8
  %xor1433 = xor i64 %xor1427, %557
  %xor1434 = xor i64 %549, %xor1433
  %arrayidx1435 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  store i64 %xor1434, i64* %arrayidx1435, align 16
  %558 = load i64*, i64** %kp, align 8
  %add.ptr1436 = getelementptr inbounds i64, i64* %558, i64 36
  %arrayidx1437 = getelementptr inbounds i64, i64* %add.ptr1436, i64 1
  %559 = load i64, i64* %arrayidx1437, align 8
  %arrayidx1438 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %560 = load i64, i64* %arrayidx1438, align 8
  %shr1439 = lshr i64 %560, 0
  %conv1440 = trunc i64 %shr1439 to i8
  %idxprom1441 = zext i8 %conv1440 to i64
  %arrayidx1442 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 0), i64 0, i64 %idxprom1441
  %561 = load i64, i64* %arrayidx1442, align 8
  %arrayidx1443 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %562 = load i64, i64* %arrayidx1443, align 16
  %shr1444 = lshr i64 %562, 8
  %conv1445 = trunc i64 %shr1444 to i8
  %idxprom1446 = zext i8 %conv1445 to i64
  %arrayidx1447 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 1), i64 0, i64 %idxprom1446
  %563 = load i64, i64* %arrayidx1447, align 8
  %xor1448 = xor i64 %561, %563
  %arrayidx1449 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %564 = load i64, i64* %arrayidx1449, align 8
  %shr1450 = lshr i64 %564, 16
  %conv1451 = trunc i64 %shr1450 to i8
  %idxprom1452 = zext i8 %conv1451 to i64
  %arrayidx1453 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 2), i64 0, i64 %idxprom1452
  %565 = load i64, i64* %arrayidx1453, align 8
  %xor1454 = xor i64 %xor1448, %565
  %arrayidx1455 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %566 = load i64, i64* %arrayidx1455, align 16
  %shr1456 = lshr i64 %566, 24
  %conv1457 = trunc i64 %shr1456 to i8
  %idxprom1458 = zext i8 %conv1457 to i64
  %arrayidx1459 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 3), i64 0, i64 %idxprom1458
  %567 = load i64, i64* %arrayidx1459, align 8
  %xor1460 = xor i64 %xor1454, %567
  %xor1461 = xor i64 %559, %xor1460
  %arrayidx1462 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  store i64 %xor1461, i64* %arrayidx1462, align 8
  %568 = load i64*, i64** %kp, align 8
  %add.ptr1463 = getelementptr inbounds i64, i64* %568, i64 36
  %arrayidx1464 = getelementptr inbounds i64, i64* %add.ptr1463, i64 2
  %569 = load i64, i64* %arrayidx1464, align 8
  %arrayidx1465 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %570 = load i64, i64* %arrayidx1465, align 16
  %shr1466 = lshr i64 %570, 0
  %conv1467 = trunc i64 %shr1466 to i8
  %idxprom1468 = zext i8 %conv1467 to i64
  %arrayidx1469 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 0), i64 0, i64 %idxprom1468
  %571 = load i64, i64* %arrayidx1469, align 8
  %arrayidx1470 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %572 = load i64, i64* %arrayidx1470, align 8
  %shr1471 = lshr i64 %572, 8
  %conv1472 = trunc i64 %shr1471 to i8
  %idxprom1473 = zext i8 %conv1472 to i64
  %arrayidx1474 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 1), i64 0, i64 %idxprom1473
  %573 = load i64, i64* %arrayidx1474, align 8
  %xor1475 = xor i64 %571, %573
  %arrayidx1476 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %574 = load i64, i64* %arrayidx1476, align 16
  %shr1477 = lshr i64 %574, 16
  %conv1478 = trunc i64 %shr1477 to i8
  %idxprom1479 = zext i8 %conv1478 to i64
  %arrayidx1480 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 2), i64 0, i64 %idxprom1479
  %575 = load i64, i64* %arrayidx1480, align 8
  %xor1481 = xor i64 %xor1475, %575
  %arrayidx1482 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %576 = load i64, i64* %arrayidx1482, align 8
  %shr1483 = lshr i64 %576, 24
  %conv1484 = trunc i64 %shr1483 to i8
  %idxprom1485 = zext i8 %conv1484 to i64
  %arrayidx1486 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 3), i64 0, i64 %idxprom1485
  %577 = load i64, i64* %arrayidx1486, align 8
  %xor1487 = xor i64 %xor1481, %577
  %xor1488 = xor i64 %569, %xor1487
  %arrayidx1489 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  store i64 %xor1488, i64* %arrayidx1489, align 16
  %578 = load i64*, i64** %kp, align 8
  %add.ptr1490 = getelementptr inbounds i64, i64* %578, i64 36
  %arrayidx1491 = getelementptr inbounds i64, i64* %add.ptr1490, i64 3
  %579 = load i64, i64* %arrayidx1491, align 8
  %arrayidx1492 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 3
  %580 = load i64, i64* %arrayidx1492, align 8
  %shr1493 = lshr i64 %580, 0
  %conv1494 = trunc i64 %shr1493 to i8
  %idxprom1495 = zext i8 %conv1494 to i64
  %arrayidx1496 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 0), i64 0, i64 %idxprom1495
  %581 = load i64, i64* %arrayidx1496, align 8
  %arrayidx1497 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 2
  %582 = load i64, i64* %arrayidx1497, align 16
  %shr1498 = lshr i64 %582, 8
  %conv1499 = trunc i64 %shr1498 to i8
  %idxprom1500 = zext i8 %conv1499 to i64
  %arrayidx1501 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 1), i64 0, i64 %idxprom1500
  %583 = load i64, i64* %arrayidx1501, align 8
  %xor1502 = xor i64 %581, %583
  %arrayidx1503 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 1
  %584 = load i64, i64* %arrayidx1503, align 8
  %shr1504 = lshr i64 %584, 16
  %conv1505 = trunc i64 %shr1504 to i8
  %idxprom1506 = zext i8 %conv1505 to i64
  %arrayidx1507 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 2), i64 0, i64 %idxprom1506
  %585 = load i64, i64* %arrayidx1507, align 8
  %xor1508 = xor i64 %xor1502, %585
  %arrayidx1509 = getelementptr inbounds [4 x i64], [4 x i64]* %b1, i64 0, i64 0
  %586 = load i64, i64* %arrayidx1509, align 16
  %shr1510 = lshr i64 %586, 24
  %conv1511 = trunc i64 %shr1510 to i8
  %idxprom1512 = zext i8 %conv1511 to i64
  %arrayidx1513 = getelementptr inbounds [256 x i64], [256 x i64]* getelementptr inbounds ([4 x [256 x i64]], [4 x [256 x i64]]* @il_tab, i64 0, i64 3), i64 0, i64 %idxprom1512
  %587 = load i64, i64* %arrayidx1513, align 8
  %xor1514 = xor i64 %xor1508, %587
  %xor1515 = xor i64 %579, %xor1514
  %arrayidx1516 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  store i64 %xor1515, i64* %arrayidx1516, align 8
  br label %sw.epilog

sw.epilog:                                        ; preds = %sw.bb440, %if.end
  %arrayidx1517 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 0
  %588 = load i64, i64* %arrayidx1517, align 16
  %589 = load i8*, i8** %out_blk.addr, align 8
  %add.ptr1518 = getelementptr inbounds i8, i8* %589, i64 0
  %590 = bitcast i8* %add.ptr1518 to i64*
  store i64 %588, i64* %590, align 8
  %arrayidx1519 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 1
  %591 = load i64, i64* %arrayidx1519, align 8
  %592 = load i8*, i8** %out_blk.addr, align 8
  %add.ptr1520 = getelementptr inbounds i8, i8* %592, i64 4
  %593 = bitcast i8* %add.ptr1520 to i64*
  store i64 %591, i64* %593, align 8
  %arrayidx1521 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 2
  %594 = load i64, i64* %arrayidx1521, align 16
  %595 = load i8*, i8** %out_blk.addr, align 8
  %add.ptr1522 = getelementptr inbounds i8, i8* %595, i64 8
  %596 = bitcast i8* %add.ptr1522 to i64*
  store i64 %594, i64* %596, align 8
  %arrayidx1523 = getelementptr inbounds [4 x i64], [4 x i64]* %b0, i64 0, i64 3
  %597 = load i64, i64* %arrayidx1523, align 8
  %598 = load i8*, i8** %out_blk.addr, align 8
  %add.ptr1524 = getelementptr inbounds i8, i8* %598, i64 12
  %599 = bitcast i8* %add.ptr1524 to i64*
  store i64 %597, i64* %599, align 8
  store i16 1, i16* %retval, align 2
  br label %return

return:                                           ; preds = %sw.epilog, %if.then
  %600 = load i16, i16* %retval, align 2
  ret i16 %600
}

attributes #0 = { nounwind uwtable "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.ident = !{!0}

!0 = !{!"clang version 3.9.0 (trunk 261206)"}
